{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 98)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('image_bins_stats.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>rmean_bins1</th>\n",
       "      <th>rmean_bins2</th>\n",
       "      <th>rmean_bins3</th>\n",
       "      <th>rmean_bins4</th>\n",
       "      <th>rmean_bins5</th>\n",
       "      <th>rmean_bins6</th>\n",
       "      <th>rmean_bins7</th>\n",
       "      <th>rstd_bins0</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clean_p_1.jpg</td>\n",
       "      <td>1.485688</td>\n",
       "      <td>116.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>128.758621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.770015</td>\n",
       "      <td>11.472993</td>\n",
       "      <td>...</td>\n",
       "      <td>7.358843</td>\n",
       "      <td>47.621590</td>\n",
       "      <td>3.092351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.421707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.181035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clean_p_2.jpg</td>\n",
       "      <td>0.191129</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>122.485714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.839854</td>\n",
       "      <td>0.626280</td>\n",
       "      <td>...</td>\n",
       "      <td>8.430080</td>\n",
       "      <td>7.154429</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.029039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.516990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clean_p_3.jpg</td>\n",
       "      <td>1.218065</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.730769</td>\n",
       "      <td>135.517857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.189458</td>\n",
       "      <td>10.132966</td>\n",
       "      <td>...</td>\n",
       "      <td>7.949709</td>\n",
       "      <td>43.394240</td>\n",
       "      <td>0.420448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.701832</td>\n",
       "      <td>13.599319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.354453</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clean_p_4.jpg</td>\n",
       "      <td>0.148524</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>129.906667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.583812</td>\n",
       "      <td>0.573290</td>\n",
       "      <td>...</td>\n",
       "      <td>8.987692</td>\n",
       "      <td>6.601182</td>\n",
       "      <td>2.619225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.787280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.943418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clean_p_5.jpg</td>\n",
       "      <td>0.183128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158.600042</td>\n",
       "      <td>0.602004</td>\n",
       "      <td>...</td>\n",
       "      <td>7.204324</td>\n",
       "      <td>6.869720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.924785</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename  rmean_bins0  rmean_bins1  rmean_bins2  rmean_bins3  \\\n",
       "0  clean_p_1.jpg     1.485688   116.416667          0.0          0.0   \n",
       "1  clean_p_2.jpg     0.191129    91.000000          0.0          0.0   \n",
       "2  clean_p_3.jpg     1.218065   115.000000          0.0          0.0   \n",
       "3  clean_p_4.jpg     0.148524    98.000000          0.0          0.0   \n",
       "4  clean_p_5.jpg     0.183128     0.000000          0.0          0.0   \n",
       "\n",
       "   rmean_bins4  rmean_bins5  rmean_bins6  rmean_bins7  rstd_bins0  ...  \\\n",
       "0     0.000000   128.758621          0.0   159.770015   11.472993  ...   \n",
       "1     0.000000   122.485714          0.0   149.839854    0.626280  ...   \n",
       "2   121.730769   135.517857          0.0   154.189458   10.132966  ...   \n",
       "3     0.000000   129.906667          0.0   157.583812    0.573290  ...   \n",
       "4     0.000000     0.000000          0.0   158.600042    0.602004  ...   \n",
       "\n",
       "   bskew_bins7  bkurto_bins0  bkurto_bins1  bkurto_bins2  bkurto_bins3  \\\n",
       "0     7.358843     47.621590      3.092351           0.0           0.0   \n",
       "1     8.430080      7.154429      0.840896           0.0           0.0   \n",
       "2     7.949709     43.394240      0.420448           0.0           0.0   \n",
       "3     8.987692      6.601182      2.619225           0.0           0.0   \n",
       "4     7.204324      6.869720      0.000000           0.0           0.0   \n",
       "\n",
       "   bkurto_bins4  bkurto_bins5  bkurto_bins6  bkurto_bins7  class  \n",
       "0      0.000000      8.421707           0.0      9.181035      1  \n",
       "1      0.000000     15.029039           0.0     10.516990      1  \n",
       "2      7.701832     13.599319           0.0     10.354453      1  \n",
       "3      0.000000     12.787280           0.0     10.943418      1  \n",
       "4      0.000000      0.000000           0.0      8.924785      1  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>rmean_bins1</th>\n",
       "      <th>rmean_bins2</th>\n",
       "      <th>rmean_bins3</th>\n",
       "      <th>rmean_bins4</th>\n",
       "      <th>rmean_bins5</th>\n",
       "      <th>rmean_bins6</th>\n",
       "      <th>rmean_bins7</th>\n",
       "      <th>rstd_bins0</th>\n",
       "      <th>rstd_bins1</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.485688</td>\n",
       "      <td>116.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>128.758621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.770015</td>\n",
       "      <td>11.472993</td>\n",
       "      <td>1.943118</td>\n",
       "      <td>...</td>\n",
       "      <td>7.358843</td>\n",
       "      <td>47.621590</td>\n",
       "      <td>3.092351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.421707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.181035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.191129</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>122.485714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.839854</td>\n",
       "      <td>0.626280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.430080</td>\n",
       "      <td>7.154429</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.029039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.516990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.218065</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.730769</td>\n",
       "      <td>135.517857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.189458</td>\n",
       "      <td>10.132966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.949709</td>\n",
       "      <td>43.394240</td>\n",
       "      <td>0.420448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.701832</td>\n",
       "      <td>13.599319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.354453</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.148524</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>129.906667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.583812</td>\n",
       "      <td>0.573290</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.987692</td>\n",
       "      <td>6.601182</td>\n",
       "      <td>2.619225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.787280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.943418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.183128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158.600042</td>\n",
       "      <td>0.602004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.204324</td>\n",
       "      <td>6.869720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.924785</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rmean_bins0  rmean_bins1  rmean_bins2  rmean_bins3  rmean_bins4  \\\n",
       "0     1.485688   116.416667          0.0          0.0     0.000000   \n",
       "1     0.191129    91.000000          0.0          0.0     0.000000   \n",
       "2     1.218065   115.000000          0.0          0.0   121.730769   \n",
       "3     0.148524    98.000000          0.0          0.0     0.000000   \n",
       "4     0.183128     0.000000          0.0          0.0     0.000000   \n",
       "\n",
       "   rmean_bins5  rmean_bins6  rmean_bins7  rstd_bins0  rstd_bins1  ...  \\\n",
       "0   128.758621          0.0   159.770015   11.472993    1.943118  ...   \n",
       "1   122.485714          0.0   149.839854    0.626280    0.000000  ...   \n",
       "2   135.517857          0.0   154.189458   10.132966    0.000000  ...   \n",
       "3   129.906667          0.0   157.583812    0.573290    2.000000  ...   \n",
       "4     0.000000          0.0   158.600042    0.602004    0.000000  ...   \n",
       "\n",
       "   bskew_bins7  bkurto_bins0  bkurto_bins1  bkurto_bins2  bkurto_bins3  \\\n",
       "0     7.358843     47.621590      3.092351           0.0           0.0   \n",
       "1     8.430080      7.154429      0.840896           0.0           0.0   \n",
       "2     7.949709     43.394240      0.420448           0.0           0.0   \n",
       "3     8.987692      6.601182      2.619225           0.0           0.0   \n",
       "4     7.204324      6.869720      0.000000           0.0           0.0   \n",
       "\n",
       "   bkurto_bins4  bkurto_bins5  bkurto_bins6  bkurto_bins7  class  \n",
       "0      0.000000      8.421707           0.0      9.181035      1  \n",
       "1      0.000000     15.029039           0.0     10.516990      1  \n",
       "2      7.701832     13.599319           0.0     10.354453      1  \n",
       "3      0.000000     12.787280           0.0     10.943418      1  \n",
       "4      0.000000      0.000000           0.0      8.924785      1  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['filename'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>rmean_bins1</th>\n",
       "      <th>rmean_bins2</th>\n",
       "      <th>rmean_bins3</th>\n",
       "      <th>rmean_bins4</th>\n",
       "      <th>rmean_bins5</th>\n",
       "      <th>rmean_bins6</th>\n",
       "      <th>rmean_bins7</th>\n",
       "      <th>rstd_bins0</th>\n",
       "      <th>rstd_bins1</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.485688</td>\n",
       "      <td>116.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>128.758621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>159.770015</td>\n",
       "      <td>11.472993</td>\n",
       "      <td>1.943118</td>\n",
       "      <td>...</td>\n",
       "      <td>7.358843</td>\n",
       "      <td>47.621590</td>\n",
       "      <td>3.092351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.421707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.181035</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.191129</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>122.485714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>149.839854</td>\n",
       "      <td>0.626280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.430080</td>\n",
       "      <td>7.154429</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.029039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.516990</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.218065</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.730769</td>\n",
       "      <td>135.517857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>154.189458</td>\n",
       "      <td>10.132966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.949709</td>\n",
       "      <td>43.394240</td>\n",
       "      <td>0.420448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.701832</td>\n",
       "      <td>13.599319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.354453</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.148524</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>129.906667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>157.583812</td>\n",
       "      <td>0.573290</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.987692</td>\n",
       "      <td>6.601182</td>\n",
       "      <td>2.619225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.787280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.943418</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.183128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>158.600042</td>\n",
       "      <td>0.602004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.204324</td>\n",
       "      <td>6.869720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.924785</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23994</th>\n",
       "      <td>0.167535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>145.580835</td>\n",
       "      <td>0.587364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.817875</td>\n",
       "      <td>7.277478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.111529</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>0.182460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>142.290042</td>\n",
       "      <td>0.590877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.262551</td>\n",
       "      <td>8.170191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.111068</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>145.978772</td>\n",
       "      <td>0.689536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.407731</td>\n",
       "      <td>7.859719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.734824</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>0.217425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>145.915418</td>\n",
       "      <td>0.665380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.073114</td>\n",
       "      <td>7.887594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.672132</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>0.226175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>114.428571</td>\n",
       "      <td>144.317780</td>\n",
       "      <td>0.689573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.435542</td>\n",
       "      <td>7.406609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.278229</td>\n",
       "      <td>11.305344</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23999 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rmean_bins0  rmean_bins1  rmean_bins2  rmean_bins3  rmean_bins4  \\\n",
       "0         1.485688   116.416667          0.0          0.0     0.000000   \n",
       "1         0.191129    91.000000          0.0          0.0     0.000000   \n",
       "2         1.218065   115.000000          0.0          0.0   121.730769   \n",
       "3         0.148524    98.000000          0.0          0.0     0.000000   \n",
       "4         0.183128     0.000000          0.0          0.0     0.000000   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "23994     0.167535     0.000000          0.0          0.0     0.000000   \n",
       "23995     0.182460     0.000000          0.0          0.0     0.000000   \n",
       "23996     0.222222     0.000000          0.0          0.0     0.000000   \n",
       "23997     0.217425     0.000000          0.0          0.0     0.000000   \n",
       "23998     0.226175     0.000000          0.0          0.0     0.000000   \n",
       "\n",
       "       rmean_bins5  rmean_bins6  rmean_bins7  rstd_bins0  rstd_bins1  ...  \\\n",
       "0       128.758621     0.000000   159.770015   11.472993    1.943118  ...   \n",
       "1       122.485714     0.000000   149.839854    0.626280    0.000000  ...   \n",
       "2       135.517857     0.000000   154.189458   10.132966    0.000000  ...   \n",
       "3       129.906667     0.000000   157.583812    0.573290    2.000000  ...   \n",
       "4         0.000000     0.000000   158.600042    0.602004    0.000000  ...   \n",
       "...            ...          ...          ...         ...         ...  ...   \n",
       "23994     0.000000     0.000000   145.580835    0.587364    0.000000  ...   \n",
       "23995     0.000000     0.000000   142.290042    0.590877    0.000000  ...   \n",
       "23996     0.000000     0.000000   145.978772    0.689536    0.000000  ...   \n",
       "23997     0.000000     0.000000   145.915418    0.665380    0.000000  ...   \n",
       "23998     0.000000   114.428571   144.317780    0.689573    0.000000  ...   \n",
       "\n",
       "       bskew_bins7  bkurto_bins0  bkurto_bins1  bkurto_bins2  bkurto_bins3  \\\n",
       "0         7.358843     47.621590      3.092351           0.0           0.0   \n",
       "1         8.430080      7.154429      0.840896           0.0           0.0   \n",
       "2         7.949709     43.394240      0.420448           0.0           0.0   \n",
       "3         8.987692      6.601182      2.619225           0.0           0.0   \n",
       "4         7.204324      6.869720      0.000000           0.0           0.0   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "23994     6.817875      7.277478      0.000000           0.0           0.0   \n",
       "23995     5.262551      8.170191      0.000000           0.0           0.0   \n",
       "23996     5.407731      7.859719      0.000000           0.0           0.0   \n",
       "23997     5.073114      7.887594      0.000000           0.0           0.0   \n",
       "23998     7.435542      7.406609      0.000000           0.0           0.0   \n",
       "\n",
       "       bkurto_bins4  bkurto_bins5  bkurto_bins6  bkurto_bins7  class  \n",
       "0          0.000000      8.421707      0.000000      9.181035    1.0  \n",
       "1          0.000000     15.029039      0.000000     10.516990    1.0  \n",
       "2          7.701832     13.599319      0.000000     10.354453    1.0  \n",
       "3          0.000000     12.787280      0.000000     10.943418    1.0  \n",
       "4          0.000000      0.000000      0.000000      8.924785    1.0  \n",
       "...             ...           ...           ...           ...    ...  \n",
       "23994      0.000000      0.000000      0.000000     11.111529    0.0  \n",
       "23995      0.000000      0.000000      0.000000     10.111068    0.0  \n",
       "23996      0.000000      0.000000      0.000000      9.734824    0.0  \n",
       "23997      0.000000      0.000000      0.000000      9.672132    0.0  \n",
       "23998      0.000000      0.000000     14.278229     11.305344    0.0  \n",
       "\n",
       "[23999 rows x 97 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)\n",
    "\n",
    "clean_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16799, 96), (7200, 96))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['class'], axis=1),\n",
    "    data['class'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5560201519965668,\n",
       " 0.6707397386960453,\n",
       " 0.5058545402378194,\n",
       " 0.5043554260394423,\n",
       " 0.7458311915303212,\n",
       " 0.9313870495085048,\n",
       " 0.5338828670601488,\n",
       " 0.5200113533244551,\n",
       " 0.6343497949078117,\n",
       " 0.6400790874186691]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine roc-auc for each feature\n",
    "\n",
    "# here we store the roc-auc values\n",
    "roc_values = []\n",
    "\n",
    "# iterate over each feature in the dataset\n",
    "for feature in X_train.columns:\n",
    "\n",
    "    # train a decision tree classifier\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train[feature].fillna(0).to_frame(), y_train)\n",
    "\n",
    "    # obtain the predictions\n",
    "    y_scored = clf.predict_proba(X_test[feature].to_frame())\n",
    "\n",
    "    # calculate and store the roc-auc\n",
    "    roc_values.append(roc_auc_score(y_test, y_scored[:, 1]))\n",
    "    \n",
    "# display the result\n",
    "roc_values[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'roc-auc')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now let's:\n",
    "\n",
    "# 1) capture the roc-auc values in a pandas series\n",
    "# 2) add the variable names in the index\n",
    "# 3) sort the features based on the roc-auc\n",
    "# 4) and make a var plot\n",
    "\n",
    "roc_values = pd.Series(roc_values)\n",
    "roc_values.index = X_train.columns\n",
    "roc_values.sort_values(ascending=False).plot.bar(figsize=(20, 5))\n",
    "plt.ylabel('roc-auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a roc auc value of 0.5 indicates random decision\n",
    "# let's check how many features show a roc-auc value\n",
    "# higher than random\n",
    "\n",
    "len(roc_values[roc_values > 0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rmean_bins1', 'rmean_bins4', 'rmean_bins5', 'rstd_bins0', 'rstd_bins1',\n",
       "       'rstd_bins4', 'rstd_bins5', 'rskew_bins0', 'rskew_bins1', 'rskew_bins4',\n",
       "       'rskew_bins5', 'rkurto_bins0', 'rkurto_bins1', 'rkurto_bins4',\n",
       "       'rkurto_bins5', 'gmean_bins1', 'gmean_bins4', 'gmean_bins5',\n",
       "       'gstd_bins0', 'gstd_bins1', 'gstd_bins4', 'gstd_bins5', 'gskew_bins0',\n",
       "       'gskew_bins1', 'gskew_bins4', 'gskew_bins5', 'gskew_bins7',\n",
       "       'gkurto_bins0', 'gkurto_bins1', 'gkurto_bins4', 'gkurto_bins5',\n",
       "       'bmean_bins1', 'bmean_bins4', 'bmean_bins5', 'bstd_bins0', 'bstd_bins1',\n",
       "       'bstd_bins4', 'bstd_bins5', 'bskew_bins0', 'bskew_bins1', 'bskew_bins4',\n",
       "       'bskew_bins5', 'bskew_bins7', 'bkurto_bins0', 'bkurto_bins1',\n",
       "       'bkurto_bins4', 'bkurto_bins5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = roc_values[roc_values > 0.6].index\n",
    "\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16799, 47), (7200, 47))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select features in the dataframes\n",
    "\n",
    "X_train = X_train[selected_features]\n",
    "X_test = X_test[selected_features]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build random forests and\n",
    "# compare its performance in train and test sets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = rf, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.9992213602955976\n",
      "Test set\n",
      "Random Forests roc-auc: 0.9989125132665742\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      3559\n",
      "           1       0.99      0.96      0.97      3641\n",
      "\n",
      "    accuracy                           0.97      7200\n",
      "   macro avg       0.97      0.97      0.97      7200\n",
      "weighted avg       0.97      0.97      0.97      7200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3509   50]\n",
      " [ 137 3504]]\n",
      "Metrics:\n",
      "Accuracy: 0.974\n",
      "F1 Score: 0.974\n",
      "Precision: 0.986\n",
      "Recall: 0.962\n",
      "After Cross Validation:\n",
      "Accuracy: 97.58 %\n",
      "Standard Deviation: 0.40 %\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "run_randomForests(X_train,\n",
    "                  X_test,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def run_logistic(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    logit = LogisticRegression(penalty='l1', random_state=44, max_iter=1000, solver='liblinear')\n",
    "    logit.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = logit.predict_proba(scaler.transform(X_train))\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = logit.predict_proba(scaler.transform(X_test))\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = logit.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = logit, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.9998861232522314\n",
      "Test set\n",
      "Logistic Regression roc-auc: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3559\n",
      "           1       1.00      1.00      1.00      3641\n",
      "\n",
      "    accuracy                           1.00      7200\n",
      "   macro avg       1.00      1.00      1.00      7200\n",
      "weighted avg       1.00      1.00      1.00      7200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3556    3]\n",
      " [   0 3641]]\n",
      "Metrics:\n",
      "Accuracy: 1.000\n",
      "F1 Score: 1.000\n",
      "Precision: 0.999\n",
      "Recall: 1.000\n",
      "After Cross Validation:\n",
      "Accuracy: 100.00 %\n",
      "Standard Deviation: 0.00 %\n"
     ]
    }
   ],
   "source": [
    "run_logistic(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run_kernel_SVM(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = SVC(kernel = 'rbf', random_state = 0, probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.9917269832612238\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.9928131110215762\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      3559\n",
      "           1       1.00      0.93      0.96      3641\n",
      "\n",
      "    accuracy                           0.96      7200\n",
      "   macro avg       0.96      0.96      0.96      7200\n",
      "weighted avg       0.96      0.96      0.96      7200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3545   14]\n",
      " [ 260 3381]]\n",
      "Metrics:\n",
      "Accuracy: 0.962\n",
      "F1 Score: 0.961\n",
      "Precision: 0.996\n",
      "Recall: 0.929\n",
      "After Cross Validation:\n",
      "Accuracy: 96.39 %\n",
      "Standard Deviation: 0.56 %\n"
     ]
    }
   ],
   "source": [
    "run_kernel_SVM(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def run_knn(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('KNN roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('KNN roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "KNN roc-auc: 0.5075367866969733\n",
      "Test set\n",
      "KNN roc-auc: 0.5068662455369404\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      3559\n",
      "           1       0.99      0.97      0.98      3641\n",
      "\n",
      "    accuracy                           0.98      7200\n",
      "   macro avg       0.98      0.98      0.98      7200\n",
      "weighted avg       0.98      0.98      0.98      7200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3536   23]\n",
      " [ 113 3528]]\n",
      "Metrics:\n",
      "Accuracy: 0.981\n",
      "F1 Score: 0.981\n",
      "Precision: 0.994\n",
      "Recall: 0.969\n",
      "After Cross Validation:\n",
      "Accuracy: 98.05 %\n",
      "Standard Deviation: 0.36 %\n"
     ]
    }
   ],
   "source": [
    "run_knn(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def run_decision_tree(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(X_train)\n",
    "    print('Decision Tree roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(X_test)\n",
    "    print('Decision Tree roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Decision Tree roc-auc: 1.0\n",
      "Test set\n",
      "Decision Tree roc-auc: 0.9980521393245528\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3559\n",
      "           1       1.00      1.00      1.00      3641\n",
      "\n",
      "    accuracy                           1.00      7200\n",
      "   macro avg       1.00      1.00      1.00      7200\n",
      "weighted avg       1.00      1.00      1.00      7200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3551    8]\n",
      " [   6 3635]]\n",
      "Metrics:\n",
      "Accuracy: 0.998\n",
      "F1 Score: 0.998\n",
      "Precision: 0.998\n",
      "Recall: 0.998\n",
      "After Cross Validation:\n",
      "Accuracy: 99.76 %\n",
      "Standard Deviation: 0.12 %\n"
     ]
    }
   ],
   "source": [
    "run_decision_tree(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def run_naive_bayes(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.9292963312806981\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.9257760207940552\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      3559\n",
      "           1       0.97      0.92      0.95      3641\n",
      "\n",
      "    accuracy                           0.95      7200\n",
      "   macro avg       0.95      0.95      0.95      7200\n",
      "weighted avg       0.95      0.95      0.95      7200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3471   88]\n",
      " [ 300 3341]]\n",
      "Metrics:\n",
      "Accuracy: 0.946\n",
      "F1 Score: 0.945\n",
      "Precision: 0.974\n",
      "Recall: 0.918\n",
      "After Cross Validation:\n",
      "Accuracy: 94.78 %\n",
      "Standard Deviation: 0.54 %\n"
     ]
    }
   ],
   "source": [
    "run_naive_bayes(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run_linear_SVM(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = SVC(kernel = 'linear', random_state = 0, probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.9973262068468927\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.997651045633311\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3559\n",
      "           1       1.00      1.00      1.00      3641\n",
      "\n",
      "    accuracy                           1.00      7200\n",
      "   macro avg       1.00      1.00      1.00      7200\n",
      "weighted avg       1.00      1.00      1.00      7200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3559    0]\n",
      " [   0 3641]]\n",
      "Metrics:\n",
      "Accuracy: 1.000\n",
      "F1 Score: 1.000\n",
      "Precision: 1.000\n",
      "Recall: 1.000\n",
      "After Cross Validation:\n",
      "Accuracy: 100.00 %\n",
      "Standard Deviation: 0.00 %\n"
     ]
    }
   ],
   "source": [
    "run_linear_SVM(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
