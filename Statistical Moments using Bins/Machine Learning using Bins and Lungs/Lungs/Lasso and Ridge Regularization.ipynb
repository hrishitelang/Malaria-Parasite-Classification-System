{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('image_bins_lungs2.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transformed_image_covid_1.png</td>\n",
       "      <td>4722</td>\n",
       "      <td>15567</td>\n",
       "      <td>4</td>\n",
       "      <td>7683</td>\n",
       "      <td>12061</td>\n",
       "      <td>1</td>\n",
       "      <td>8864</td>\n",
       "      <td>16634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transformed_image_covid_2.png</td>\n",
       "      <td>6556</td>\n",
       "      <td>13701</td>\n",
       "      <td>25</td>\n",
       "      <td>9956</td>\n",
       "      <td>9437</td>\n",
       "      <td>0</td>\n",
       "      <td>12114</td>\n",
       "      <td>13747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transformed_image_covid_3.png</td>\n",
       "      <td>10512</td>\n",
       "      <td>12249</td>\n",
       "      <td>1</td>\n",
       "      <td>11502</td>\n",
       "      <td>7743</td>\n",
       "      <td>2</td>\n",
       "      <td>9619</td>\n",
       "      <td>13908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transformed_image_covid_4.png</td>\n",
       "      <td>7987</td>\n",
       "      <td>11854</td>\n",
       "      <td>2</td>\n",
       "      <td>10419</td>\n",
       "      <td>11895</td>\n",
       "      <td>9</td>\n",
       "      <td>11931</td>\n",
       "      <td>11439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transformed_image_covid_5.png</td>\n",
       "      <td>7761</td>\n",
       "      <td>14159</td>\n",
       "      <td>4</td>\n",
       "      <td>10898</td>\n",
       "      <td>10560</td>\n",
       "      <td>9</td>\n",
       "      <td>9153</td>\n",
       "      <td>12992</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        filename  Bins0  Bins1  Bins2  Bins3  Bins4  Bins5  \\\n",
       "0  transformed_image_covid_1.png   4722  15567      4   7683  12061      1   \n",
       "1  transformed_image_covid_2.png   6556  13701     25   9956   9437      0   \n",
       "2  transformed_image_covid_3.png  10512  12249      1  11502   7743      2   \n",
       "3  transformed_image_covid_4.png   7987  11854      2  10419  11895      9   \n",
       "4  transformed_image_covid_5.png   7761  14159      4  10898  10560      9   \n",
       "\n",
       "   Bins6  Bins7  Class  \n",
       "0   8864  16634      0  \n",
       "1  12114  13747      0  \n",
       "2   9619  13908      0  \n",
       "3  11931  11439      0  \n",
       "4   9153  12992      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4722</td>\n",
       "      <td>15567</td>\n",
       "      <td>4</td>\n",
       "      <td>7683</td>\n",
       "      <td>12061</td>\n",
       "      <td>1</td>\n",
       "      <td>8864</td>\n",
       "      <td>16634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6556</td>\n",
       "      <td>13701</td>\n",
       "      <td>25</td>\n",
       "      <td>9956</td>\n",
       "      <td>9437</td>\n",
       "      <td>0</td>\n",
       "      <td>12114</td>\n",
       "      <td>13747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10512</td>\n",
       "      <td>12249</td>\n",
       "      <td>1</td>\n",
       "      <td>11502</td>\n",
       "      <td>7743</td>\n",
       "      <td>2</td>\n",
       "      <td>9619</td>\n",
       "      <td>13908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7987</td>\n",
       "      <td>11854</td>\n",
       "      <td>2</td>\n",
       "      <td>10419</td>\n",
       "      <td>11895</td>\n",
       "      <td>9</td>\n",
       "      <td>11931</td>\n",
       "      <td>11439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7761</td>\n",
       "      <td>14159</td>\n",
       "      <td>4</td>\n",
       "      <td>10898</td>\n",
       "      <td>10560</td>\n",
       "      <td>9</td>\n",
       "      <td>9153</td>\n",
       "      <td>12992</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bins0  Bins1  Bins2  Bins3  Bins4  Bins5  Bins6  Bins7  Class\n",
       "0   4722  15567      4   7683  12061      1   8864  16634      0\n",
       "1   6556  13701     25   9956   9437      0  12114  13747      0\n",
       "2  10512  12249      1  11502   7743      2   9619  13908      0\n",
       "3   7987  11854      2  10419  11895      9  11931  11439      0\n",
       "4   7761  14159      4  10898  10560      9   9153  12992      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['filename'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4722.0</td>\n",
       "      <td>15567.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7683.0</td>\n",
       "      <td>12061.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8864.0</td>\n",
       "      <td>16634.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6556.0</td>\n",
       "      <td>13701.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9956.0</td>\n",
       "      <td>9437.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12114.0</td>\n",
       "      <td>13747.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10512.0</td>\n",
       "      <td>12249.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11502.0</td>\n",
       "      <td>7743.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9619.0</td>\n",
       "      <td>13908.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7987.0</td>\n",
       "      <td>11854.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10419.0</td>\n",
       "      <td>11895.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11931.0</td>\n",
       "      <td>11439.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7761.0</td>\n",
       "      <td>14159.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10898.0</td>\n",
       "      <td>10560.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9153.0</td>\n",
       "      <td>12992.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>7794.0</td>\n",
       "      <td>14496.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9859.0</td>\n",
       "      <td>11028.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9656.0</td>\n",
       "      <td>12703.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>7098.0</td>\n",
       "      <td>9460.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11614.0</td>\n",
       "      <td>15969.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6950.0</td>\n",
       "      <td>14445.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>6380.0</td>\n",
       "      <td>10094.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11283.0</td>\n",
       "      <td>13771.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7565.0</td>\n",
       "      <td>16442.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>6929.0</td>\n",
       "      <td>13336.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10413.0</td>\n",
       "      <td>11515.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9202.0</td>\n",
       "      <td>14140.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>6836.0</td>\n",
       "      <td>8529.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11780.0</td>\n",
       "      <td>16135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7419.0</td>\n",
       "      <td>14836.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2200 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bins0    Bins1  Bins2    Bins3    Bins4  Bins5    Bins6    Bins7  \\\n",
       "0      4722.0  15567.0    4.0   7683.0  12061.0    1.0   8864.0  16634.0   \n",
       "1      6556.0  13701.0   25.0   9956.0   9437.0    0.0  12114.0  13747.0   \n",
       "2     10512.0  12249.0    1.0  11502.0   7743.0    2.0   9619.0  13908.0   \n",
       "3      7987.0  11854.0    2.0  10419.0  11895.0    9.0  11931.0  11439.0   \n",
       "4      7761.0  14159.0    4.0  10898.0  10560.0    9.0   9153.0  12992.0   \n",
       "...       ...      ...    ...      ...      ...    ...      ...      ...   \n",
       "2195   7794.0  14496.0    0.0   9859.0  11028.0    0.0   9656.0  12703.0   \n",
       "2196   7098.0   9460.0    0.0  11614.0  15969.0    0.0   6950.0  14445.0   \n",
       "2197   6380.0  10094.0    1.0  11283.0  13771.0    0.0   7565.0  16442.0   \n",
       "2198   6929.0  13336.0    1.0  10413.0  11515.0    0.0   9202.0  14140.0   \n",
       "2199   6836.0   8529.0    1.0  11780.0  16135.0    0.0   7419.0  14836.0   \n",
       "\n",
       "      Class  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "...     ...  \n",
       "2195    1.0  \n",
       "2196    1.0  \n",
       "2197    1.0  \n",
       "2198    1.0  \n",
       "2199    1.0  \n",
       "\n",
       "[2200 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)\n",
    "\n",
    "clean_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1540, 8), (660, 8))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['Class'], axis=1),\n",
    "    data['Class'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear models benefit from feature scaling\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=0.1, penalty='l1',\n",
       "                                             random_state=10,\n",
       "                                             solver='liblinear'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here I will do the model fitting and feature selection\n",
    "# altogether in one line of code\n",
    "\n",
    "# first I specify the Logistic Regression model, and I\n",
    "# make sure I select the Lasso (l1) penalty.\n",
    "\n",
    "# Then I use the selectFromModel class from sklearn, which\n",
    "# will select the features which coefficients are non-zero\n",
    "\n",
    "sel_ = SelectFromModel(\n",
    "    LogisticRegression(C=0.1, penalty='l1', solver='liblinear', random_state=10))\n",
    "\n",
    "sel_.fit(scaler.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False,  True])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this command let's me visualise the index of the\n",
    "# features that were selected\n",
    "\n",
    "sel_.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 8\n",
      "selected features: 7\n",
      "features with coefficients shrank to zero: 1\n"
     ]
    }
   ],
   "source": [
    "# Now I make a list with the selected features\n",
    "selected_feat = X_train.columns[(sel_.get_support())]\n",
    "\n",
    "print('total features: {}'.format((X_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "    np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of features which coefficient was shrank to zero:\n",
    "np.sum(sel_.estimator_.coef_ == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Bins6'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can identify the removed features like this:\n",
    "\n",
    "removed_feats = X_train.columns[(sel_.estimator_.coef_ == 0).ravel().tolist()]\n",
    "removed_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1540, 7), (660, 7))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can then remove the features from the training and testing set\n",
    "# like this:\n",
    "\n",
    "X_train_selected = sel_.transform(X_train)\n",
    "X_test_selected = sel_.transform(X_test)\n",
    "\n",
    "X_train_selected.shape, X_test_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build random forests and\n",
    "# compare its performance in train and test sets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    y_pred = rf.predict(X_test_selected)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = rf, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.9525135942897237\n",
      "Test set\n",
      "Random Forests roc-auc: 0.930846863062004\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86       332\n",
      "           1       0.86      0.86      0.86       328\n",
      "\n",
      "    accuracy                           0.86       660\n",
      "   macro avg       0.86      0.86      0.86       660\n",
      "weighted avg       0.86      0.86      0.86       660\n",
      "\n",
      "Confusion Matrix:\n",
      "[[286  46]\n",
      " [ 47 281]]\n",
      "Metrics:\n",
      "Accuracy: 0.859\n",
      "F1 Score: 0.858\n",
      "Precision: 0.859\n",
      "Recall: 0.857\n",
      "After Cross Validation:\n",
      "Accuracy: 86.17 %\n",
      "Standard Deviation: 1.05 %\n"
     ]
    }
   ],
   "source": [
    "run_randomForests(X_train_selected, X_test_selected, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def run_logistic(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    logit = LogisticRegression(penalty='l1', random_state=44, max_iter=1000, solver='liblinear')\n",
    "    logit.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = logit.predict_proba(scaler.transform(X_train))\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = logit.predict_proba(scaler.transform(X_test))\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = logit.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = logit, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.8433350874352332\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.8369177931237144\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.77      0.81       332\n",
      "           1       0.79      0.87      0.83       328\n",
      "\n",
      "    accuracy                           0.82       660\n",
      "   macro avg       0.82      0.82      0.82       660\n",
      "weighted avg       0.82      0.82      0.82       660\n",
      "\n",
      "Confusion Matrix:\n",
      "[[256  76]\n",
      " [ 42 286]]\n",
      "Metrics:\n",
      "Accuracy: 0.821\n",
      "F1 Score: 0.829\n",
      "Precision: 0.790\n",
      "Recall: 0.872\n",
      "After Cross Validation:\n",
      "Accuracy: 80.65 %\n",
      "Standard Deviation: 1.48 %\n"
     ]
    }
   ],
   "source": [
    "run_logistic(X_train_selected, X_test_selected, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run_kernel_SVM(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = SVC(kernel = 'rbf', random_state = 0, probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.34711989961139894\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.33740449603291217\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82       332\n",
      "           1       0.80      0.87      0.83       328\n",
      "\n",
      "    accuracy                           0.83       660\n",
      "   macro avg       0.83      0.83      0.83       660\n",
      "weighted avg       0.83      0.83      0.83       660\n",
      "\n",
      "Confusion Matrix:\n",
      "[[262  70]\n",
      " [ 43 285]]\n",
      "Metrics:\n",
      "Accuracy: 0.829\n",
      "F1 Score: 0.835\n",
      "Precision: 0.803\n",
      "Recall: 0.869\n",
      "After Cross Validation:\n",
      "Accuracy: 82.60 %\n",
      "Standard Deviation: 2.72 %\n"
     ]
    }
   ],
   "source": [
    "run_kernel_SVM(X_train_selected, X_test_selected, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def run_knn(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('KNN roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('KNN roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "KNN roc-auc: 0.5\n",
      "Test set\n",
      "KNN roc-auc: 0.5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.85       332\n",
      "           1       0.83      0.89      0.86       328\n",
      "\n",
      "    accuracy                           0.85       660\n",
      "   macro avg       0.86      0.85      0.85       660\n",
      "weighted avg       0.86      0.85      0.85       660\n",
      "\n",
      "Confusion Matrix:\n",
      "[[271  61]\n",
      " [ 35 293]]\n",
      "Metrics:\n",
      "Accuracy: 0.855\n",
      "F1 Score: 0.859\n",
      "Precision: 0.828\n",
      "Recall: 0.893\n",
      "After Cross Validation:\n",
      "Accuracy: 85.91 %\n",
      "Standard Deviation: 2.13 %\n"
     ]
    }
   ],
   "source": [
    "run_knn(X_train_selected, X_test_selected, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def run_decision_tree(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(X_train)\n",
    "    print('Decision Tree roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(X_test)\n",
    "    print('Decision Tree roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Decision Tree roc-auc: 1.0\n",
      "Test set\n",
      "Decision Tree roc-auc: 0.8347965030855128\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84       332\n",
      "           1       0.84      0.83      0.83       328\n",
      "\n",
      "    accuracy                           0.83       660\n",
      "   macro avg       0.83      0.83      0.83       660\n",
      "weighted avg       0.83      0.83      0.83       660\n",
      "\n",
      "Confusion Matrix:\n",
      "[[280  52]\n",
      " [ 57 271]]\n",
      "Metrics:\n",
      "Accuracy: 0.835\n",
      "F1 Score: 0.833\n",
      "Precision: 0.839\n",
      "Recall: 0.826\n",
      "After Cross Validation:\n",
      "Accuracy: 84.29 %\n",
      "Standard Deviation: 1.56 %\n"
     ]
    }
   ],
   "source": [
    "run_decision_tree(X_train_selected, X_test_selected, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run_linear_SVM(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = SVC(kernel = 'linear', random_state = 0, probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.8437904792746115\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.838322803408757\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.76      0.81       332\n",
      "           1       0.78      0.88      0.83       328\n",
      "\n",
      "    accuracy                           0.82       660\n",
      "   macro avg       0.82      0.82      0.82       660\n",
      "weighted avg       0.82      0.82      0.82       660\n",
      "\n",
      "Confusion Matrix:\n",
      "[[252  80]\n",
      " [ 40 288]]\n",
      "Metrics:\n",
      "Accuracy: 0.818\n",
      "F1 Score: 0.828\n",
      "Precision: 0.783\n",
      "Recall: 0.878\n",
      "After Cross Validation:\n",
      "Accuracy: 81.17 %\n",
      "Standard Deviation: 1.69 %\n"
     ]
    }
   ],
   "source": [
    "run_linear_SVM(X_train_selected, X_test_selected, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def run_naive_bayes(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.25784454609240065\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.2487419188950926\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.53      0.67       332\n",
      "           1       0.67      0.95      0.78       328\n",
      "\n",
      "    accuracy                           0.74       660\n",
      "   macro avg       0.79      0.74      0.73       660\n",
      "weighted avg       0.79      0.74      0.72       660\n",
      "\n",
      "Confusion Matrix:\n",
      "[[176 156]\n",
      " [ 18 310]]\n",
      "Metrics:\n",
      "Accuracy: 0.736\n",
      "F1 Score: 0.781\n",
      "Precision: 0.665\n",
      "Recall: 0.945\n",
      "After Cross Validation:\n",
      "Accuracy: 71.62 %\n",
      "Standard Deviation: 1.51 %\n"
     ]
    }
   ],
   "source": [
    "run_naive_bayes(X_train_selected, X_test_selected, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For comparison, I will fit a logistic regression with a\n",
    "# Ridge regularisation, and evaluate the coefficients\n",
    "\n",
    "l1_logit = LogisticRegression(C=0.5, penalty='l2', max_iter=300, random_state=10)\n",
    "l1_logit.fit(scaler.transform(X_train), y_train)\n",
    "\n",
    "# I count the number of coefficients with zero values\n",
    "# and it is zero, as expected\n",
    "np.sum(l1_logit.coef_ == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=0.5, random_state=10,\n",
       "                                             solver='liblinear'))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here I will do the model fitting and feature selection\n",
    "# altogether in one line of code\n",
    "\n",
    "# first I specify the Logistic Regression model, and I\n",
    "# make sure I select the Lasso (l1) penalty.\n",
    "\n",
    "# Then I use the selectFromModel class from sklearn, which\n",
    "# will select the features which coefficients are non-zero\n",
    "\n",
    "sel_ = SelectFromModel(\n",
    "    LogisticRegression(C=0.5, penalty='l2', solver='liblinear', random_state=10))\n",
    "\n",
    "sel_.fit(scaler.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False,  True,  True, False, False, False, False, False,\n",
       "       False,  True,  True, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False,  True, False, False,\n",
       "        True, False, False, False, False, False, False,  True,  True,\n",
       "       False, False, False, False, False, False,  True,  True, False,\n",
       "       False, False, False, False, False,  True])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this command let's me visualise the index of the\n",
    "# features that were selected\n",
    "\n",
    "sel_.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 96\n",
      "selected features: 13\n",
      "features with coefficients shrank to zero: 0\n"
     ]
    }
   ],
   "source": [
    "# Now I make a list with the selected features\n",
    "selected_feat = X_train.columns[(sel_.get_support())]\n",
    "\n",
    "print('total features: {}'.format((X_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "    np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can identify the removed features like this:\n",
    "\n",
    "removed_feats = X_train.columns[(sel_.estimator_.coef_ == 0).ravel().tolist()]\n",
    "removed_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16799, 13), (7200, 13))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can then remove the features from the training and testing set\n",
    "# like this:\n",
    "\n",
    "X_train_ridge = sel_.transform(X_train)\n",
    "X_test_ridge = sel_.transform(X_test)\n",
    "\n",
    "X_train_ridge.shape, X_test_ridge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.999772997745144\n",
      "Test set\n",
      "Random Forests roc-auc: 0.9998485143018937\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93      3559\n",
      "           1       0.98      0.87      0.92      3641\n",
      "\n",
      "    accuracy                           0.93      7200\n",
      "   macro avg       0.93      0.93      0.93      7200\n",
      "weighted avg       0.93      0.93      0.93      7200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3488   71]\n",
      " [ 456 3185]]\n",
      "Metrics:\n",
      "Accuracy: 0.927\n",
      "F1 Score: 0.924\n",
      "Precision: 0.978\n",
      "Recall: 0.875\n",
      "After Cross Validation:\n",
      "Accuracy: 99.57 %\n",
      "Standard Deviation: 0.23 %\n"
     ]
    }
   ],
   "source": [
    "run_randomForests(X_train_ridge, X_test_ridge, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.999753252872149\n",
      "Test set\n",
      "Logistic Regression roc-auc: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3559\n",
      "           1       1.00      1.00      1.00      3641\n",
      "\n",
      "    accuracy                           1.00      7200\n",
      "   macro avg       1.00      1.00      1.00      7200\n",
      "weighted avg       1.00      1.00      1.00      7200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3558    1]\n",
      " [   0 3641]]\n",
      "Metrics:\n",
      "Accuracy: 1.000\n",
      "F1 Score: 1.000\n",
      "Precision: 1.000\n",
      "Recall: 1.000\n",
      "After Cross Validation:\n",
      "Accuracy: 100.00 %\n",
      "Standard Deviation: 0.00 %\n"
     ]
    }
   ],
   "source": [
    "run_logistic(X_train_ridge, X_test_ridge, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.9986423946944832\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.998696050004634\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      3559\n",
      "           1       0.97      0.94      0.96      3641\n",
      "\n",
      "    accuracy                           0.96      7200\n",
      "   macro avg       0.96      0.96      0.96      7200\n",
      "weighted avg       0.96      0.96      0.96      7200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3467   92]\n",
      " [ 222 3419]]\n",
      "Metrics:\n",
      "Accuracy: 0.956\n",
      "F1 Score: 0.956\n",
      "Precision: 0.974\n",
      "Recall: 0.939\n",
      "After Cross Validation:\n",
      "Accuracy: 95.77 %\n",
      "Standard Deviation: 0.47 %\n"
     ]
    }
   ],
   "source": [
    "run_kernel_SVM(X_train_ridge, X_test_ridge, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "KNN roc-auc: 0.510707022371097\n",
      "Test set\n",
      "KNN roc-auc: 0.5102941207111817\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3559\n",
      "           1       0.98      0.99      0.99      3641\n",
      "\n",
      "    accuracy                           0.99      7200\n",
      "   macro avg       0.99      0.99      0.99      7200\n",
      "weighted avg       0.99      0.99      0.99      7200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3490   69]\n",
      " [  32 3609]]\n",
      "Metrics:\n",
      "Accuracy: 0.986\n",
      "F1 Score: 0.986\n",
      "Precision: 0.981\n",
      "Recall: 0.991\n",
      "After Cross Validation:\n",
      "Accuracy: 98.63 %\n",
      "Standard Deviation: 0.31 %\n"
     ]
    }
   ],
   "source": [
    "run_knn(X_train_ridge, X_test_ridge, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Decision Tree roc-auc: 1.0\n",
      "Test set\n",
      "Decision Tree roc-auc: 0.9983236251553924\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3559\n",
      "           1       1.00      1.00      1.00      3641\n",
      "\n",
      "    accuracy                           1.00      7200\n",
      "   macro avg       1.00      1.00      1.00      7200\n",
      "weighted avg       1.00      1.00      1.00      7200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3550    9]\n",
      " [   3 3638]]\n",
      "Metrics:\n",
      "Accuracy: 0.998\n",
      "F1 Score: 0.998\n",
      "Precision: 0.998\n",
      "Recall: 0.999\n",
      "After Cross Validation:\n",
      "Accuracy: 99.84 %\n",
      "Standard Deviation: 0.10 %\n"
     ]
    }
   ],
   "source": [
    "run_decision_tree(X_train_ridge, X_test_ridge, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.9979560158503278\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.997918480012724\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3559\n",
      "           1       1.00      1.00      1.00      3641\n",
      "\n",
      "    accuracy                           1.00      7200\n",
      "   macro avg       1.00      1.00      1.00      7200\n",
      "weighted avg       1.00      1.00      1.00      7200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3558    1]\n",
      " [   0 3641]]\n",
      "Metrics:\n",
      "Accuracy: 1.000\n",
      "F1 Score: 1.000\n",
      "Precision: 1.000\n",
      "Recall: 1.000\n",
      "After Cross Validation:\n",
      "Accuracy: 100.00 %\n",
      "Standard Deviation: 0.00 %\n"
     ]
    }
   ],
   "source": [
    "run_linear_SVM(X_train_ridge, X_test_ridge, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.34678172035816884\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.34544318595645007\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93      3559\n",
      "           1       0.95      0.91      0.93      3641\n",
      "\n",
      "    accuracy                           0.93      7200\n",
      "   macro avg       0.93      0.93      0.93      7200\n",
      "weighted avg       0.93      0.93      0.93      7200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3387  172]\n",
      " [ 337 3304]]\n",
      "Metrics:\n",
      "Accuracy: 0.929\n",
      "F1 Score: 0.928\n",
      "Precision: 0.951\n",
      "Recall: 0.907\n",
      "After Cross Validation:\n",
      "Accuracy: 93.33 %\n",
      "Standard Deviation: 0.50 %\n"
     ]
    }
   ],
   "source": [
    "run_naive_bayes(X_train_ridge, X_test_ridge, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
