{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2696, 106)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('image_bins_stats_lungs2.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transformed_image_normal_1.png</td>\n",
       "      <td>5822.0</td>\n",
       "      <td>14402.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9189.0</td>\n",
       "      <td>10538.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11831.0</td>\n",
       "      <td>13754.0</td>\n",
       "      <td>86.982480</td>\n",
       "      <td>...</td>\n",
       "      <td>30.9217012</td>\n",
       "      <td>27.556681</td>\n",
       "      <td>26.125116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.668177</td>\n",
       "      <td>19.678833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.325143</td>\n",
       "      <td>33.029938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transformed_image_normal_2.png</td>\n",
       "      <td>6325.0</td>\n",
       "      <td>11758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10893.0</td>\n",
       "      <td>13314.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8460.0</td>\n",
       "      <td>14786.0</td>\n",
       "      <td>86.937708</td>\n",
       "      <td>...</td>\n",
       "      <td>32.45653958</td>\n",
       "      <td>30.429971</td>\n",
       "      <td>21.410499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.701043</td>\n",
       "      <td>16.311605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.183742</td>\n",
       "      <td>36.344060</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transformed_image_normal_3.png</td>\n",
       "      <td>5911.0</td>\n",
       "      <td>15666.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9025.0</td>\n",
       "      <td>13587.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8205.0</td>\n",
       "      <td>13142.0</td>\n",
       "      <td>76.833362</td>\n",
       "      <td>...</td>\n",
       "      <td>32.04297751</td>\n",
       "      <td>31.149385</td>\n",
       "      <td>23.374875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.936013</td>\n",
       "      <td>17.187983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.580706</td>\n",
       "      <td>35.631835</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transformed_image_normal_4.png</td>\n",
       "      <td>5688.0</td>\n",
       "      <td>15515.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8941.0</td>\n",
       "      <td>10462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11009.0</td>\n",
       "      <td>13921.0</td>\n",
       "      <td>73.869726</td>\n",
       "      <td>...</td>\n",
       "      <td>29.69319943</td>\n",
       "      <td>31.537897</td>\n",
       "      <td>22.614153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.457708</td>\n",
       "      <td>15.659193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.081886</td>\n",
       "      <td>32.843335</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transformed_image_normal_5.png</td>\n",
       "      <td>6101.0</td>\n",
       "      <td>12231.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10258.0</td>\n",
       "      <td>14797.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7655.0</td>\n",
       "      <td>14494.0</td>\n",
       "      <td>87.165219</td>\n",
       "      <td>...</td>\n",
       "      <td>32.21430004</td>\n",
       "      <td>31.326113</td>\n",
       "      <td>21.152459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.285766</td>\n",
       "      <td>13.344069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.956341</td>\n",
       "      <td>36.139280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename   Bins0    Bins1  Bins2    Bins3    Bins4  \\\n",
       "0  transformed_image_normal_1.png  5822.0  14402.0    0.0   9189.0  10538.0   \n",
       "1  transformed_image_normal_2.png  6325.0  11758.0    0.0  10893.0  13314.0   \n",
       "2  transformed_image_normal_3.png  5911.0  15666.0    0.0   9025.0  13587.0   \n",
       "3  transformed_image_normal_4.png  5688.0  15515.0    0.0   8941.0  10462.0   \n",
       "4  transformed_image_normal_5.png  6101.0  12231.0    0.0  10258.0  14797.0   \n",
       "\n",
       "   Bins5    Bins6    Bins7  rmean_bins0  ...  bskew_bins7  bkurto_bins0  \\\n",
       "0    0.0  11831.0  13754.0    86.982480  ...   30.9217012     27.556681   \n",
       "1    0.0   8460.0  14786.0    86.937708  ...  32.45653958     30.429971   \n",
       "2    0.0   8205.0  13142.0    76.833362  ...  32.04297751     31.149385   \n",
       "3    0.0  11009.0  13921.0    73.869726  ...  29.69319943     31.537897   \n",
       "4    0.0   7655.0  14494.0    87.165219  ...  32.21430004     31.326113   \n",
       "\n",
       "   bkurto_bins1  bkurto_bins2  bkurto_bins3  bkurto_bins4  bkurto_bins5  \\\n",
       "0     26.125116           0.0     12.668177     19.678833           0.0   \n",
       "1     21.410499           0.0      9.701043     16.311605           0.0   \n",
       "2     23.374875           0.0     12.936013     17.187983           0.0   \n",
       "3     22.614153           0.0     11.457708     15.659193           0.0   \n",
       "4     21.152459           0.0     12.285766     13.344069           0.0   \n",
       "\n",
       "  bkurto_bins6 bkurto_bins7 class  \n",
       "0    42.325143    33.029938     1  \n",
       "1    41.183742    36.344060     1  \n",
       "2    45.580706    35.631835     1  \n",
       "3    42.081886    32.843335     1  \n",
       "4    42.956341    36.139280     1  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>rmean_bins1</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5822.0</td>\n",
       "      <td>14402.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9189.0</td>\n",
       "      <td>10538.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11831.0</td>\n",
       "      <td>13754.0</td>\n",
       "      <td>86.982480</td>\n",
       "      <td>4.430912</td>\n",
       "      <td>...</td>\n",
       "      <td>30.9217012</td>\n",
       "      <td>27.556681</td>\n",
       "      <td>26.125116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.668177</td>\n",
       "      <td>19.678833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.325143</td>\n",
       "      <td>33.029938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6325.0</td>\n",
       "      <td>11758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10893.0</td>\n",
       "      <td>13314.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8460.0</td>\n",
       "      <td>14786.0</td>\n",
       "      <td>86.937708</td>\n",
       "      <td>5.183279</td>\n",
       "      <td>...</td>\n",
       "      <td>32.45653958</td>\n",
       "      <td>30.429971</td>\n",
       "      <td>21.410499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.701043</td>\n",
       "      <td>16.311605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.183742</td>\n",
       "      <td>36.344060</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5911.0</td>\n",
       "      <td>15666.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9025.0</td>\n",
       "      <td>13587.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8205.0</td>\n",
       "      <td>13142.0</td>\n",
       "      <td>76.833362</td>\n",
       "      <td>2.389570</td>\n",
       "      <td>...</td>\n",
       "      <td>32.04297751</td>\n",
       "      <td>31.149385</td>\n",
       "      <td>23.374875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.936013</td>\n",
       "      <td>17.187983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.580706</td>\n",
       "      <td>35.631835</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5688.0</td>\n",
       "      <td>15515.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8941.0</td>\n",
       "      <td>10462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11009.0</td>\n",
       "      <td>13921.0</td>\n",
       "      <td>73.869726</td>\n",
       "      <td>1.710925</td>\n",
       "      <td>...</td>\n",
       "      <td>29.69319943</td>\n",
       "      <td>31.537897</td>\n",
       "      <td>22.614153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.457708</td>\n",
       "      <td>15.659193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.081886</td>\n",
       "      <td>32.843335</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6101.0</td>\n",
       "      <td>12231.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10258.0</td>\n",
       "      <td>14797.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7655.0</td>\n",
       "      <td>14494.0</td>\n",
       "      <td>87.165219</td>\n",
       "      <td>5.596517</td>\n",
       "      <td>...</td>\n",
       "      <td>32.21430004</td>\n",
       "      <td>31.326113</td>\n",
       "      <td>21.152459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.285766</td>\n",
       "      <td>13.344069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.956341</td>\n",
       "      <td>36.139280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Bins0    Bins1  Bins2    Bins3    Bins4  Bins5    Bins6    Bins7  \\\n",
       "0  5822.0  14402.0    0.0   9189.0  10538.0    0.0  11831.0  13754.0   \n",
       "1  6325.0  11758.0    0.0  10893.0  13314.0    0.0   8460.0  14786.0   \n",
       "2  5911.0  15666.0    0.0   9025.0  13587.0    0.0   8205.0  13142.0   \n",
       "3  5688.0  15515.0    0.0   8941.0  10462.0    0.0  11009.0  13921.0   \n",
       "4  6101.0  12231.0    0.0  10258.0  14797.0    0.0   7655.0  14494.0   \n",
       "\n",
       "   rmean_bins0  rmean_bins1  ...  bskew_bins7  bkurto_bins0  bkurto_bins1  \\\n",
       "0    86.982480     4.430912  ...   30.9217012     27.556681     26.125116   \n",
       "1    86.937708     5.183279  ...  32.45653958     30.429971     21.410499   \n",
       "2    76.833362     2.389570  ...  32.04297751     31.149385     23.374875   \n",
       "3    73.869726     1.710925  ...  29.69319943     31.537897     22.614153   \n",
       "4    87.165219     5.596517  ...  32.21430004     31.326113     21.152459   \n",
       "\n",
       "   bkurto_bins2  bkurto_bins3  bkurto_bins4 bkurto_bins5 bkurto_bins6  \\\n",
       "0           0.0     12.668177     19.678833          0.0    42.325143   \n",
       "1           0.0      9.701043     16.311605          0.0    41.183742   \n",
       "2           0.0     12.936013     17.187983          0.0    45.580706   \n",
       "3           0.0     11.457708     15.659193          0.0    42.081886   \n",
       "4           0.0     12.285766     13.344069          0.0    42.956341   \n",
       "\n",
       "  bkurto_bins7 class  \n",
       "0    33.029938     1  \n",
       "1    36.344060     1  \n",
       "2    35.631835     1  \n",
       "3    32.843335     1  \n",
       "4    36.139280     1  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['filename'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['rstd_bins0','rstd_bins1','rstd_bins2','rstd_bins3','rstd_bins4','rstd_bins5','rstd_bins6','rstd_bins7','rskew_bins0','rskew_bins1','rskew_bins2','rskew_bins3','rskew_bins4','rskew_bins5','rskew_bins6','rskew_bins7','gstd_bins0','gstd_bins1','gstd_bins2','gstd_bins3','gstd_bins4','gstd_bins5','gstd_bins6','gstd_bins7','bstd_bins0','bstd_bins1','bstd_bins2','bstd_bins3','bstd_bins4','bstd_bins5','bstd_bins6','bstd_bins7','gskew_bins0','gskew_bins1','gskew_bins2','gskew_bins3','gskew_bins4','gskew_bins5','gskew_bins6','gskew_bins7','bskew_bins0','bskew_bins1','bskew_bins2','bskew_bins3','bskew_bins4','bskew_bins5','bskew_bins6','bskew_bins7','class']\n",
    "for i in name:\n",
    "    data[i] = pd.to_numeric(data[i],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>rmean_bins1</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5822.0</td>\n",
       "      <td>14402.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9189.0</td>\n",
       "      <td>10538.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11831.0</td>\n",
       "      <td>13754.0</td>\n",
       "      <td>86.982480</td>\n",
       "      <td>4.430912</td>\n",
       "      <td>...</td>\n",
       "      <td>30.921701</td>\n",
       "      <td>27.556681</td>\n",
       "      <td>26.125116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.668177</td>\n",
       "      <td>19.678833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.325143</td>\n",
       "      <td>33.029938</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6325.0</td>\n",
       "      <td>11758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10893.0</td>\n",
       "      <td>13314.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8460.0</td>\n",
       "      <td>14786.0</td>\n",
       "      <td>86.937708</td>\n",
       "      <td>5.183279</td>\n",
       "      <td>...</td>\n",
       "      <td>32.456540</td>\n",
       "      <td>30.429971</td>\n",
       "      <td>21.410499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.701043</td>\n",
       "      <td>16.311605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.183742</td>\n",
       "      <td>36.344060</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5911.0</td>\n",
       "      <td>15666.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9025.0</td>\n",
       "      <td>13587.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8205.0</td>\n",
       "      <td>13142.0</td>\n",
       "      <td>76.833362</td>\n",
       "      <td>2.389570</td>\n",
       "      <td>...</td>\n",
       "      <td>32.042978</td>\n",
       "      <td>31.149385</td>\n",
       "      <td>23.374875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.936013</td>\n",
       "      <td>17.187983</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.580706</td>\n",
       "      <td>35.631835</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5688.0</td>\n",
       "      <td>15515.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8941.0</td>\n",
       "      <td>10462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11009.0</td>\n",
       "      <td>13921.0</td>\n",
       "      <td>73.869726</td>\n",
       "      <td>1.710925</td>\n",
       "      <td>...</td>\n",
       "      <td>29.693199</td>\n",
       "      <td>31.537897</td>\n",
       "      <td>22.614153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.457708</td>\n",
       "      <td>15.659193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.081886</td>\n",
       "      <td>32.843335</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6101.0</td>\n",
       "      <td>12231.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10258.0</td>\n",
       "      <td>14797.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7655.0</td>\n",
       "      <td>14494.0</td>\n",
       "      <td>87.165219</td>\n",
       "      <td>5.596517</td>\n",
       "      <td>...</td>\n",
       "      <td>32.214300</td>\n",
       "      <td>31.326113</td>\n",
       "      <td>21.152459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.285766</td>\n",
       "      <td>13.344069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.956341</td>\n",
       "      <td>36.139280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>9870.0</td>\n",
       "      <td>10436.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9558.0</td>\n",
       "      <td>9764.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16080.0</td>\n",
       "      <td>9815.0</td>\n",
       "      <td>104.708207</td>\n",
       "      <td>27.440974</td>\n",
       "      <td>...</td>\n",
       "      <td>28.826381</td>\n",
       "      <td>16.609479</td>\n",
       "      <td>32.541509</td>\n",
       "      <td>10.841782</td>\n",
       "      <td>18.263777</td>\n",
       "      <td>29.591836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.584547</td>\n",
       "      <td>43.219779</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>5946.0</td>\n",
       "      <td>14026.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11041.0</td>\n",
       "      <td>12415.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7886.0</td>\n",
       "      <td>14221.0</td>\n",
       "      <td>74.044736</td>\n",
       "      <td>1.607016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.246127</td>\n",
       "      <td>30.936390</td>\n",
       "      <td>21.337923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.706518</td>\n",
       "      <td>17.877323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.339391</td>\n",
       "      <td>32.611797</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>7330.0</td>\n",
       "      <td>8408.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10811.0</td>\n",
       "      <td>18521.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6699.0</td>\n",
       "      <td>13759.0</td>\n",
       "      <td>112.515416</td>\n",
       "      <td>7.136774</td>\n",
       "      <td>...</td>\n",
       "      <td>28.790502</td>\n",
       "      <td>42.515393</td>\n",
       "      <td>18.625921</td>\n",
       "      <td>11.891740</td>\n",
       "      <td>14.170267</td>\n",
       "      <td>3.991819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.311970</td>\n",
       "      <td>41.914116</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>7630.0</td>\n",
       "      <td>16431.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9530.0</td>\n",
       "      <td>3413.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17843.0</td>\n",
       "      <td>10685.0</td>\n",
       "      <td>73.122412</td>\n",
       "      <td>24.310145</td>\n",
       "      <td>...</td>\n",
       "      <td>37.426827</td>\n",
       "      <td>20.622111</td>\n",
       "      <td>29.148814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.197666</td>\n",
       "      <td>31.678731</td>\n",
       "      <td>4.769168</td>\n",
       "      <td>50.967873</td>\n",
       "      <td>38.781249</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>5415.0</td>\n",
       "      <td>17347.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8790.0</td>\n",
       "      <td>12865.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8924.0</td>\n",
       "      <td>12193.0</td>\n",
       "      <td>60.702862</td>\n",
       "      <td>1.042082</td>\n",
       "      <td>...</td>\n",
       "      <td>34.588816</td>\n",
       "      <td>33.378388</td>\n",
       "      <td>26.261638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.291031</td>\n",
       "      <td>20.163037</td>\n",
       "      <td>5.045378</td>\n",
       "      <td>45.099627</td>\n",
       "      <td>35.944590</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2683 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Bins0    Bins1  Bins2    Bins3    Bins4  Bins5    Bins6    Bins7  \\\n",
       "0     5822.0  14402.0    0.0   9189.0  10538.0    0.0  11831.0  13754.0   \n",
       "1     6325.0  11758.0    0.0  10893.0  13314.0    0.0   8460.0  14786.0   \n",
       "2     5911.0  15666.0    0.0   9025.0  13587.0    0.0   8205.0  13142.0   \n",
       "3     5688.0  15515.0    0.0   8941.0  10462.0    0.0  11009.0  13921.0   \n",
       "4     6101.0  12231.0    0.0  10258.0  14797.0    0.0   7655.0  14494.0   \n",
       "...      ...      ...    ...      ...      ...    ...      ...      ...   \n",
       "2689  9870.0  10436.0   13.0   9558.0   9764.0    0.0  16080.0   9815.0   \n",
       "2690  5946.0  14026.0    1.0  11041.0  12415.0    0.0   7886.0  14221.0   \n",
       "2691  7330.0   8408.0    6.0  10811.0  18521.0    2.0   6699.0  13759.0   \n",
       "2692  7630.0  16431.0    1.0   9530.0   3413.0    3.0  17843.0  10685.0   \n",
       "2693  5415.0  17347.0    0.0   8790.0  12865.0    2.0   8924.0  12193.0   \n",
       "\n",
       "      rmean_bins0  rmean_bins1  ...  bskew_bins7  bkurto_bins0  bkurto_bins1  \\\n",
       "0       86.982480     4.430912  ...    30.921701     27.556681     26.125116   \n",
       "1       86.937708     5.183279  ...    32.456540     30.429971     21.410499   \n",
       "2       76.833362     2.389570  ...    32.042978     31.149385     23.374875   \n",
       "3       73.869726     1.710925  ...    29.693199     31.537897     22.614153   \n",
       "4       87.165219     5.596517  ...    32.214300     31.326113     21.152459   \n",
       "...           ...          ...  ...          ...           ...           ...   \n",
       "2689   104.708207    27.440974  ...    28.826381     16.609479     32.541509   \n",
       "2690    74.044736     1.607016  ...    39.246127     30.936390     21.337923   \n",
       "2691   112.515416     7.136774  ...    28.790502     42.515393     18.625921   \n",
       "2692    73.122412    24.310145  ...    37.426827     20.622111     29.148814   \n",
       "2693    60.702862     1.042082  ...    34.588816     33.378388     26.261638   \n",
       "\n",
       "      bkurto_bins2  bkurto_bins3  bkurto_bins4  bkurto_bins5  bkurto_bins6  \\\n",
       "0         0.000000     12.668177     19.678833      0.000000     42.325143   \n",
       "1         0.000000      9.701043     16.311605      0.000000     41.183742   \n",
       "2         0.000000     12.936013     17.187983      0.000000     45.580706   \n",
       "3         0.000000     11.457708     15.659193      0.000000     42.081886   \n",
       "4         0.000000     12.285766     13.344069      0.000000     42.956341   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2689     10.841782     18.263777     29.591836      0.000000     43.584547   \n",
       "2690      0.000000      9.706518     17.877323      0.000000     45.339391   \n",
       "2691     11.891740     14.170267      3.991819      0.000000     36.311970   \n",
       "2692      0.000000     20.197666     31.678731      4.769168     50.967873   \n",
       "2693      0.000000     17.291031     20.163037      5.045378     45.099627   \n",
       "\n",
       "      bkurto_bins7  class  \n",
       "0        33.029938    1.0  \n",
       "1        36.344060    1.0  \n",
       "2        35.631835    1.0  \n",
       "3        32.843335    1.0  \n",
       "4        36.139280    1.0  \n",
       "...            ...    ...  \n",
       "2689     43.219779    2.0  \n",
       "2690     32.611797    2.0  \n",
       "2691     41.914116    2.0  \n",
       "2692     38.781249    2.0  \n",
       "2693     35.944590    2.0  \n",
       "\n",
       "[2683 rows x 105 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)\n",
    "\n",
    "clean_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1878, 104), (805, 104))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['class'], axis=1),\n",
    "    data['class'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5852377248540069,\n",
       " 0.5240471869328494,\n",
       " 0.66237638431053,\n",
       " 0.5300844475721322,\n",
       " 0.5405447115325259,\n",
       " 0.5312326382458611,\n",
       " 0.535945775769473,\n",
       " 0.5779041199056756,\n",
       " 0.5414830178895514,\n",
       " 0.5551810560884971]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine roc-auc for each feature\n",
    "\n",
    "# here we store the roc-auc values\n",
    "roc_values = []\n",
    "\n",
    "# iterate over each feature in the dataset\n",
    "for feature in X_train.columns:\n",
    "\n",
    "    # train a decision tree classifier\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train[feature].fillna(0).to_frame(), y_train)\n",
    "\n",
    "    # obtain the predictions\n",
    "    y_scored = clf.predict_proba(X_test[feature].to_frame())\n",
    "\n",
    "    # calculate and store the roc-auc\n",
    "    roc_values.append(roc_auc_score(y_test, y_scored[:, 1]))\n",
    "    \n",
    "# display the result\n",
    "roc_values[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'roc-auc')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now let's:\n",
    "\n",
    "# 1) capture the roc-auc values in a pandas series\n",
    "# 2) add the variable names in the index\n",
    "# 3) sort the features based on the roc-auc\n",
    "# 4) and make a var plot\n",
    "\n",
    "roc_values = pd.Series(roc_values)\n",
    "roc_values.index = X_train.columns\n",
    "roc_values.sort_values(ascending=False).plot.bar(figsize=(20, 5))\n",
    "plt.ylabel('roc-auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a roc auc value of 0.5 indicates random decision\n",
    "# let's check how many features show a roc-auc value\n",
    "# higher than random\n",
    "\n",
    "len(roc_values[roc_values > 0.57])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Bins2', 'gstd_bins0', 'gskew_bins0', 'gskew_bins1', 'gkurto_bins0',\n",
       "       'bstd_bins1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = roc_values[roc_values > 0.6].index\n",
    "\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1878, 6), (805, 6))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select features in the dataframes\n",
    "\n",
    "X_train = X_train[selected_features]\n",
    "X_test = X_test[selected_features]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build random forests and\n",
    "# compare its performance in train and test sets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = rf, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.8520002495349577\n",
      "Test set\n",
      "Random Forests roc-auc: 0.8484141387952641\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.76      0.79      0.77       406\n",
      "         2.0       0.78      0.75      0.76       399\n",
      "\n",
      "    accuracy                           0.77       805\n",
      "   macro avg       0.77      0.77      0.77       805\n",
      "weighted avg       0.77      0.77      0.77       805\n",
      "\n",
      "Confusion Matrix:\n",
      "[[320  86]\n",
      " [100 299]]\n",
      "Metrics:\n",
      "Accuracy: 0.769\n",
      "F1 Score: 0.775\n",
      "Precision: 0.762\n",
      "Recall: 0.788\n",
      "After Cross Validation:\n",
      "Accuracy: 74.23 %\n",
      "Standard Deviation: 3.27 %\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "run_randomForests(X_train,\n",
    "                  X_test,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def run_logistic(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    logit = LogisticRegression(penalty='l1', random_state=44, max_iter=1000, solver='liblinear')\n",
    "    logit.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = logit.predict_proba(scaler.transform(X_train))\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = logit.predict_proba(scaler.transform(X_test))\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = logit.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = logit, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.7557892110158341\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.7972147116559872\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.70      0.84      0.77       406\n",
      "         2.0       0.80      0.64      0.71       399\n",
      "\n",
      "    accuracy                           0.74       805\n",
      "   macro avg       0.75      0.74      0.74       805\n",
      "weighted avg       0.75      0.74      0.74       805\n",
      "\n",
      "Confusion Matrix:\n",
      "[[343  63]\n",
      " [145 254]]\n",
      "Metrics:\n",
      "Accuracy: 0.742\n",
      "F1 Score: 0.767\n",
      "Precision: 0.703\n",
      "Recall: 0.845\n",
      "After Cross Validation:\n",
      "Accuracy: 71.30 %\n",
      "Standard Deviation: 3.36 %\n"
     ]
    }
   ],
   "source": [
    "run_logistic(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run_kernel_SVM(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = SVC(kernel = 'rbf', random_state = 0, probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.7416292364230299\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.7821215600577798\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.73      0.85      0.78       406\n",
      "         2.0       0.82      0.67      0.74       399\n",
      "\n",
      "    accuracy                           0.76       805\n",
      "   macro avg       0.77      0.76      0.76       805\n",
      "weighted avg       0.77      0.76      0.76       805\n",
      "\n",
      "Confusion Matrix:\n",
      "[[346  60]\n",
      " [130 269]]\n",
      "Metrics:\n",
      "Accuracy: 0.764\n",
      "F1 Score: 0.785\n",
      "Precision: 0.727\n",
      "Recall: 0.852\n",
      "After Cross Validation:\n",
      "Accuracy: 72.95 %\n",
      "Standard Deviation: 3.25 %\n"
     ]
    }
   ],
   "source": [
    "run_kernel_SVM(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def run_knn(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('KNN roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('KNN roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "KNN roc-auc: 0.5805430788076766\n",
      "Test set\n",
      "KNN roc-auc: 0.5928861562773929\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.73      0.83      0.78       406\n",
      "         2.0       0.80      0.69      0.74       399\n",
      "\n",
      "    accuracy                           0.76       805\n",
      "   macro avg       0.76      0.76      0.76       805\n",
      "weighted avg       0.76      0.76      0.76       805\n",
      "\n",
      "Confusion Matrix:\n",
      "[[336  70]\n",
      " [125 274]]\n",
      "Metrics:\n",
      "Accuracy: 0.758\n",
      "F1 Score: 0.775\n",
      "Precision: 0.729\n",
      "Recall: 0.828\n",
      "After Cross Validation:\n",
      "Accuracy: 73.16 %\n",
      "Standard Deviation: 4.31 %\n"
     ]
    }
   ],
   "source": [
    "run_knn(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def run_decision_tree(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(X_train)\n",
    "    print('Decision Tree roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(X_test)\n",
    "    print('Decision Tree roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Decision Tree roc-auc: 1.0\n",
      "Test set\n",
      "Decision Tree roc-auc: 0.6782905539711347\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.68      0.67      0.68       406\n",
      "         2.0       0.67      0.68      0.68       399\n",
      "\n",
      "    accuracy                           0.68       805\n",
      "   macro avg       0.68      0.68      0.68       805\n",
      "weighted avg       0.68      0.68      0.68       805\n",
      "\n",
      "Confusion Matrix:\n",
      "[[274 132]\n",
      " [127 272]]\n",
      "Metrics:\n",
      "Accuracy: 0.678\n",
      "F1 Score: 0.679\n",
      "Precision: 0.683\n",
      "Recall: 0.675\n",
      "After Cross Validation:\n",
      "Accuracy: 65.87 %\n",
      "Standard Deviation: 2.84 %\n"
     ]
    }
   ],
   "source": [
    "run_decision_tree(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def run_naive_bayes(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.5\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.67      0.91      0.77       406\n",
      "         2.0       0.86      0.54      0.66       399\n",
      "\n",
      "    accuracy                           0.73       805\n",
      "   macro avg       0.76      0.72      0.71       805\n",
      "weighted avg       0.76      0.73      0.72       805\n",
      "\n",
      "Confusion Matrix:\n",
      "[[370  36]\n",
      " [185 214]]\n",
      "Metrics:\n",
      "Accuracy: 0.725\n",
      "F1 Score: 0.770\n",
      "Precision: 0.667\n",
      "Recall: 0.911\n",
      "After Cross Validation:\n",
      "Accuracy: 71.30 %\n",
      "Standard Deviation: 3.06 %\n"
     ]
    }
   ],
   "source": [
    "run_naive_bayes(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run_linear_SVM(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = SVC(kernel = 'linear', random_state = 0, probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.7594914023864616\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.8047149894440535\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.70      0.86      0.77       406\n",
      "         2.0       0.82      0.62      0.71       399\n",
      "\n",
      "    accuracy                           0.74       805\n",
      "   macro avg       0.76      0.74      0.74       805\n",
      "weighted avg       0.76      0.74      0.74       805\n",
      "\n",
      "Confusion Matrix:\n",
      "[[350  56]\n",
      " [151 248]]\n",
      "Metrics:\n",
      "Accuracy: 0.743\n",
      "F1 Score: 0.772\n",
      "Precision: 0.699\n",
      "Recall: 0.862\n",
      "After Cross Validation:\n",
      "Accuracy: 70.82 %\n",
      "Standard Deviation: 3.13 %\n"
     ]
    }
   ],
   "source": [
    "run_linear_SVM(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
