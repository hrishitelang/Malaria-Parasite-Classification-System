{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold, f_classif, SelectKBest\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2484, 106)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('image_bins_stats_lungs1.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transformed_image_covid_1.png</td>\n",
       "      <td>4722</td>\n",
       "      <td>15567</td>\n",
       "      <td>4</td>\n",
       "      <td>7683</td>\n",
       "      <td>12061</td>\n",
       "      <td>1</td>\n",
       "      <td>8864</td>\n",
       "      <td>16634</td>\n",
       "      <td>77.433079</td>\n",
       "      <td>...</td>\n",
       "      <td>29.26670025</td>\n",
       "      <td>39.092067</td>\n",
       "      <td>21.915792</td>\n",
       "      <td>15.564234</td>\n",
       "      <td>10.232452</td>\n",
       "      <td>12.530200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.674295</td>\n",
       "      <td>31.538221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transformed_image_covid_2.png</td>\n",
       "      <td>6556</td>\n",
       "      <td>13701</td>\n",
       "      <td>25</td>\n",
       "      <td>9956</td>\n",
       "      <td>9437</td>\n",
       "      <td>0</td>\n",
       "      <td>12114</td>\n",
       "      <td>13747</td>\n",
       "      <td>79.728951</td>\n",
       "      <td>...</td>\n",
       "      <td>33.53821958</td>\n",
       "      <td>28.281468</td>\n",
       "      <td>23.127681</td>\n",
       "      <td>11.979449</td>\n",
       "      <td>17.519198</td>\n",
       "      <td>24.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.506228</td>\n",
       "      <td>36.562100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transformed_image_covid_3.png</td>\n",
       "      <td>10512</td>\n",
       "      <td>12249</td>\n",
       "      <td>1</td>\n",
       "      <td>11502</td>\n",
       "      <td>7743</td>\n",
       "      <td>2</td>\n",
       "      <td>9619</td>\n",
       "      <td>13908</td>\n",
       "      <td>68.987348</td>\n",
       "      <td>...</td>\n",
       "      <td>25.22521593</td>\n",
       "      <td>26.681675</td>\n",
       "      <td>24.442798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.323460</td>\n",
       "      <td>38.083555</td>\n",
       "      <td>4.204482</td>\n",
       "      <td>55.658016</td>\n",
       "      <td>27.952446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transformed_image_covid_4.png</td>\n",
       "      <td>7987</td>\n",
       "      <td>11854</td>\n",
       "      <td>2</td>\n",
       "      <td>10419</td>\n",
       "      <td>11895</td>\n",
       "      <td>9</td>\n",
       "      <td>11931</td>\n",
       "      <td>11439</td>\n",
       "      <td>94.638788</td>\n",
       "      <td>...</td>\n",
       "      <td>34.51618537</td>\n",
       "      <td>24.056261</td>\n",
       "      <td>28.558353</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>13.800903</td>\n",
       "      <td>27.757483</td>\n",
       "      <td>33.449086</td>\n",
       "      <td>44.809595</td>\n",
       "      <td>37.884099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transformed_image_covid_5.png</td>\n",
       "      <td>7761</td>\n",
       "      <td>14159</td>\n",
       "      <td>4</td>\n",
       "      <td>10898</td>\n",
       "      <td>10560</td>\n",
       "      <td>9</td>\n",
       "      <td>9153</td>\n",
       "      <td>12992</td>\n",
       "      <td>68.762015</td>\n",
       "      <td>...</td>\n",
       "      <td>32.13721328</td>\n",
       "      <td>27.884767</td>\n",
       "      <td>23.329477</td>\n",
       "      <td>13.445587</td>\n",
       "      <td>16.742312</td>\n",
       "      <td>28.738945</td>\n",
       "      <td>26.135224</td>\n",
       "      <td>49.330295</td>\n",
       "      <td>35.162254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        filename  Bins0  Bins1  Bins2  Bins3  Bins4  Bins5  \\\n",
       "0  transformed_image_covid_1.png   4722  15567      4   7683  12061      1   \n",
       "1  transformed_image_covid_2.png   6556  13701     25   9956   9437      0   \n",
       "2  transformed_image_covid_3.png  10512  12249      1  11502   7743      2   \n",
       "3  transformed_image_covid_4.png   7987  11854      2  10419  11895      9   \n",
       "4  transformed_image_covid_5.png   7761  14159      4  10898  10560      9   \n",
       "\n",
       "   Bins6  Bins7  rmean_bins0  ...  bskew_bins7  bkurto_bins0  bkurto_bins1  \\\n",
       "0   8864  16634    77.433079  ...  29.26670025     39.092067     21.915792   \n",
       "1  12114  13747    79.728951  ...  33.53821958     28.281468     23.127681   \n",
       "2   9619  13908    68.987348  ...  25.22521593     26.681675     24.442798   \n",
       "3  11931  11439    94.638788  ...  34.51618537     24.056261     28.558353   \n",
       "4   9153  12992    68.762015  ...  32.13721328     27.884767     23.329477   \n",
       "\n",
       "   bkurto_bins2  bkurto_bins3  bkurto_bins4  bkurto_bins5 bkurto_bins6  \\\n",
       "0     15.564234     10.232452     12.530200      0.000000    40.674295   \n",
       "1     11.979449     17.519198     24.313131      0.000000    38.506228   \n",
       "2      0.000000     12.323460     38.083555      4.204482    55.658016   \n",
       "3      0.840896     13.800903     27.757483     33.449086    44.809595   \n",
       "4     13.445587     16.742312     28.738945     26.135224    49.330295   \n",
       "\n",
       "  bkurto_bins7 class  \n",
       "0    31.538221     0  \n",
       "1    36.562100     0  \n",
       "2    27.952446     0  \n",
       "3    37.884099     0  \n",
       "4    35.162254     0  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>rmean_bins1</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4722</td>\n",
       "      <td>15567</td>\n",
       "      <td>4</td>\n",
       "      <td>7683</td>\n",
       "      <td>12061</td>\n",
       "      <td>1</td>\n",
       "      <td>8864</td>\n",
       "      <td>16634</td>\n",
       "      <td>77.433079</td>\n",
       "      <td>0.202929</td>\n",
       "      <td>...</td>\n",
       "      <td>29.26670025</td>\n",
       "      <td>39.092067</td>\n",
       "      <td>21.915792</td>\n",
       "      <td>15.564234</td>\n",
       "      <td>10.232452</td>\n",
       "      <td>12.530200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.674295</td>\n",
       "      <td>31.538221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6556</td>\n",
       "      <td>13701</td>\n",
       "      <td>25</td>\n",
       "      <td>9956</td>\n",
       "      <td>9437</td>\n",
       "      <td>0</td>\n",
       "      <td>12114</td>\n",
       "      <td>13747</td>\n",
       "      <td>79.728951</td>\n",
       "      <td>5.447851</td>\n",
       "      <td>...</td>\n",
       "      <td>33.53821958</td>\n",
       "      <td>28.281468</td>\n",
       "      <td>23.127681</td>\n",
       "      <td>11.979449</td>\n",
       "      <td>17.519198</td>\n",
       "      <td>24.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.506228</td>\n",
       "      <td>36.562100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10512</td>\n",
       "      <td>12249</td>\n",
       "      <td>1</td>\n",
       "      <td>11502</td>\n",
       "      <td>7743</td>\n",
       "      <td>2</td>\n",
       "      <td>9619</td>\n",
       "      <td>13908</td>\n",
       "      <td>68.987348</td>\n",
       "      <td>36.388358</td>\n",
       "      <td>...</td>\n",
       "      <td>25.22521593</td>\n",
       "      <td>26.681675</td>\n",
       "      <td>24.442798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.323460</td>\n",
       "      <td>38.083555</td>\n",
       "      <td>4.204482</td>\n",
       "      <td>55.658016</td>\n",
       "      <td>27.952446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7987</td>\n",
       "      <td>11854</td>\n",
       "      <td>2</td>\n",
       "      <td>10419</td>\n",
       "      <td>11895</td>\n",
       "      <td>9</td>\n",
       "      <td>11931</td>\n",
       "      <td>11439</td>\n",
       "      <td>94.638788</td>\n",
       "      <td>15.529948</td>\n",
       "      <td>...</td>\n",
       "      <td>34.51618537</td>\n",
       "      <td>24.056261</td>\n",
       "      <td>28.558353</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>13.800903</td>\n",
       "      <td>27.757483</td>\n",
       "      <td>33.449086</td>\n",
       "      <td>44.809595</td>\n",
       "      <td>37.884099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7761</td>\n",
       "      <td>14159</td>\n",
       "      <td>4</td>\n",
       "      <td>10898</td>\n",
       "      <td>10560</td>\n",
       "      <td>9</td>\n",
       "      <td>9153</td>\n",
       "      <td>12992</td>\n",
       "      <td>68.762015</td>\n",
       "      <td>4.809379</td>\n",
       "      <td>...</td>\n",
       "      <td>32.13721328</td>\n",
       "      <td>27.884767</td>\n",
       "      <td>23.329477</td>\n",
       "      <td>13.445587</td>\n",
       "      <td>16.742312</td>\n",
       "      <td>28.738945</td>\n",
       "      <td>26.135224</td>\n",
       "      <td>49.330295</td>\n",
       "      <td>35.162254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bins0  Bins1  Bins2  Bins3  Bins4  Bins5  Bins6  Bins7  rmean_bins0  \\\n",
       "0   4722  15567      4   7683  12061      1   8864  16634    77.433079   \n",
       "1   6556  13701     25   9956   9437      0  12114  13747    79.728951   \n",
       "2  10512  12249      1  11502   7743      2   9619  13908    68.987348   \n",
       "3   7987  11854      2  10419  11895      9  11931  11439    94.638788   \n",
       "4   7761  14159      4  10898  10560      9   9153  12992    68.762015   \n",
       "\n",
       "   rmean_bins1  ...  bskew_bins7  bkurto_bins0  bkurto_bins1  bkurto_bins2  \\\n",
       "0     0.202929  ...  29.26670025     39.092067     21.915792     15.564234   \n",
       "1     5.447851  ...  33.53821958     28.281468     23.127681     11.979449   \n",
       "2    36.388358  ...  25.22521593     26.681675     24.442798      0.000000   \n",
       "3    15.529948  ...  34.51618537     24.056261     28.558353      0.840896   \n",
       "4     4.809379  ...  32.13721328     27.884767     23.329477     13.445587   \n",
       "\n",
       "   bkurto_bins3  bkurto_bins4 bkurto_bins5 bkurto_bins6 bkurto_bins7 class  \n",
       "0     10.232452     12.530200     0.000000    40.674295    31.538221     0  \n",
       "1     17.519198     24.313131     0.000000    38.506228    36.562100     0  \n",
       "2     12.323460     38.083555     4.204482    55.658016    27.952446     0  \n",
       "3     13.800903     27.757483    33.449086    44.809595    37.884099     0  \n",
       "4     16.742312     28.738945    26.135224    49.330295    35.162254     0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['filename'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['rstd_bins0','rstd_bins1','rstd_bins2','rstd_bins3','rstd_bins4','rstd_bins5','rstd_bins6','rstd_bins7','gstd_bins0','gstd_bins1','gstd_bins2','gstd_bins3','gstd_bins4','gstd_bins5','gstd_bins6','gstd_bins7','bstd_bins0','bstd_bins1','bstd_bins2','bstd_bins3','bstd_bins4','bstd_bins5','bstd_bins6','bstd_bins7','gskew_bins0','gskew_bins1','gskew_bins2','gskew_bins3','gskew_bins4','gskew_bins5','gskew_bins6','gskew_bins7','bskew_bins0','bskew_bins1','bskew_bins2','bskew_bins3','bskew_bins4','bskew_bins5','bskew_bins6','bskew_bins7','class']\n",
    "for i in name:\n",
    "    data[i] = pd.to_numeric(data[i],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>rmean_bins1</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4722.0</td>\n",
       "      <td>15567.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7683.0</td>\n",
       "      <td>12061.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8864.0</td>\n",
       "      <td>16634.0</td>\n",
       "      <td>77.433079</td>\n",
       "      <td>0.202929</td>\n",
       "      <td>...</td>\n",
       "      <td>29.266700</td>\n",
       "      <td>39.092067</td>\n",
       "      <td>21.915792</td>\n",
       "      <td>15.564234</td>\n",
       "      <td>10.232452</td>\n",
       "      <td>12.530200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.674295</td>\n",
       "      <td>31.538221</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6556.0</td>\n",
       "      <td>13701.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9956.0</td>\n",
       "      <td>9437.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12114.0</td>\n",
       "      <td>13747.0</td>\n",
       "      <td>79.728951</td>\n",
       "      <td>5.447851</td>\n",
       "      <td>...</td>\n",
       "      <td>33.538220</td>\n",
       "      <td>28.281468</td>\n",
       "      <td>23.127681</td>\n",
       "      <td>11.979449</td>\n",
       "      <td>17.519198</td>\n",
       "      <td>24.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.506228</td>\n",
       "      <td>36.562100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10512.0</td>\n",
       "      <td>12249.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11502.0</td>\n",
       "      <td>7743.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9619.0</td>\n",
       "      <td>13908.0</td>\n",
       "      <td>68.987348</td>\n",
       "      <td>36.388358</td>\n",
       "      <td>...</td>\n",
       "      <td>25.225216</td>\n",
       "      <td>26.681675</td>\n",
       "      <td>24.442798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.323460</td>\n",
       "      <td>38.083555</td>\n",
       "      <td>4.204482</td>\n",
       "      <td>55.658016</td>\n",
       "      <td>27.952446</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7987.0</td>\n",
       "      <td>11854.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10419.0</td>\n",
       "      <td>11895.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11931.0</td>\n",
       "      <td>11439.0</td>\n",
       "      <td>94.638788</td>\n",
       "      <td>15.529948</td>\n",
       "      <td>...</td>\n",
       "      <td>34.516185</td>\n",
       "      <td>24.056261</td>\n",
       "      <td>28.558353</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>13.800903</td>\n",
       "      <td>27.757483</td>\n",
       "      <td>33.449086</td>\n",
       "      <td>44.809595</td>\n",
       "      <td>37.884099</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7761.0</td>\n",
       "      <td>14159.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10898.0</td>\n",
       "      <td>10560.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9153.0</td>\n",
       "      <td>12992.0</td>\n",
       "      <td>68.762015</td>\n",
       "      <td>4.809379</td>\n",
       "      <td>...</td>\n",
       "      <td>32.137213</td>\n",
       "      <td>27.884767</td>\n",
       "      <td>23.329477</td>\n",
       "      <td>13.445587</td>\n",
       "      <td>16.742312</td>\n",
       "      <td>28.738945</td>\n",
       "      <td>26.135224</td>\n",
       "      <td>49.330295</td>\n",
       "      <td>35.162254</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>4950.0</td>\n",
       "      <td>16941.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9161.0</td>\n",
       "      <td>12953.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8179.0</td>\n",
       "      <td>13352.0</td>\n",
       "      <td>59.237576</td>\n",
       "      <td>0.162269</td>\n",
       "      <td>...</td>\n",
       "      <td>25.786782</td>\n",
       "      <td>40.580961</td>\n",
       "      <td>22.391613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.716628</td>\n",
       "      <td>15.733760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.642531</td>\n",
       "      <td>33.442984</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>6149.0</td>\n",
       "      <td>11217.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10795.0</td>\n",
       "      <td>14813.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7335.0</td>\n",
       "      <td>15226.0</td>\n",
       "      <td>89.067328</td>\n",
       "      <td>2.286262</td>\n",
       "      <td>...</td>\n",
       "      <td>30.321740</td>\n",
       "      <td>38.459722</td>\n",
       "      <td>19.856163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.773049</td>\n",
       "      <td>11.227728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.091211</td>\n",
       "      <td>34.380787</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>8157.0</td>\n",
       "      <td>8955.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8384.0</td>\n",
       "      <td>14395.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8516.0</td>\n",
       "      <td>17126.0</td>\n",
       "      <td>110.959421</td>\n",
       "      <td>12.390955</td>\n",
       "      <td>...</td>\n",
       "      <td>30.361398</td>\n",
       "      <td>40.138990</td>\n",
       "      <td>24.611149</td>\n",
       "      <td>8.738112</td>\n",
       "      <td>13.053664</td>\n",
       "      <td>9.750293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.766410</td>\n",
       "      <td>38.228325</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>6614.0</td>\n",
       "      <td>11508.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10639.0</td>\n",
       "      <td>14738.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7195.0</td>\n",
       "      <td>14839.0</td>\n",
       "      <td>90.745086</td>\n",
       "      <td>4.628172</td>\n",
       "      <td>...</td>\n",
       "      <td>35.209322</td>\n",
       "      <td>29.755901</td>\n",
       "      <td>22.888434</td>\n",
       "      <td>14.582557</td>\n",
       "      <td>13.300365</td>\n",
       "      <td>13.399057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.964578</td>\n",
       "      <td>34.453684</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>6026.0</td>\n",
       "      <td>14923.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11764.0</td>\n",
       "      <td>9530.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6751.0</td>\n",
       "      <td>16540.0</td>\n",
       "      <td>50.459177</td>\n",
       "      <td>3.036186</td>\n",
       "      <td>...</td>\n",
       "      <td>30.498729</td>\n",
       "      <td>34.411057</td>\n",
       "      <td>11.863055</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>9.137053</td>\n",
       "      <td>17.018301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.159898</td>\n",
       "      <td>29.685276</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2476 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bins0    Bins1  Bins2    Bins3    Bins4  Bins5    Bins6    Bins7  \\\n",
       "0      4722.0  15567.0    4.0   7683.0  12061.0    1.0   8864.0  16634.0   \n",
       "1      6556.0  13701.0   25.0   9956.0   9437.0    0.0  12114.0  13747.0   \n",
       "2     10512.0  12249.0    1.0  11502.0   7743.0    2.0   9619.0  13908.0   \n",
       "3      7987.0  11854.0    2.0  10419.0  11895.0    9.0  11931.0  11439.0   \n",
       "4      7761.0  14159.0    4.0  10898.0  10560.0    9.0   9153.0  12992.0   \n",
       "...       ...      ...    ...      ...      ...    ...      ...      ...   \n",
       "2479   4950.0  16941.0    0.0   9161.0  12953.0    0.0   8179.0  13352.0   \n",
       "2480   6149.0  11217.0    1.0  10795.0  14813.0    0.0   7335.0  15226.0   \n",
       "2481   8157.0   8955.0    3.0   8384.0  14395.0    0.0   8516.0  17126.0   \n",
       "2482   6614.0  11508.0    3.0  10639.0  14738.0    0.0   7195.0  14839.0   \n",
       "2483   6026.0  14923.0    2.0  11764.0   9530.0    0.0   6751.0  16540.0   \n",
       "\n",
       "      rmean_bins0  rmean_bins1  ...  bskew_bins7  bkurto_bins0  bkurto_bins1  \\\n",
       "0       77.433079     0.202929  ...    29.266700     39.092067     21.915792   \n",
       "1       79.728951     5.447851  ...    33.538220     28.281468     23.127681   \n",
       "2       68.987348    36.388358  ...    25.225216     26.681675     24.442798   \n",
       "3       94.638788    15.529948  ...    34.516185     24.056261     28.558353   \n",
       "4       68.762015     4.809379  ...    32.137213     27.884767     23.329477   \n",
       "...           ...          ...  ...          ...           ...           ...   \n",
       "2479    59.237576     0.162269  ...    25.786782     40.580961     22.391613   \n",
       "2480    89.067328     2.286262  ...    30.321740     38.459722     19.856163   \n",
       "2481   110.959421    12.390955  ...    30.361398     40.138990     24.611149   \n",
       "2482    90.745086     4.628172  ...    35.209322     29.755901     22.888434   \n",
       "2483    50.459177     3.036186  ...    30.498729     34.411057     11.863055   \n",
       "\n",
       "      bkurto_bins2  bkurto_bins3  bkurto_bins4  bkurto_bins5  bkurto_bins6  \\\n",
       "0        15.564234     10.232452     12.530200      0.000000     40.674295   \n",
       "1        11.979449     17.519198     24.313131      0.000000     38.506228   \n",
       "2         0.000000     12.323460     38.083555      4.204482     55.658016   \n",
       "3         0.840896     13.800903     27.757483     33.449086     44.809595   \n",
       "4        13.445587     16.742312     28.738945     26.135224     49.330295   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2479      0.000000      6.716628     15.733760      0.000000     45.642531   \n",
       "2480      0.000000      7.773049     11.227728      0.000000     40.091211   \n",
       "2481      8.738112     13.053664      9.750293      0.000000     32.766410   \n",
       "2482     14.582557     13.300365     13.399057      0.000000     41.964578   \n",
       "2483      0.840896      9.137053     17.018301      0.000000     42.159898   \n",
       "\n",
       "      bkurto_bins7  class  \n",
       "0        31.538221    0.0  \n",
       "1        36.562100    0.0  \n",
       "2        27.952446    0.0  \n",
       "3        37.884099    0.0  \n",
       "4        35.162254    0.0  \n",
       "...            ...    ...  \n",
       "2479     33.442984    1.0  \n",
       "2480     34.380787    1.0  \n",
       "2481     38.228325    1.0  \n",
       "2482     34.453684    1.0  \n",
       "2483     29.685276    1.0  \n",
       "\n",
       "[2476 rows x 105 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)\n",
    "\n",
    "clean_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1733, 104), (743, 104))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['class'], axis=1),\n",
    "    data['class'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.78393493e+02, 1.01513697e+01, 4.88574811e+01, 6.61234379e+00,\n",
       "        5.25160133e+02, 2.46638927e+01, 1.05918506e+01, 2.26045880e+01,\n",
       "        4.52130422e+01, 1.18244288e+02, 1.05100483e+02, 5.52099145e+01,\n",
       "        3.34785117e+02, 3.01654715e+02, 2.53701614e+00, 9.98255610e+01,\n",
       "        8.97913730e+01, 5.89120021e+00, 2.79788679e+02, 6.39555554e+01,\n",
       "        5.62911363e-01, 1.98179370e+02, 5.77484367e+02, 2.84998651e+01,\n",
       "        1.14781781e+02, 9.12899173e+00, 2.83523940e+02, 5.17879774e+01,\n",
       "        2.14036394e+00, 1.98657185e+02, 6.14782321e+02, 4.87517893e+01,\n",
       "        1.77577549e+02, 1.26552441e+01, 2.85544338e+02, 4.47470867e+01,\n",
       "        6.50685574e+00, 1.97089345e+02, 5.09967445e+02, 7.03993663e+01,\n",
       "        3.32141761e+02, 1.56174638e+02, 1.53401928e+02, 2.25915637e+02,\n",
       "        2.94692486e+02, 6.05682275e+01, 3.21723166e+01, 6.68773558e+01,\n",
       "        6.04353185e+02, 2.38869175e+02, 2.57891188e+02, 4.37268404e+01,\n",
       "        1.93672020e+01, 1.15263005e+02, 6.35308010e+01, 1.47104916e+02,\n",
       "        4.42449296e+02, 1.77379544e+02, 2.61399212e+02, 3.75248640e+01,\n",
       "        1.45144147e+01, 1.35473521e+02, 8.00691155e+01, 2.04851626e+02,\n",
       "        2.90905805e+02, 1.27202878e+02, 2.60888825e+02, 3.33175818e+01,\n",
       "        1.06643910e+01, 1.34278231e+02, 9.89534939e+01, 2.41834740e+02,\n",
       "        1.79814024e+01, 2.30656879e+01, 1.84903268e+02, 2.60423608e+01,\n",
       "        1.84103539e+02, 3.18002058e+02, 1.44256840e+02, 1.61049562e+01,\n",
       "        3.98855263e+01, 3.31256244e+01, 2.31752069e+02, 3.86551910e+02,\n",
       "        6.12825579e+01, 1.80405642e+02, 9.75844235e-04, 1.76162414e+01,\n",
       "        3.68645444e+01, 2.94285967e+01, 2.25203614e+02, 3.15214552e+02,\n",
       "        8.80318407e+01, 1.84957234e+02, 1.80985829e+00, 1.74590142e+01,\n",
       "        4.62582977e+01, 3.03519745e+01, 2.26073349e+02, 2.21528955e+02,\n",
       "        1.01069170e+02, 1.83982538e+02, 5.73087656e+00, 2.63999553e+01]),\n",
       " array([4.50556536e-058, 1.46764715e-003, 3.91460054e-012, 1.02102503e-002,\n",
       "        1.00668002e-101, 7.49773522e-007, 1.15778423e-003, 2.15484787e-006,\n",
       "        2.39260888e-011, 1.09345101e-026, 5.54089765e-024, 1.69314218e-013,\n",
       "        1.64634909e-068, 2.05416611e-062, 1.11387337e-001, 6.84465563e-023,\n",
       "        8.36485093e-021, 1.53181718e-002, 2.46561917e-058, 2.30629682e-015,\n",
       "        4.53191548e-001, 1.07360113e-042, 2.34164849e-110, 1.06085011e-007,\n",
       "        5.61302657e-026, 2.55277777e-003, 4.91897887e-059, 9.17238282e-013,\n",
       "        1.43649395e-001, 8.65551617e-043, 2.16226708e-116, 4.12523422e-012,\n",
       "        1.22391507e-038, 3.84599347e-004, 2.05955094e-059, 3.01711766e-011,\n",
       "        1.08313375e-002, 1.75528219e-042, 3.52756269e-099, 9.91846121e-017,\n",
       "        5.00308074e-068, 2.24823748e-034, 8.09152640e-034, 4.36615319e-048,\n",
       "        4.04207556e-061, 1.21333464e-014, 1.65030277e-008, 5.52696564e-016,\n",
       "        1.02921908e-114, 1.41132187e-050, 3.33365933e-054, 5.01527348e-011,\n",
       "        1.14424278e-005, 4.47069322e-026, 2.83940290e-015, 1.49436661e-032,\n",
       "        1.17653686e-087, 1.33957206e-038, 7.21094777e-055, 1.11465972e-009,\n",
       "        1.43950520e-004, 3.35647179e-030, 9.07932963e-019, 5.32954951e-044,\n",
       "        2.05253750e-060, 1.61320883e-028, 9.00863442e-055, 9.25636094e-009,\n",
       "        1.11351642e-003, 5.86722654e-030, 1.03800957e-022, 3.81807570e-051,\n",
       "        2.34849923e-005, 1.70053332e-006, 4.36423836e-040, 3.70739234e-007,\n",
       "        6.27597032e-040, 1.95930120e-065, 5.60738279e-032, 6.24827738e-005,\n",
       "        3.41502105e-010, 1.01977266e-008, 3.27995713e-049, 7.72067824e-078,\n",
       "        8.54589451e-015, 3.37377958e-039, 9.75082933e-001, 2.83980287e-005,\n",
       "        1.55275531e-009, 6.62012760e-008, 5.99085612e-048, 6.38868376e-065,\n",
       "        1.94924029e-020, 4.25857468e-040, 1.78701435e-001, 3.08203909e-005,\n",
       "        1.42266002e-011, 4.14528042e-008, 4.07074892e-048, 3.07161244e-047,\n",
       "        3.78117100e-023, 6.63068439e-040, 1.67750347e-002, 3.08923578e-007]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the univariate statistical measure between\n",
    "# each of the variables and the target\n",
    "\n",
    "# similarly to chi2, the output is one array with f-scores\n",
    "# and one array with the pvalues\n",
    "\n",
    "univariate = f_classif(X_train, y_train)\n",
    "\n",
    "univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2d14057ad90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) let's capture the pvalues in a pandas series\n",
    "# 2) add the variable names in the index\n",
    "# 3) sort the features based on their anova pvalues\n",
    "# 4) and make a var plot\n",
    "\n",
    "univariate = pd.Series(univariate[1])\n",
    "univariate.index = X_train.columns\n",
    "univariate.sort_values(ascending=False).plot.bar(figsize=(20, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Bins0', 'Bins4', 'rmean_bins4', 'rmean_bins5', 'rstd_bins2',\n",
       "       'rstd_bins6', 'rskew_bins2', 'rskew_bins6', 'rkurto_bins2',\n",
       "       'rkurto_bins6', 'gmean_bins0', 'gmean_bins4', 'gstd_bins0',\n",
       "       'gskew_bins0', 'gskew_bins2', 'gkurto_bins0', 'gkurto_bins2',\n",
       "       'bmean_bins5', 'bstd_bins3', 'bskew_bins3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the top 10 features\n",
    "sel_ = SelectKBest(f_classif, k=20).fit(X_train, y_train)\n",
    "\n",
    "# display selected feature names\n",
    "X_train.columns[sel_.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I keep a copy of the dataset with all the variables\n",
    "# to compare the performance of machine learning models\n",
    "# at the end of the notebook\n",
    "\n",
    "X_train_original = X_train.copy()\n",
    "X_test_original = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlated features:  39\n"
     ]
    }
   ],
   "source": [
    "# find and remove correlated features\n",
    "def correlation(dataset, threshold):\n",
    "    \n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    \n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            # we are interested in absolute coeff value\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    \n",
    "    return col_corr\n",
    "\n",
    "\n",
    "corr_features = correlation(X_train, 0.8)\n",
    "print('correlated features: ', len(set(corr_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1733, 65), (743, 65))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove correlated features\n",
    "X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep a copy of the dataset at  this stage\n",
    "X_train_corr = X_train.copy()\n",
    "X_test_corr = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1733, 20), (743, 20))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_ = SelectKBest(f_classif, k=20).fit(X_train, y_train)\n",
    "\n",
    "# capture selected feature names\n",
    "features_to_keep = X_train.columns[sel_.get_support()]\n",
    "\n",
    "# select features\n",
    "X_train_anova = sel_.transform(X_train)\n",
    "X_test_anova = sel_.transform(X_test)\n",
    "\n",
    "# numpy array to dataframe\n",
    "X_train_anova = pd.DataFrame(X_train_anova)\n",
    "X_train_anova.columns = features_to_keep\n",
    "\n",
    "X_test_anova = pd.DataFrame(X_test_anova)\n",
    "X_test_anova.columns = features_to_keep\n",
    "\n",
    "X_train_anova.shape, X_test_anova.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build random forests and\n",
    "# compare its performance in train and test sets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = rf, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.9855457266735572\n",
      "Test set\n",
      "Random Forests roc-auc: 0.9705852417302799\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.89      0.91       350\n",
      "         1.0       0.91      0.94      0.92       393\n",
      "\n",
      "    accuracy                           0.92       743\n",
      "   macro avg       0.92      0.92      0.92       743\n",
      "weighted avg       0.92      0.92      0.92       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[313  37]\n",
      " [ 23 370]]\n",
      "Metrics:\n",
      "Accuracy: 0.919\n",
      "F1 Score: 0.925\n",
      "Precision: 0.909\n",
      "Recall: 0.941\n",
      "After Cross Validation:\n",
      "Accuracy: 90.71 %\n",
      "Standard Deviation: 1.86 %\n"
     ]
    }
   ],
   "source": [
    "run_randomForests(X_train_original,\n",
    "                  X_test_original,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.9823952642388285\n",
      "Test set\n",
      "Random Forests roc-auc: 0.9665648854961832\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.89      0.91       350\n",
      "         1.0       0.90      0.95      0.93       393\n",
      "\n",
      "    accuracy                           0.92       743\n",
      "   macro avg       0.92      0.92      0.92       743\n",
      "weighted avg       0.92      0.92      0.92       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[310  40]\n",
      " [ 19 374]]\n",
      "Metrics:\n",
      "Accuracy: 0.921\n",
      "F1 Score: 0.927\n",
      "Precision: 0.903\n",
      "Recall: 0.952\n",
      "After Cross Validation:\n",
      "Accuracy: 91.17 %\n",
      "Standard Deviation: 2.09 %\n"
     ]
    }
   ],
   "source": [
    "# filter methods - univariate roc-auc\n",
    "run_randomForests(X_train_anova,\n",
    "                  X_test_anova,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def run_logistic(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    logit = LogisticRegression(penalty='l1', random_state=44, max_iter=1000, solver='liblinear')\n",
    "    logit.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = logit.predict_proba(scaler.transform(X_train))\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = logit.predict_proba(scaler.transform(X_test))\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = logit.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = logit, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.9812435400083224\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.9738131588513268\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.95      0.96       350\n",
      "         1.0       0.96      0.98      0.97       393\n",
      "\n",
      "    accuracy                           0.97       743\n",
      "   macro avg       0.97      0.97      0.97       743\n",
      "weighted avg       0.97      0.97      0.97       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[334  16]\n",
      " [  9 384]]\n",
      "Metrics:\n",
      "Accuracy: 0.966\n",
      "F1 Score: 0.968\n",
      "Precision: 0.960\n",
      "Recall: 0.977\n",
      "After Cross Validation:\n",
      "Accuracy: 95.85 %\n",
      "Standard Deviation: 1.33 %\n"
     ]
    }
   ],
   "source": [
    "run_logistic(X_train_original,\n",
    "                  X_test_original,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.9567150355047854\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.9553326063249727\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.87      0.90       350\n",
      "         1.0       0.89      0.94      0.91       393\n",
      "\n",
      "    accuracy                           0.91       743\n",
      "   macro avg       0.91      0.90      0.91       743\n",
      "weighted avg       0.91      0.91      0.91       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[304  46]\n",
      " [ 24 369]]\n",
      "Metrics:\n",
      "Accuracy: 0.906\n",
      "F1 Score: 0.913\n",
      "Precision: 0.889\n",
      "Recall: 0.939\n",
      "After Cross Validation:\n",
      "Accuracy: 90.02 %\n",
      "Standard Deviation: 1.82 %\n"
     ]
    }
   ],
   "source": [
    "run_logistic(X_train_anova,\n",
    "                  X_test_anova,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run_kernel_SVM(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = SVC(kernel = 'rbf', random_state = 0, probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.8879471656576775\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.894729189385678\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.74      0.80       350\n",
      "         1.0       0.79      0.90      0.84       393\n",
      "\n",
      "    accuracy                           0.82       743\n",
      "   macro avg       0.83      0.82      0.82       743\n",
      "weighted avg       0.83      0.82      0.82       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[258  92]\n",
      " [ 41 352]]\n",
      "Metrics:\n",
      "Accuracy: 0.821\n",
      "F1 Score: 0.841\n",
      "Precision: 0.793\n",
      "Recall: 0.896\n",
      "After Cross Validation:\n",
      "Accuracy: 79.92 %\n",
      "Standard Deviation: 3.75 %\n"
     ]
    }
   ],
   "source": [
    "run_kernel_SVM(X_train_original,\n",
    "                  X_test_original,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.9120716270453844\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.9045583424209379\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.66      0.72       350\n",
      "         1.0       0.73      0.84      0.78       393\n",
      "\n",
      "    accuracy                           0.76       743\n",
      "   macro avg       0.76      0.75      0.75       743\n",
      "weighted avg       0.76      0.76      0.75       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[230 120]\n",
      " [ 62 331]]\n",
      "Metrics:\n",
      "Accuracy: 0.755\n",
      "F1 Score: 0.784\n",
      "Precision: 0.734\n",
      "Recall: 0.842\n",
      "After Cross Validation:\n",
      "Accuracy: 74.96 %\n",
      "Standard Deviation: 2.77 %\n"
     ]
    }
   ],
   "source": [
    "run_kernel_SVM(X_train_anova,\n",
    "                  X_test_anova,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def run_knn(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('KNN roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('KNN roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "KNN roc-auc: 0.5\n",
      "Test set\n",
      "KNN roc-auc: 0.5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.81      0.86       350\n",
      "         1.0       0.85      0.93      0.89       393\n",
      "\n",
      "    accuracy                           0.88       743\n",
      "   macro avg       0.88      0.87      0.88       743\n",
      "weighted avg       0.88      0.88      0.88       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[285  65]\n",
      " [ 26 367]]\n",
      "Metrics:\n",
      "Accuracy: 0.878\n",
      "F1 Score: 0.890\n",
      "Precision: 0.850\n",
      "Recall: 0.934\n",
      "After Cross Validation:\n",
      "Accuracy: 86.38 %\n",
      "Standard Deviation: 2.55 %\n"
     ]
    }
   ],
   "source": [
    "run_knn(X_train_original,\n",
    "                  X_test_original,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "KNN roc-auc: 0.5\n",
      "Test set\n",
      "KNN roc-auc: 0.5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.74      0.77       350\n",
      "         1.0       0.78      0.83      0.81       393\n",
      "\n",
      "    accuracy                           0.79       743\n",
      "   macro avg       0.79      0.79      0.79       743\n",
      "weighted avg       0.79      0.79      0.79       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[259  91]\n",
      " [ 65 328]]\n",
      "Metrics:\n",
      "Accuracy: 0.790\n",
      "F1 Score: 0.808\n",
      "Precision: 0.783\n",
      "Recall: 0.835\n",
      "After Cross Validation:\n",
      "Accuracy: 78.76 %\n",
      "Standard Deviation: 2.80 %\n"
     ]
    }
   ],
   "source": [
    "run_knn(X_train_anova,\n",
    "                  X_test_anova,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def run_decision_tree(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(X_train)\n",
    "    print('Decision Tree roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(X_test)\n",
    "    print('Decision Tree roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Decision Tree roc-auc: 1.0\n",
      "Test set\n",
      "Decision Tree roc-auc: 0.8837295528898582\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.85      0.88       350\n",
      "         1.0       0.87      0.92      0.89       393\n",
      "\n",
      "    accuracy                           0.89       743\n",
      "   macro avg       0.89      0.88      0.88       743\n",
      "weighted avg       0.89      0.89      0.89       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[298  52]\n",
      " [ 33 360]]\n",
      "Metrics:\n",
      "Accuracy: 0.886\n",
      "F1 Score: 0.894\n",
      "Precision: 0.874\n",
      "Recall: 0.916\n",
      "After Cross Validation:\n",
      "Accuracy: 89.85 %\n",
      "Standard Deviation: 0.96 %\n"
     ]
    }
   ],
   "source": [
    "run_decision_tree(X_train_original,\n",
    "                  X_test_original,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Decision Tree roc-auc: 1.0\n",
      "Test set\n",
      "Decision Tree roc-auc: 0.8778371501272265\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.86      0.87       350\n",
      "         1.0       0.88      0.90      0.89       393\n",
      "\n",
      "    accuracy                           0.88       743\n",
      "   macro avg       0.88      0.88      0.88       743\n",
      "weighted avg       0.88      0.88      0.88       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[301  49]\n",
      " [ 41 352]]\n",
      "Metrics:\n",
      "Accuracy: 0.879\n",
      "F1 Score: 0.887\n",
      "Precision: 0.878\n",
      "Recall: 0.896\n",
      "After Cross Validation:\n",
      "Accuracy: 88.98 %\n",
      "Standard Deviation: 1.74 %\n"
     ]
    }
   ],
   "source": [
    "run_decision_tree(X_train_anova,\n",
    "                  X_test_anova,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def run_naive_bayes(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.5\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.85      0.87       350\n",
      "         1.0       0.87      0.90      0.89       393\n",
      "\n",
      "    accuracy                           0.88       743\n",
      "   macro avg       0.88      0.87      0.88       743\n",
      "weighted avg       0.88      0.88      0.88       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[296  54]\n",
      " [ 38 355]]\n",
      "Metrics:\n",
      "Accuracy: 0.876\n",
      "F1 Score: 0.885\n",
      "Precision: 0.868\n",
      "Recall: 0.903\n",
      "After Cross Validation:\n",
      "Accuracy: 86.67 %\n",
      "Standard Deviation: 2.61 %\n"
     ]
    }
   ],
   "source": [
    "run_naive_bayes(X_train_original,\n",
    "                  X_test_original,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.5535229606561338\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.5367066521264995\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.85      0.87       350\n",
      "         1.0       0.87      0.91      0.89       393\n",
      "\n",
      "    accuracy                           0.88       743\n",
      "   macro avg       0.88      0.88      0.88       743\n",
      "weighted avg       0.88      0.88      0.88       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[297  53]\n",
      " [ 36 357]]\n",
      "Metrics:\n",
      "Accuracy: 0.880\n",
      "F1 Score: 0.889\n",
      "Precision: 0.871\n",
      "Recall: 0.908\n",
      "After Cross Validation:\n",
      "Accuracy: 86.85 %\n",
      "Standard Deviation: 2.58 %\n"
     ]
    }
   ],
   "source": [
    "run_naive_bayes(X_train_anova,\n",
    "                  X_test_anova,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run_linear_SVM(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = SVC(kernel = 'linear', random_state = 0, probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.5\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.94      0.95       350\n",
      "         1.0       0.95      0.98      0.96       393\n",
      "\n",
      "    accuracy                           0.96       743\n",
      "   macro avg       0.96      0.96      0.96       743\n",
      "weighted avg       0.96      0.96      0.96       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[328  22]\n",
      " [  9 384]]\n",
      "Metrics:\n",
      "Accuracy: 0.958\n",
      "F1 Score: 0.961\n",
      "Precision: 0.946\n",
      "Recall: 0.977\n",
      "After Cross Validation:\n"
     ]
    }
   ],
   "source": [
    "run_linear_SVM(X_train_original,\n",
    "                  X_test_original,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_linear_SVM(X_train_anova,\n",
    "                  X_test_anova,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
