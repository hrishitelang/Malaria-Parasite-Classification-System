{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2488, 106)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('image_bins_stats_lungs3.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transformed_image_covid_1.png</td>\n",
       "      <td>4722</td>\n",
       "      <td>15567</td>\n",
       "      <td>4</td>\n",
       "      <td>7683</td>\n",
       "      <td>12061</td>\n",
       "      <td>1</td>\n",
       "      <td>8864</td>\n",
       "      <td>16634</td>\n",
       "      <td>77.433079</td>\n",
       "      <td>...</td>\n",
       "      <td>29.26670025</td>\n",
       "      <td>39.092067</td>\n",
       "      <td>21.915792</td>\n",
       "      <td>15.564234</td>\n",
       "      <td>10.232452</td>\n",
       "      <td>12.530200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.674295</td>\n",
       "      <td>31.538221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transformed_image_covid_2.png</td>\n",
       "      <td>6556</td>\n",
       "      <td>13701</td>\n",
       "      <td>25</td>\n",
       "      <td>9956</td>\n",
       "      <td>9437</td>\n",
       "      <td>0</td>\n",
       "      <td>12114</td>\n",
       "      <td>13747</td>\n",
       "      <td>79.728951</td>\n",
       "      <td>...</td>\n",
       "      <td>33.53821958</td>\n",
       "      <td>28.281468</td>\n",
       "      <td>23.127681</td>\n",
       "      <td>11.979449</td>\n",
       "      <td>17.519198</td>\n",
       "      <td>24.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.506228</td>\n",
       "      <td>36.562100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transformed_image_covid_3.png</td>\n",
       "      <td>10512</td>\n",
       "      <td>12249</td>\n",
       "      <td>1</td>\n",
       "      <td>11502</td>\n",
       "      <td>7743</td>\n",
       "      <td>2</td>\n",
       "      <td>9619</td>\n",
       "      <td>13908</td>\n",
       "      <td>68.987348</td>\n",
       "      <td>...</td>\n",
       "      <td>25.22521593</td>\n",
       "      <td>26.681675</td>\n",
       "      <td>24.442798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.323460</td>\n",
       "      <td>38.083555</td>\n",
       "      <td>4.204482</td>\n",
       "      <td>55.658016</td>\n",
       "      <td>27.952446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transformed_image_covid_4.png</td>\n",
       "      <td>7987</td>\n",
       "      <td>11854</td>\n",
       "      <td>2</td>\n",
       "      <td>10419</td>\n",
       "      <td>11895</td>\n",
       "      <td>9</td>\n",
       "      <td>11931</td>\n",
       "      <td>11439</td>\n",
       "      <td>94.638788</td>\n",
       "      <td>...</td>\n",
       "      <td>34.51618537</td>\n",
       "      <td>24.056261</td>\n",
       "      <td>28.558353</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>13.800903</td>\n",
       "      <td>27.757483</td>\n",
       "      <td>33.449086</td>\n",
       "      <td>44.809595</td>\n",
       "      <td>37.884099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transformed_image_covid_5.png</td>\n",
       "      <td>7761</td>\n",
       "      <td>14159</td>\n",
       "      <td>4</td>\n",
       "      <td>10898</td>\n",
       "      <td>10560</td>\n",
       "      <td>9</td>\n",
       "      <td>9153</td>\n",
       "      <td>12992</td>\n",
       "      <td>68.762015</td>\n",
       "      <td>...</td>\n",
       "      <td>32.13721328</td>\n",
       "      <td>27.884767</td>\n",
       "      <td>23.329477</td>\n",
       "      <td>13.445587</td>\n",
       "      <td>16.742312</td>\n",
       "      <td>28.738945</td>\n",
       "      <td>26.135224</td>\n",
       "      <td>49.330295</td>\n",
       "      <td>35.162254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        filename  Bins0  Bins1  Bins2  Bins3  Bins4  Bins5  \\\n",
       "0  transformed_image_covid_1.png   4722  15567      4   7683  12061      1   \n",
       "1  transformed_image_covid_2.png   6556  13701     25   9956   9437      0   \n",
       "2  transformed_image_covid_3.png  10512  12249      1  11502   7743      2   \n",
       "3  transformed_image_covid_4.png   7987  11854      2  10419  11895      9   \n",
       "4  transformed_image_covid_5.png   7761  14159      4  10898  10560      9   \n",
       "\n",
       "   Bins6  Bins7  rmean_bins0  ...  bskew_bins7  bkurto_bins0  bkurto_bins1  \\\n",
       "0   8864  16634    77.433079  ...  29.26670025     39.092067     21.915792   \n",
       "1  12114  13747    79.728951  ...  33.53821958     28.281468     23.127681   \n",
       "2   9619  13908    68.987348  ...  25.22521593     26.681675     24.442798   \n",
       "3  11931  11439    94.638788  ...  34.51618537     24.056261     28.558353   \n",
       "4   9153  12992    68.762015  ...  32.13721328     27.884767     23.329477   \n",
       "\n",
       "   bkurto_bins2  bkurto_bins3  bkurto_bins4  bkurto_bins5 bkurto_bins6  \\\n",
       "0     15.564234     10.232452     12.530200      0.000000    40.674295   \n",
       "1     11.979449     17.519198     24.313131      0.000000    38.506228   \n",
       "2      0.000000     12.323460     38.083555      4.204482    55.658016   \n",
       "3      0.840896     13.800903     27.757483     33.449086    44.809595   \n",
       "4     13.445587     16.742312     28.738945     26.135224    49.330295   \n",
       "\n",
       "  bkurto_bins7 class  \n",
       "0    31.538221     0  \n",
       "1    36.562100     0  \n",
       "2    27.952446     0  \n",
       "3    37.884099     0  \n",
       "4    35.162254     0  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>rmean_bins1</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4722</td>\n",
       "      <td>15567</td>\n",
       "      <td>4</td>\n",
       "      <td>7683</td>\n",
       "      <td>12061</td>\n",
       "      <td>1</td>\n",
       "      <td>8864</td>\n",
       "      <td>16634</td>\n",
       "      <td>77.433079</td>\n",
       "      <td>0.202929</td>\n",
       "      <td>...</td>\n",
       "      <td>29.26670025</td>\n",
       "      <td>39.092067</td>\n",
       "      <td>21.915792</td>\n",
       "      <td>15.564234</td>\n",
       "      <td>10.232452</td>\n",
       "      <td>12.530200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.674295</td>\n",
       "      <td>31.538221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6556</td>\n",
       "      <td>13701</td>\n",
       "      <td>25</td>\n",
       "      <td>9956</td>\n",
       "      <td>9437</td>\n",
       "      <td>0</td>\n",
       "      <td>12114</td>\n",
       "      <td>13747</td>\n",
       "      <td>79.728951</td>\n",
       "      <td>5.447851</td>\n",
       "      <td>...</td>\n",
       "      <td>33.53821958</td>\n",
       "      <td>28.281468</td>\n",
       "      <td>23.127681</td>\n",
       "      <td>11.979449</td>\n",
       "      <td>17.519198</td>\n",
       "      <td>24.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.506228</td>\n",
       "      <td>36.562100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10512</td>\n",
       "      <td>12249</td>\n",
       "      <td>1</td>\n",
       "      <td>11502</td>\n",
       "      <td>7743</td>\n",
       "      <td>2</td>\n",
       "      <td>9619</td>\n",
       "      <td>13908</td>\n",
       "      <td>68.987348</td>\n",
       "      <td>36.388358</td>\n",
       "      <td>...</td>\n",
       "      <td>25.22521593</td>\n",
       "      <td>26.681675</td>\n",
       "      <td>24.442798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.323460</td>\n",
       "      <td>38.083555</td>\n",
       "      <td>4.204482</td>\n",
       "      <td>55.658016</td>\n",
       "      <td>27.952446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7987</td>\n",
       "      <td>11854</td>\n",
       "      <td>2</td>\n",
       "      <td>10419</td>\n",
       "      <td>11895</td>\n",
       "      <td>9</td>\n",
       "      <td>11931</td>\n",
       "      <td>11439</td>\n",
       "      <td>94.638788</td>\n",
       "      <td>15.529948</td>\n",
       "      <td>...</td>\n",
       "      <td>34.51618537</td>\n",
       "      <td>24.056261</td>\n",
       "      <td>28.558353</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>13.800903</td>\n",
       "      <td>27.757483</td>\n",
       "      <td>33.449086</td>\n",
       "      <td>44.809595</td>\n",
       "      <td>37.884099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7761</td>\n",
       "      <td>14159</td>\n",
       "      <td>4</td>\n",
       "      <td>10898</td>\n",
       "      <td>10560</td>\n",
       "      <td>9</td>\n",
       "      <td>9153</td>\n",
       "      <td>12992</td>\n",
       "      <td>68.762015</td>\n",
       "      <td>4.809379</td>\n",
       "      <td>...</td>\n",
       "      <td>32.13721328</td>\n",
       "      <td>27.884767</td>\n",
       "      <td>23.329477</td>\n",
       "      <td>13.445587</td>\n",
       "      <td>16.742312</td>\n",
       "      <td>28.738945</td>\n",
       "      <td>26.135224</td>\n",
       "      <td>49.330295</td>\n",
       "      <td>35.162254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bins0  Bins1  Bins2  Bins3  Bins4  Bins5  Bins6  Bins7  rmean_bins0  \\\n",
       "0   4722  15567      4   7683  12061      1   8864  16634    77.433079   \n",
       "1   6556  13701     25   9956   9437      0  12114  13747    79.728951   \n",
       "2  10512  12249      1  11502   7743      2   9619  13908    68.987348   \n",
       "3   7987  11854      2  10419  11895      9  11931  11439    94.638788   \n",
       "4   7761  14159      4  10898  10560      9   9153  12992    68.762015   \n",
       "\n",
       "   rmean_bins1  ...  bskew_bins7  bkurto_bins0  bkurto_bins1  bkurto_bins2  \\\n",
       "0     0.202929  ...  29.26670025     39.092067     21.915792     15.564234   \n",
       "1     5.447851  ...  33.53821958     28.281468     23.127681     11.979449   \n",
       "2    36.388358  ...  25.22521593     26.681675     24.442798      0.000000   \n",
       "3    15.529948  ...  34.51618537     24.056261     28.558353      0.840896   \n",
       "4     4.809379  ...  32.13721328     27.884767     23.329477     13.445587   \n",
       "\n",
       "   bkurto_bins3  bkurto_bins4 bkurto_bins5 bkurto_bins6 bkurto_bins7 class  \n",
       "0     10.232452     12.530200     0.000000    40.674295    31.538221     0  \n",
       "1     17.519198     24.313131     0.000000    38.506228    36.562100     0  \n",
       "2     12.323460     38.083555     4.204482    55.658016    27.952446     0  \n",
       "3     13.800903     27.757483    33.449086    44.809595    37.884099     0  \n",
       "4     16.742312     28.738945    26.135224    49.330295    35.162254     0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['filename'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['rstd_bins0','rstd_bins1','rstd_bins2','rstd_bins3','rstd_bins4','rstd_bins5','rstd_bins6','rstd_bins7','rskew_bins0','rskew_bins1','rskew_bins2','rskew_bins3','rskew_bins4','rskew_bins5','rskew_bins6','rskew_bins7','gstd_bins0','gstd_bins1','gstd_bins2','gstd_bins3','gstd_bins4','gstd_bins5','gstd_bins6','gstd_bins7','bstd_bins0','bstd_bins1','bstd_bins2','bstd_bins3','bstd_bins4','bstd_bins5','bstd_bins6','bstd_bins7','gskew_bins0','gskew_bins1','gskew_bins2','gskew_bins3','gskew_bins4','gskew_bins5','gskew_bins6','gskew_bins7','bskew_bins0','bskew_bins1','bskew_bins2','bskew_bins3','bskew_bins4','bskew_bins5','bskew_bins6','bskew_bins7','class']\n",
    "for i in name:\n",
    "    data[i] = pd.to_numeric(data[i],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>rmean_bins1</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4722.0</td>\n",
       "      <td>15567.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7683.0</td>\n",
       "      <td>12061.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8864.0</td>\n",
       "      <td>16634.0</td>\n",
       "      <td>77.433079</td>\n",
       "      <td>0.202929</td>\n",
       "      <td>...</td>\n",
       "      <td>29.266700</td>\n",
       "      <td>39.092067</td>\n",
       "      <td>21.915792</td>\n",
       "      <td>15.564234</td>\n",
       "      <td>10.232452</td>\n",
       "      <td>12.530200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.674295</td>\n",
       "      <td>31.538221</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6556.0</td>\n",
       "      <td>13701.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9956.0</td>\n",
       "      <td>9437.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12114.0</td>\n",
       "      <td>13747.0</td>\n",
       "      <td>79.728951</td>\n",
       "      <td>5.447851</td>\n",
       "      <td>...</td>\n",
       "      <td>33.538220</td>\n",
       "      <td>28.281468</td>\n",
       "      <td>23.127681</td>\n",
       "      <td>11.979449</td>\n",
       "      <td>17.519198</td>\n",
       "      <td>24.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.506228</td>\n",
       "      <td>36.562100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10512.0</td>\n",
       "      <td>12249.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11502.0</td>\n",
       "      <td>7743.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9619.0</td>\n",
       "      <td>13908.0</td>\n",
       "      <td>68.987348</td>\n",
       "      <td>36.388358</td>\n",
       "      <td>...</td>\n",
       "      <td>25.225216</td>\n",
       "      <td>26.681675</td>\n",
       "      <td>24.442798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.323460</td>\n",
       "      <td>38.083555</td>\n",
       "      <td>4.204482</td>\n",
       "      <td>55.658016</td>\n",
       "      <td>27.952446</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7987.0</td>\n",
       "      <td>11854.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10419.0</td>\n",
       "      <td>11895.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11931.0</td>\n",
       "      <td>11439.0</td>\n",
       "      <td>94.638788</td>\n",
       "      <td>15.529948</td>\n",
       "      <td>...</td>\n",
       "      <td>34.516185</td>\n",
       "      <td>24.056261</td>\n",
       "      <td>28.558353</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>13.800903</td>\n",
       "      <td>27.757483</td>\n",
       "      <td>33.449086</td>\n",
       "      <td>44.809595</td>\n",
       "      <td>37.884099</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7761.0</td>\n",
       "      <td>14159.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10898.0</td>\n",
       "      <td>10560.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9153.0</td>\n",
       "      <td>12992.0</td>\n",
       "      <td>68.762015</td>\n",
       "      <td>4.809379</td>\n",
       "      <td>...</td>\n",
       "      <td>32.137213</td>\n",
       "      <td>27.884767</td>\n",
       "      <td>23.329477</td>\n",
       "      <td>13.445587</td>\n",
       "      <td>16.742312</td>\n",
       "      <td>28.738945</td>\n",
       "      <td>26.135224</td>\n",
       "      <td>49.330295</td>\n",
       "      <td>35.162254</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>9870.0</td>\n",
       "      <td>10436.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9558.0</td>\n",
       "      <td>9764.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16080.0</td>\n",
       "      <td>9815.0</td>\n",
       "      <td>104.708207</td>\n",
       "      <td>27.440974</td>\n",
       "      <td>...</td>\n",
       "      <td>28.826381</td>\n",
       "      <td>16.609479</td>\n",
       "      <td>32.541509</td>\n",
       "      <td>10.841782</td>\n",
       "      <td>18.263777</td>\n",
       "      <td>29.591836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.584547</td>\n",
       "      <td>43.219779</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>5946.0</td>\n",
       "      <td>14026.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11041.0</td>\n",
       "      <td>12415.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7886.0</td>\n",
       "      <td>14221.0</td>\n",
       "      <td>74.044736</td>\n",
       "      <td>1.607016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.246127</td>\n",
       "      <td>30.936390</td>\n",
       "      <td>21.337923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.706518</td>\n",
       "      <td>17.877323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.339391</td>\n",
       "      <td>32.611797</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>7330.0</td>\n",
       "      <td>8408.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10811.0</td>\n",
       "      <td>18521.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6699.0</td>\n",
       "      <td>13759.0</td>\n",
       "      <td>112.515416</td>\n",
       "      <td>7.136774</td>\n",
       "      <td>...</td>\n",
       "      <td>28.790502</td>\n",
       "      <td>42.515393</td>\n",
       "      <td>18.625921</td>\n",
       "      <td>11.891740</td>\n",
       "      <td>14.170267</td>\n",
       "      <td>3.991819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.311970</td>\n",
       "      <td>41.914116</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>7630.0</td>\n",
       "      <td>16431.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9530.0</td>\n",
       "      <td>3413.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17843.0</td>\n",
       "      <td>10685.0</td>\n",
       "      <td>73.122412</td>\n",
       "      <td>24.310145</td>\n",
       "      <td>...</td>\n",
       "      <td>37.426827</td>\n",
       "      <td>20.622111</td>\n",
       "      <td>29.148814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.197666</td>\n",
       "      <td>31.678731</td>\n",
       "      <td>4.769168</td>\n",
       "      <td>50.967873</td>\n",
       "      <td>38.781249</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>5415.0</td>\n",
       "      <td>17347.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8790.0</td>\n",
       "      <td>12865.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8924.0</td>\n",
       "      <td>12193.0</td>\n",
       "      <td>60.702862</td>\n",
       "      <td>1.042082</td>\n",
       "      <td>...</td>\n",
       "      <td>34.588816</td>\n",
       "      <td>33.378388</td>\n",
       "      <td>26.261638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.291031</td>\n",
       "      <td>20.163037</td>\n",
       "      <td>5.045378</td>\n",
       "      <td>45.099627</td>\n",
       "      <td>35.944590</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2479 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bins0    Bins1  Bins2    Bins3    Bins4  Bins5    Bins6    Bins7  \\\n",
       "0      4722.0  15567.0    4.0   7683.0  12061.0    1.0   8864.0  16634.0   \n",
       "1      6556.0  13701.0   25.0   9956.0   9437.0    0.0  12114.0  13747.0   \n",
       "2     10512.0  12249.0    1.0  11502.0   7743.0    2.0   9619.0  13908.0   \n",
       "3      7987.0  11854.0    2.0  10419.0  11895.0    9.0  11931.0  11439.0   \n",
       "4      7761.0  14159.0    4.0  10898.0  10560.0    9.0   9153.0  12992.0   \n",
       "...       ...      ...    ...      ...      ...    ...      ...      ...   \n",
       "2483   9870.0  10436.0   13.0   9558.0   9764.0    0.0  16080.0   9815.0   \n",
       "2484   5946.0  14026.0    1.0  11041.0  12415.0    0.0   7886.0  14221.0   \n",
       "2485   7330.0   8408.0    6.0  10811.0  18521.0    2.0   6699.0  13759.0   \n",
       "2486   7630.0  16431.0    1.0   9530.0   3413.0    3.0  17843.0  10685.0   \n",
       "2487   5415.0  17347.0    0.0   8790.0  12865.0    2.0   8924.0  12193.0   \n",
       "\n",
       "      rmean_bins0  rmean_bins1  ...  bskew_bins7  bkurto_bins0  bkurto_bins1  \\\n",
       "0       77.433079     0.202929  ...    29.266700     39.092067     21.915792   \n",
       "1       79.728951     5.447851  ...    33.538220     28.281468     23.127681   \n",
       "2       68.987348    36.388358  ...    25.225216     26.681675     24.442798   \n",
       "3       94.638788    15.529948  ...    34.516185     24.056261     28.558353   \n",
       "4       68.762015     4.809379  ...    32.137213     27.884767     23.329477   \n",
       "...           ...          ...  ...          ...           ...           ...   \n",
       "2483   104.708207    27.440974  ...    28.826381     16.609479     32.541509   \n",
       "2484    74.044736     1.607016  ...    39.246127     30.936390     21.337923   \n",
       "2485   112.515416     7.136774  ...    28.790502     42.515393     18.625921   \n",
       "2486    73.122412    24.310145  ...    37.426827     20.622111     29.148814   \n",
       "2487    60.702862     1.042082  ...    34.588816     33.378388     26.261638   \n",
       "\n",
       "      bkurto_bins2  bkurto_bins3  bkurto_bins4  bkurto_bins5  bkurto_bins6  \\\n",
       "0        15.564234     10.232452     12.530200      0.000000     40.674295   \n",
       "1        11.979449     17.519198     24.313131      0.000000     38.506228   \n",
       "2         0.000000     12.323460     38.083555      4.204482     55.658016   \n",
       "3         0.840896     13.800903     27.757483     33.449086     44.809595   \n",
       "4        13.445587     16.742312     28.738945     26.135224     49.330295   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2483     10.841782     18.263777     29.591836      0.000000     43.584547   \n",
       "2484      0.000000      9.706518     17.877323      0.000000     45.339391   \n",
       "2485     11.891740     14.170267      3.991819      0.000000     36.311970   \n",
       "2486      0.000000     20.197666     31.678731      4.769168     50.967873   \n",
       "2487      0.000000     17.291031     20.163037      5.045378     45.099627   \n",
       "\n",
       "      bkurto_bins7  class  \n",
       "0        31.538221    0.0  \n",
       "1        36.562100    0.0  \n",
       "2        27.952446    0.0  \n",
       "3        37.884099    0.0  \n",
       "4        35.162254    0.0  \n",
       "...            ...    ...  \n",
       "2483     43.219779    1.0  \n",
       "2484     32.611797    1.0  \n",
       "2485     41.914116    1.0  \n",
       "2486     38.781249    1.0  \n",
       "2487     35.944590    1.0  \n",
       "\n",
       "[2479 rows x 105 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)\n",
    "\n",
    "clean_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1735, 104), (744, 104))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['class'], axis=1),\n",
    "    data['class'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5273250760538897,\n",
       " 0.505950311458786,\n",
       " 0.5795559901492104,\n",
       " 0.535593220338983,\n",
       " 0.560767057800956,\n",
       " 0.6496740547588006,\n",
       " 0.5471208170360713,\n",
       " 0.5531399391568883,\n",
       " 0.5188396349413298,\n",
       " 0.5737505432420686]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine roc-auc for each feature\n",
    "\n",
    "# here we store the roc-auc values\n",
    "roc_values = []\n",
    "\n",
    "# iterate over each feature in the dataset\n",
    "for feature in X_train.columns:\n",
    "\n",
    "    # train a decision tree classifier\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train[feature].fillna(0).to_frame(), y_train)\n",
    "\n",
    "    # obtain the predictions\n",
    "    y_scored = clf.predict_proba(X_test[feature].to_frame())\n",
    "\n",
    "    # calculate and store the roc-auc\n",
    "    roc_values.append(roc_auc_score(y_test, y_scored[:, 1]))\n",
    "    \n",
    "# display the result\n",
    "roc_values[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'roc-auc')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now let's:\n",
    "\n",
    "# 1) capture the roc-auc values in a pandas series\n",
    "# 2) add the variable names in the index\n",
    "# 3) sort the features based on the roc-auc\n",
    "# 4) and make a var plot\n",
    "\n",
    "roc_values = pd.Series(roc_values)\n",
    "roc_values.index = X_train.columns\n",
    "roc_values.sort_values(ascending=False).plot.bar(figsize=(20, 5))\n",
    "plt.ylabel('roc-auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a roc auc value of 0.5 indicates random decision\n",
    "# let's check how many features show a roc-auc value\n",
    "# higher than random\n",
    "\n",
    "len(roc_values[roc_values > 0.57])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Bins5', 'rmean_bins7', 'bmean_bins2', 'bmean_bins5', 'bstd_bins3',\n",
       "       'bskew_bins5', 'bkurto_bins6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = roc_values[roc_values > 0.6].index\n",
    "\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1735, 7), (744, 7))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select features in the dataframes\n",
    "\n",
    "X_train = X_train[selected_features]\n",
    "X_test = X_test[selected_features]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build random forests and\n",
    "# compare its performance in train and test sets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = rf, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.8668566349471923\n",
      "Test set\n",
      "Random Forests roc-auc: 0.8468274663189918\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.65      0.72       354\n",
      "           1       0.73      0.86      0.79       390\n",
      "\n",
      "    accuracy                           0.76       744\n",
      "   macro avg       0.77      0.76      0.76       744\n",
      "weighted avg       0.77      0.76      0.76       744\n",
      "\n",
      "Confusion Matrix:\n",
      "[[230 124]\n",
      " [ 53 337]]\n",
      "Metrics:\n",
      "Accuracy: 0.762\n",
      "F1 Score: 0.792\n",
      "Precision: 0.731\n",
      "Recall: 0.864\n",
      "After Cross Validation:\n",
      "Accuracy: 75.05 %\n",
      "Standard Deviation: 1.95 %\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "run_randomForests(X_train,\n",
    "                  X_test,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def run_logistic(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    logit = LogisticRegression(penalty='l1', random_state=44, max_iter=1000, solver='liblinear')\n",
    "    logit.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = logit.predict_proba(scaler.transform(X_train))\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = logit.predict_proba(scaler.transform(X_test))\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = logit.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = logit, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.7836533434149244\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.7863465160075329\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.58      0.66       354\n",
      "           1       0.69      0.83      0.75       390\n",
      "\n",
      "    accuracy                           0.72       744\n",
      "   macro avg       0.72      0.71      0.71       744\n",
      "weighted avg       0.72      0.72      0.71       744\n",
      "\n",
      "Confusion Matrix:\n",
      "[[207 147]\n",
      " [ 65 325]]\n",
      "Metrics:\n",
      "Accuracy: 0.715\n",
      "F1 Score: 0.754\n",
      "Precision: 0.689\n",
      "Recall: 0.833\n",
      "After Cross Validation:\n",
      "Accuracy: 71.47 %\n",
      "Standard Deviation: 3.28 %\n"
     ]
    }
   ],
   "source": [
    "run_logistic(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run_kernel_SVM(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = SVC(kernel = 'rbf', random_state = 0, probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.7242872502728197\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.7138997537302623\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.42      0.54       354\n",
      "           1       0.62      0.87      0.73       390\n",
      "\n",
      "    accuracy                           0.66       744\n",
      "   macro avg       0.69      0.65      0.63       744\n",
      "weighted avg       0.69      0.66      0.64       744\n",
      "\n",
      "Confusion Matrix:\n",
      "[[149 205]\n",
      " [ 49 341]]\n",
      "Metrics:\n",
      "Accuracy: 0.659\n",
      "F1 Score: 0.729\n",
      "Precision: 0.625\n",
      "Recall: 0.874\n",
      "After Cross Validation:\n",
      "Accuracy: 65.82 %\n",
      "Standard Deviation: 2.08 %\n"
     ]
    }
   ],
   "source": [
    "run_kernel_SVM(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def run_knn(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('KNN roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('KNN roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "KNN roc-auc: 0.4993638676844784\n",
      "Test set\n",
      "KNN roc-auc: 0.4985875706214689\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71       354\n",
      "           1       0.73      0.81      0.77       390\n",
      "\n",
      "    accuracy                           0.74       744\n",
      "   macro avg       0.75      0.74      0.74       744\n",
      "weighted avg       0.75      0.74      0.74       744\n",
      "\n",
      "Confusion Matrix:\n",
      "[[237 117]\n",
      " [ 74 316]]\n",
      "Metrics:\n",
      "Accuracy: 0.743\n",
      "F1 Score: 0.768\n",
      "Precision: 0.730\n",
      "Recall: 0.810\n",
      "After Cross Validation:\n",
      "Accuracy: 74.52 %\n",
      "Standard Deviation: 3.91 %\n"
     ]
    }
   ],
   "source": [
    "run_knn(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def run_decision_tree(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(X_train)\n",
    "    print('Decision Tree roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(X_test)\n",
    "    print('Decision Tree roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Decision Tree roc-auc: 1.0\n",
      "Test set\n",
      "Decision Tree roc-auc: 0.7147544545849631\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.70       354\n",
      "           1       0.72      0.75      0.73       390\n",
      "\n",
      "    accuracy                           0.72       744\n",
      "   macro avg       0.72      0.71      0.72       744\n",
      "weighted avg       0.72      0.72      0.72       744\n",
      "\n",
      "Confusion Matrix:\n",
      "[[241 113]\n",
      " [ 98 292]]\n",
      "Metrics:\n",
      "Accuracy: 0.716\n",
      "F1 Score: 0.735\n",
      "Precision: 0.721\n",
      "Recall: 0.749\n",
      "After Cross Validation:\n",
      "Accuracy: 70.83 %\n",
      "Standard Deviation: 4.20 %\n"
     ]
    }
   ],
   "source": [
    "run_decision_tree(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def run_naive_bayes(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.6091238400137281\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.5744748660002897\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.35      0.50       354\n",
      "           1       0.62      0.95      0.75       390\n",
      "\n",
      "    accuracy                           0.67       744\n",
      "   macro avg       0.74      0.65      0.62       744\n",
      "weighted avg       0.74      0.67      0.63       744\n",
      "\n",
      "Confusion Matrix:\n",
      "[[123 231]\n",
      " [ 18 372]]\n",
      "Metrics:\n",
      "Accuracy: 0.665\n",
      "F1 Score: 0.749\n",
      "Precision: 0.617\n",
      "Recall: 0.954\n",
      "After Cross Validation:\n",
      "Accuracy: 66.74 %\n",
      "Standard Deviation: 2.52 %\n"
     ]
    }
   ],
   "source": [
    "run_naive_bayes(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run_linear_SVM(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = SVC(kernel = 'linear', random_state = 0, probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.7594914023864616\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.8047149894440535\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.70      0.86      0.77       406\n",
      "         2.0       0.82      0.62      0.71       399\n",
      "\n",
      "    accuracy                           0.74       805\n",
      "   macro avg       0.76      0.74      0.74       805\n",
      "weighted avg       0.76      0.74      0.74       805\n",
      "\n",
      "Confusion Matrix:\n",
      "[[350  56]\n",
      " [151 248]]\n",
      "Metrics:\n",
      "Accuracy: 0.743\n",
      "F1 Score: 0.772\n",
      "Precision: 0.699\n",
      "Recall: 0.862\n",
      "After Cross Validation:\n",
      "Accuracy: 70.82 %\n",
      "Standard Deviation: 3.13 %\n"
     ]
    }
   ],
   "source": [
    "run_linear_SVM(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
