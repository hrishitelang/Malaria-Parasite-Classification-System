{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold, f_classif, SelectKBest\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2488, 106)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('image_bins_stats_lungs3.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transformed_image_covid_1.png</td>\n",
       "      <td>4722</td>\n",
       "      <td>15567</td>\n",
       "      <td>4</td>\n",
       "      <td>7683</td>\n",
       "      <td>12061</td>\n",
       "      <td>1</td>\n",
       "      <td>8864</td>\n",
       "      <td>16634</td>\n",
       "      <td>77.433079</td>\n",
       "      <td>...</td>\n",
       "      <td>29.26670025</td>\n",
       "      <td>39.092067</td>\n",
       "      <td>21.915792</td>\n",
       "      <td>15.564234</td>\n",
       "      <td>10.232452</td>\n",
       "      <td>12.530200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.674295</td>\n",
       "      <td>31.538221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transformed_image_covid_2.png</td>\n",
       "      <td>6556</td>\n",
       "      <td>13701</td>\n",
       "      <td>25</td>\n",
       "      <td>9956</td>\n",
       "      <td>9437</td>\n",
       "      <td>0</td>\n",
       "      <td>12114</td>\n",
       "      <td>13747</td>\n",
       "      <td>79.728951</td>\n",
       "      <td>...</td>\n",
       "      <td>33.53821958</td>\n",
       "      <td>28.281468</td>\n",
       "      <td>23.127681</td>\n",
       "      <td>11.979449</td>\n",
       "      <td>17.519198</td>\n",
       "      <td>24.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.506228</td>\n",
       "      <td>36.562100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transformed_image_covid_3.png</td>\n",
       "      <td>10512</td>\n",
       "      <td>12249</td>\n",
       "      <td>1</td>\n",
       "      <td>11502</td>\n",
       "      <td>7743</td>\n",
       "      <td>2</td>\n",
       "      <td>9619</td>\n",
       "      <td>13908</td>\n",
       "      <td>68.987348</td>\n",
       "      <td>...</td>\n",
       "      <td>25.22521593</td>\n",
       "      <td>26.681675</td>\n",
       "      <td>24.442798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.323460</td>\n",
       "      <td>38.083555</td>\n",
       "      <td>4.204482</td>\n",
       "      <td>55.658016</td>\n",
       "      <td>27.952446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transformed_image_covid_4.png</td>\n",
       "      <td>7987</td>\n",
       "      <td>11854</td>\n",
       "      <td>2</td>\n",
       "      <td>10419</td>\n",
       "      <td>11895</td>\n",
       "      <td>9</td>\n",
       "      <td>11931</td>\n",
       "      <td>11439</td>\n",
       "      <td>94.638788</td>\n",
       "      <td>...</td>\n",
       "      <td>34.51618537</td>\n",
       "      <td>24.056261</td>\n",
       "      <td>28.558353</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>13.800903</td>\n",
       "      <td>27.757483</td>\n",
       "      <td>33.449086</td>\n",
       "      <td>44.809595</td>\n",
       "      <td>37.884099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transformed_image_covid_5.png</td>\n",
       "      <td>7761</td>\n",
       "      <td>14159</td>\n",
       "      <td>4</td>\n",
       "      <td>10898</td>\n",
       "      <td>10560</td>\n",
       "      <td>9</td>\n",
       "      <td>9153</td>\n",
       "      <td>12992</td>\n",
       "      <td>68.762015</td>\n",
       "      <td>...</td>\n",
       "      <td>32.13721328</td>\n",
       "      <td>27.884767</td>\n",
       "      <td>23.329477</td>\n",
       "      <td>13.445587</td>\n",
       "      <td>16.742312</td>\n",
       "      <td>28.738945</td>\n",
       "      <td>26.135224</td>\n",
       "      <td>49.330295</td>\n",
       "      <td>35.162254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        filename  Bins0  Bins1  Bins2  Bins3  Bins4  Bins5  \\\n",
       "0  transformed_image_covid_1.png   4722  15567      4   7683  12061      1   \n",
       "1  transformed_image_covid_2.png   6556  13701     25   9956   9437      0   \n",
       "2  transformed_image_covid_3.png  10512  12249      1  11502   7743      2   \n",
       "3  transformed_image_covid_4.png   7987  11854      2  10419  11895      9   \n",
       "4  transformed_image_covid_5.png   7761  14159      4  10898  10560      9   \n",
       "\n",
       "   Bins6  Bins7  rmean_bins0  ...  bskew_bins7  bkurto_bins0  bkurto_bins1  \\\n",
       "0   8864  16634    77.433079  ...  29.26670025     39.092067     21.915792   \n",
       "1  12114  13747    79.728951  ...  33.53821958     28.281468     23.127681   \n",
       "2   9619  13908    68.987348  ...  25.22521593     26.681675     24.442798   \n",
       "3  11931  11439    94.638788  ...  34.51618537     24.056261     28.558353   \n",
       "4   9153  12992    68.762015  ...  32.13721328     27.884767     23.329477   \n",
       "\n",
       "   bkurto_bins2  bkurto_bins3  bkurto_bins4  bkurto_bins5 bkurto_bins6  \\\n",
       "0     15.564234     10.232452     12.530200      0.000000    40.674295   \n",
       "1     11.979449     17.519198     24.313131      0.000000    38.506228   \n",
       "2      0.000000     12.323460     38.083555      4.204482    55.658016   \n",
       "3      0.840896     13.800903     27.757483     33.449086    44.809595   \n",
       "4     13.445587     16.742312     28.738945     26.135224    49.330295   \n",
       "\n",
       "  bkurto_bins7 class  \n",
       "0    31.538221     0  \n",
       "1    36.562100     0  \n",
       "2    27.952446     0  \n",
       "3    37.884099     0  \n",
       "4    35.162254     0  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>rmean_bins1</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4722</td>\n",
       "      <td>15567</td>\n",
       "      <td>4</td>\n",
       "      <td>7683</td>\n",
       "      <td>12061</td>\n",
       "      <td>1</td>\n",
       "      <td>8864</td>\n",
       "      <td>16634</td>\n",
       "      <td>77.433079</td>\n",
       "      <td>0.202929</td>\n",
       "      <td>...</td>\n",
       "      <td>29.26670025</td>\n",
       "      <td>39.092067</td>\n",
       "      <td>21.915792</td>\n",
       "      <td>15.564234</td>\n",
       "      <td>10.232452</td>\n",
       "      <td>12.530200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.674295</td>\n",
       "      <td>31.538221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6556</td>\n",
       "      <td>13701</td>\n",
       "      <td>25</td>\n",
       "      <td>9956</td>\n",
       "      <td>9437</td>\n",
       "      <td>0</td>\n",
       "      <td>12114</td>\n",
       "      <td>13747</td>\n",
       "      <td>79.728951</td>\n",
       "      <td>5.447851</td>\n",
       "      <td>...</td>\n",
       "      <td>33.53821958</td>\n",
       "      <td>28.281468</td>\n",
       "      <td>23.127681</td>\n",
       "      <td>11.979449</td>\n",
       "      <td>17.519198</td>\n",
       "      <td>24.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.506228</td>\n",
       "      <td>36.562100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10512</td>\n",
       "      <td>12249</td>\n",
       "      <td>1</td>\n",
       "      <td>11502</td>\n",
       "      <td>7743</td>\n",
       "      <td>2</td>\n",
       "      <td>9619</td>\n",
       "      <td>13908</td>\n",
       "      <td>68.987348</td>\n",
       "      <td>36.388358</td>\n",
       "      <td>...</td>\n",
       "      <td>25.22521593</td>\n",
       "      <td>26.681675</td>\n",
       "      <td>24.442798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.323460</td>\n",
       "      <td>38.083555</td>\n",
       "      <td>4.204482</td>\n",
       "      <td>55.658016</td>\n",
       "      <td>27.952446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7987</td>\n",
       "      <td>11854</td>\n",
       "      <td>2</td>\n",
       "      <td>10419</td>\n",
       "      <td>11895</td>\n",
       "      <td>9</td>\n",
       "      <td>11931</td>\n",
       "      <td>11439</td>\n",
       "      <td>94.638788</td>\n",
       "      <td>15.529948</td>\n",
       "      <td>...</td>\n",
       "      <td>34.51618537</td>\n",
       "      <td>24.056261</td>\n",
       "      <td>28.558353</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>13.800903</td>\n",
       "      <td>27.757483</td>\n",
       "      <td>33.449086</td>\n",
       "      <td>44.809595</td>\n",
       "      <td>37.884099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7761</td>\n",
       "      <td>14159</td>\n",
       "      <td>4</td>\n",
       "      <td>10898</td>\n",
       "      <td>10560</td>\n",
       "      <td>9</td>\n",
       "      <td>9153</td>\n",
       "      <td>12992</td>\n",
       "      <td>68.762015</td>\n",
       "      <td>4.809379</td>\n",
       "      <td>...</td>\n",
       "      <td>32.13721328</td>\n",
       "      <td>27.884767</td>\n",
       "      <td>23.329477</td>\n",
       "      <td>13.445587</td>\n",
       "      <td>16.742312</td>\n",
       "      <td>28.738945</td>\n",
       "      <td>26.135224</td>\n",
       "      <td>49.330295</td>\n",
       "      <td>35.162254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bins0  Bins1  Bins2  Bins3  Bins4  Bins5  Bins6  Bins7  rmean_bins0  \\\n",
       "0   4722  15567      4   7683  12061      1   8864  16634    77.433079   \n",
       "1   6556  13701     25   9956   9437      0  12114  13747    79.728951   \n",
       "2  10512  12249      1  11502   7743      2   9619  13908    68.987348   \n",
       "3   7987  11854      2  10419  11895      9  11931  11439    94.638788   \n",
       "4   7761  14159      4  10898  10560      9   9153  12992    68.762015   \n",
       "\n",
       "   rmean_bins1  ...  bskew_bins7  bkurto_bins0  bkurto_bins1  bkurto_bins2  \\\n",
       "0     0.202929  ...  29.26670025     39.092067     21.915792     15.564234   \n",
       "1     5.447851  ...  33.53821958     28.281468     23.127681     11.979449   \n",
       "2    36.388358  ...  25.22521593     26.681675     24.442798      0.000000   \n",
       "3    15.529948  ...  34.51618537     24.056261     28.558353      0.840896   \n",
       "4     4.809379  ...  32.13721328     27.884767     23.329477     13.445587   \n",
       "\n",
       "   bkurto_bins3  bkurto_bins4 bkurto_bins5 bkurto_bins6 bkurto_bins7 class  \n",
       "0     10.232452     12.530200     0.000000    40.674295    31.538221     0  \n",
       "1     17.519198     24.313131     0.000000    38.506228    36.562100     0  \n",
       "2     12.323460     38.083555     4.204482    55.658016    27.952446     0  \n",
       "3     13.800903     27.757483    33.449086    44.809595    37.884099     0  \n",
       "4     16.742312     28.738945    26.135224    49.330295    35.162254     0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['filename'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['rstd_bins0','rstd_bins1','rstd_bins2','rstd_bins3','rstd_bins4','rstd_bins5','rstd_bins6','rstd_bins7','rskew_bins0','rskew_bins1','rskew_bins2','rskew_bins3','rskew_bins4','rskew_bins5','rskew_bins6','rskew_bins7','gstd_bins0','gstd_bins1','gstd_bins2','gstd_bins3','gstd_bins4','gstd_bins5','gstd_bins6','gstd_bins7','bstd_bins0','bstd_bins1','bstd_bins2','bstd_bins3','bstd_bins4','bstd_bins5','bstd_bins6','bstd_bins7','gskew_bins0','gskew_bins1','gskew_bins2','gskew_bins3','gskew_bins4','gskew_bins5','gskew_bins6','gskew_bins7','bskew_bins0','bskew_bins1','bskew_bins2','bskew_bins3','bskew_bins4','bskew_bins5','bskew_bins6','bskew_bins7','class']\n",
    "for i in name:\n",
    "    data[i] = pd.to_numeric(data[i],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>rmean_bins1</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4722.0</td>\n",
       "      <td>15567.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7683.0</td>\n",
       "      <td>12061.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8864.0</td>\n",
       "      <td>16634.0</td>\n",
       "      <td>77.433079</td>\n",
       "      <td>0.202929</td>\n",
       "      <td>...</td>\n",
       "      <td>29.266700</td>\n",
       "      <td>39.092067</td>\n",
       "      <td>21.915792</td>\n",
       "      <td>15.564234</td>\n",
       "      <td>10.232452</td>\n",
       "      <td>12.530200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.674295</td>\n",
       "      <td>31.538221</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6556.0</td>\n",
       "      <td>13701.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9956.0</td>\n",
       "      <td>9437.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12114.0</td>\n",
       "      <td>13747.0</td>\n",
       "      <td>79.728951</td>\n",
       "      <td>5.447851</td>\n",
       "      <td>...</td>\n",
       "      <td>33.538220</td>\n",
       "      <td>28.281468</td>\n",
       "      <td>23.127681</td>\n",
       "      <td>11.979449</td>\n",
       "      <td>17.519198</td>\n",
       "      <td>24.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.506228</td>\n",
       "      <td>36.562100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10512.0</td>\n",
       "      <td>12249.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11502.0</td>\n",
       "      <td>7743.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9619.0</td>\n",
       "      <td>13908.0</td>\n",
       "      <td>68.987348</td>\n",
       "      <td>36.388358</td>\n",
       "      <td>...</td>\n",
       "      <td>25.225216</td>\n",
       "      <td>26.681675</td>\n",
       "      <td>24.442798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.323460</td>\n",
       "      <td>38.083555</td>\n",
       "      <td>4.204482</td>\n",
       "      <td>55.658016</td>\n",
       "      <td>27.952446</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7987.0</td>\n",
       "      <td>11854.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10419.0</td>\n",
       "      <td>11895.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11931.0</td>\n",
       "      <td>11439.0</td>\n",
       "      <td>94.638788</td>\n",
       "      <td>15.529948</td>\n",
       "      <td>...</td>\n",
       "      <td>34.516185</td>\n",
       "      <td>24.056261</td>\n",
       "      <td>28.558353</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>13.800903</td>\n",
       "      <td>27.757483</td>\n",
       "      <td>33.449086</td>\n",
       "      <td>44.809595</td>\n",
       "      <td>37.884099</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7761.0</td>\n",
       "      <td>14159.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10898.0</td>\n",
       "      <td>10560.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9153.0</td>\n",
       "      <td>12992.0</td>\n",
       "      <td>68.762015</td>\n",
       "      <td>4.809379</td>\n",
       "      <td>...</td>\n",
       "      <td>32.137213</td>\n",
       "      <td>27.884767</td>\n",
       "      <td>23.329477</td>\n",
       "      <td>13.445587</td>\n",
       "      <td>16.742312</td>\n",
       "      <td>28.738945</td>\n",
       "      <td>26.135224</td>\n",
       "      <td>49.330295</td>\n",
       "      <td>35.162254</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>9870.0</td>\n",
       "      <td>10436.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9558.0</td>\n",
       "      <td>9764.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16080.0</td>\n",
       "      <td>9815.0</td>\n",
       "      <td>104.708207</td>\n",
       "      <td>27.440974</td>\n",
       "      <td>...</td>\n",
       "      <td>28.826381</td>\n",
       "      <td>16.609479</td>\n",
       "      <td>32.541509</td>\n",
       "      <td>10.841782</td>\n",
       "      <td>18.263777</td>\n",
       "      <td>29.591836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.584547</td>\n",
       "      <td>43.219779</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>5946.0</td>\n",
       "      <td>14026.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11041.0</td>\n",
       "      <td>12415.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7886.0</td>\n",
       "      <td>14221.0</td>\n",
       "      <td>74.044736</td>\n",
       "      <td>1.607016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.246127</td>\n",
       "      <td>30.936390</td>\n",
       "      <td>21.337923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.706518</td>\n",
       "      <td>17.877323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.339391</td>\n",
       "      <td>32.611797</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>7330.0</td>\n",
       "      <td>8408.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10811.0</td>\n",
       "      <td>18521.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6699.0</td>\n",
       "      <td>13759.0</td>\n",
       "      <td>112.515416</td>\n",
       "      <td>7.136774</td>\n",
       "      <td>...</td>\n",
       "      <td>28.790502</td>\n",
       "      <td>42.515393</td>\n",
       "      <td>18.625921</td>\n",
       "      <td>11.891740</td>\n",
       "      <td>14.170267</td>\n",
       "      <td>3.991819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.311970</td>\n",
       "      <td>41.914116</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>7630.0</td>\n",
       "      <td>16431.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9530.0</td>\n",
       "      <td>3413.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17843.0</td>\n",
       "      <td>10685.0</td>\n",
       "      <td>73.122412</td>\n",
       "      <td>24.310145</td>\n",
       "      <td>...</td>\n",
       "      <td>37.426827</td>\n",
       "      <td>20.622111</td>\n",
       "      <td>29.148814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.197666</td>\n",
       "      <td>31.678731</td>\n",
       "      <td>4.769168</td>\n",
       "      <td>50.967873</td>\n",
       "      <td>38.781249</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>5415.0</td>\n",
       "      <td>17347.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8790.0</td>\n",
       "      <td>12865.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8924.0</td>\n",
       "      <td>12193.0</td>\n",
       "      <td>60.702862</td>\n",
       "      <td>1.042082</td>\n",
       "      <td>...</td>\n",
       "      <td>34.588816</td>\n",
       "      <td>33.378388</td>\n",
       "      <td>26.261638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.291031</td>\n",
       "      <td>20.163037</td>\n",
       "      <td>5.045378</td>\n",
       "      <td>45.099627</td>\n",
       "      <td>35.944590</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2479 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bins0    Bins1  Bins2    Bins3    Bins4  Bins5    Bins6    Bins7  \\\n",
       "0      4722.0  15567.0    4.0   7683.0  12061.0    1.0   8864.0  16634.0   \n",
       "1      6556.0  13701.0   25.0   9956.0   9437.0    0.0  12114.0  13747.0   \n",
       "2     10512.0  12249.0    1.0  11502.0   7743.0    2.0   9619.0  13908.0   \n",
       "3      7987.0  11854.0    2.0  10419.0  11895.0    9.0  11931.0  11439.0   \n",
       "4      7761.0  14159.0    4.0  10898.0  10560.0    9.0   9153.0  12992.0   \n",
       "...       ...      ...    ...      ...      ...    ...      ...      ...   \n",
       "2483   9870.0  10436.0   13.0   9558.0   9764.0    0.0  16080.0   9815.0   \n",
       "2484   5946.0  14026.0    1.0  11041.0  12415.0    0.0   7886.0  14221.0   \n",
       "2485   7330.0   8408.0    6.0  10811.0  18521.0    2.0   6699.0  13759.0   \n",
       "2486   7630.0  16431.0    1.0   9530.0   3413.0    3.0  17843.0  10685.0   \n",
       "2487   5415.0  17347.0    0.0   8790.0  12865.0    2.0   8924.0  12193.0   \n",
       "\n",
       "      rmean_bins0  rmean_bins1  ...  bskew_bins7  bkurto_bins0  bkurto_bins1  \\\n",
       "0       77.433079     0.202929  ...    29.266700     39.092067     21.915792   \n",
       "1       79.728951     5.447851  ...    33.538220     28.281468     23.127681   \n",
       "2       68.987348    36.388358  ...    25.225216     26.681675     24.442798   \n",
       "3       94.638788    15.529948  ...    34.516185     24.056261     28.558353   \n",
       "4       68.762015     4.809379  ...    32.137213     27.884767     23.329477   \n",
       "...           ...          ...  ...          ...           ...           ...   \n",
       "2483   104.708207    27.440974  ...    28.826381     16.609479     32.541509   \n",
       "2484    74.044736     1.607016  ...    39.246127     30.936390     21.337923   \n",
       "2485   112.515416     7.136774  ...    28.790502     42.515393     18.625921   \n",
       "2486    73.122412    24.310145  ...    37.426827     20.622111     29.148814   \n",
       "2487    60.702862     1.042082  ...    34.588816     33.378388     26.261638   \n",
       "\n",
       "      bkurto_bins2  bkurto_bins3  bkurto_bins4  bkurto_bins5  bkurto_bins6  \\\n",
       "0        15.564234     10.232452     12.530200      0.000000     40.674295   \n",
       "1        11.979449     17.519198     24.313131      0.000000     38.506228   \n",
       "2         0.000000     12.323460     38.083555      4.204482     55.658016   \n",
       "3         0.840896     13.800903     27.757483     33.449086     44.809595   \n",
       "4        13.445587     16.742312     28.738945     26.135224     49.330295   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2483     10.841782     18.263777     29.591836      0.000000     43.584547   \n",
       "2484      0.000000      9.706518     17.877323      0.000000     45.339391   \n",
       "2485     11.891740     14.170267      3.991819      0.000000     36.311970   \n",
       "2486      0.000000     20.197666     31.678731      4.769168     50.967873   \n",
       "2487      0.000000     17.291031     20.163037      5.045378     45.099627   \n",
       "\n",
       "      bkurto_bins7  class  \n",
       "0        31.538221    0.0  \n",
       "1        36.562100    0.0  \n",
       "2        27.952446    0.0  \n",
       "3        37.884099    0.0  \n",
       "4        35.162254    0.0  \n",
       "...            ...    ...  \n",
       "2483     43.219779    1.0  \n",
       "2484     32.611797    1.0  \n",
       "2485     41.914116    1.0  \n",
       "2486     38.781249    1.0  \n",
       "2487     35.944590    1.0  \n",
       "\n",
       "[2479 rows x 105 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)\n",
    "\n",
    "clean_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1735, 104), (744, 104))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['class'], axis=1),\n",
    "    data['class'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.79578327e+02, 1.38423129e+01, 3.66421700e+01, 4.23093473e+00,\n",
       "        1.57814257e+02, 2.57463276e+01, 7.99464883e+00, 1.63845604e-02,\n",
       "        4.73948424e+00, 9.94726843e+01, 1.97686513e-01, 2.91455185e+01,\n",
       "        1.70838834e+01, 1.99558471e+02, 7.80603698e+00, 3.04065503e+01,\n",
       "        1.91660370e+00, 2.24344505e+01, 7.76399942e+01, 7.88771736e+00,\n",
       "        2.82202349e+01, 1.76159983e+02, 2.89958138e+02, 7.28407274e+00,\n",
       "        2.40678538e+00, 2.85260850e+01, 8.26694594e+01, 2.86133829e+00,\n",
       "        2.85660271e+01, 1.80041939e+02, 2.84364689e+02, 9.79116527e+00,\n",
       "        6.07598275e+00, 3.74040829e+01, 7.87208028e+01, 1.68497679e+00,\n",
       "        3.43970150e+01, 1.81394500e+02, 1.99082033e+02, 1.67905722e+01,\n",
       "        3.37050911e+01, 1.48667682e+01, 4.03537968e+00, 1.83254975e+01,\n",
       "        1.24915904e+02, 1.23276292e+01, 7.53652307e+00, 1.00249143e+01,\n",
       "        6.49434160e+01, 4.16266415e+01, 6.81095264e+01, 4.99846904e+01,\n",
       "        3.84341692e+01, 1.15589619e+02, 1.27491789e+02, 1.44776991e+01,\n",
       "        4.39750868e+01, 4.34062679e+01, 7.03739237e+01, 5.36978047e+01,\n",
       "        2.06469404e+01, 1.42426363e+02, 1.42912691e+02, 4.59569973e+01,\n",
       "        2.02284534e+01, 4.86862787e+01, 6.75897809e+01, 4.94913964e+01,\n",
       "        1.16840830e+01, 1.39107660e+02, 1.63171965e+02, 7.35935423e+01,\n",
       "        4.68158335e+01, 5.59527569e+01, 1.35687162e+01, 8.99302916e+00,\n",
       "        2.10150164e+02, 2.10844832e+02, 2.91143306e+01, 2.06704917e+01,\n",
       "        3.35892968e+01, 2.88777556e+00, 4.62610542e+01, 2.69599201e+02,\n",
       "        1.60458347e+02, 1.64701143e+02, 2.82635349e+01, 3.91313785e+00,\n",
       "        3.12886495e+01, 2.00581646e+00, 4.69148071e+01, 2.95089494e+02,\n",
       "        1.64645411e+02, 1.73322796e+02, 3.36587963e+01, 1.21437616e+01,\n",
       "        2.31230489e+01, 2.44882625e-01, 4.05060410e+01, 2.68940873e+02,\n",
       "        1.50163514e+02, 1.71904407e+02, 4.36710761e+01, 3.00486372e+01]),\n",
       " array([4.89406241e-39, 2.05146480e-04, 1.73584380e-09, 3.98429566e-02,\n",
       "        1.05131538e-34, 4.31158284e-07, 4.74548837e-03, 8.98162092e-01,\n",
       "        2.96124624e-02, 8.08799466e-23, 6.56650263e-01, 7.64169255e-08,\n",
       "        3.74719448e-05, 5.73299741e-43, 5.26449721e-03, 4.03159162e-08,\n",
       "        1.66409779e-01, 2.35150948e-06, 2.94012194e-18, 5.03297475e-03,\n",
       "        1.22268004e-07, 2.32594279e-38, 3.04880720e-60, 7.02443062e-03,\n",
       "        1.20992812e-01, 1.04666247e-07, 2.58109239e-19, 9.09117701e-02,\n",
       "        1.02563596e-07, 3.96241274e-39, 3.38594068e-59, 1.78272847e-03,\n",
       "        1.37995550e-02, 1.18402914e-09, 1.74181175e-18, 1.94437193e-01,\n",
       "        5.37057359e-09, 2.14060280e-39, 7.10604264e-43, 4.36671989e-05,\n",
       "        7.61158119e-09, 1.19592883e-04, 4.47104976e-02, 1.96385375e-05,\n",
       "        4.71147078e-28, 4.57728372e-04, 6.10849800e-03, 1.57123792e-03,\n",
       "        1.42131869e-15, 1.42964258e-10, 3.02643169e-16, 2.23819226e-12,\n",
       "        7.06276710e-10, 3.82310746e-26, 1.40512554e-28, 1.46754055e-04,\n",
       "        4.43027333e-11, 5.88235962e-11, 1.00340652e-16, 3.56832874e-13,\n",
       "        5.90422667e-06, 1.30926947e-31, 1.04419801e-31, 1.65197160e-11,\n",
       "        7.32852525e-06, 4.25976457e-12, 3.90027272e-16, 2.85785977e-12,\n",
       "        6.44960836e-04, 6.14048228e-31, 8.92039978e-36, 2.09485136e-17,\n",
       "        1.07798216e-11, 1.17345024e-13, 2.37045744e-04, 2.74871105e-03,\n",
       "        4.91605440e-45, 3.60144591e-45, 7.76363110e-08, 5.83289476e-06,\n",
       "        8.06927537e-09, 8.94335465e-02, 1.42020168e-11, 2.01391721e-56,\n",
       "        3.10888312e-35, 4.41771726e-36, 1.19606212e-07, 4.80682194e-02,\n",
       "        2.57946092e-08, 1.56876618e-01, 1.02625871e-11, 3.36942833e-61,\n",
       "        4.53227326e-36, 8.50000012e-38, 7.79135964e-09, 5.04780322e-04,\n",
       "        1.65104438e-06, 6.20764384e-01, 2.50299654e-10, 2.68056671e-56,\n",
       "        3.60805525e-33, 1.62600469e-37, 5.15495318e-11, 4.83330205e-08]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the univariate statistical measure between\n",
    "# each of the variables and the target\n",
    "\n",
    "# similarly to chi2, the output is one array with f-scores\n",
    "# and one array with the pvalues\n",
    "\n",
    "univariate = f_classif(X_train, y_train)\n",
    "\n",
    "univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f78aceadc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) let's capture the pvalues in a pandas series\n",
    "# 2) add the variable names in the index\n",
    "# 3) sort the features based on their anova pvalues\n",
    "# 4) and make a var plot\n",
    "\n",
    "univariate = pd.Series(univariate[1])\n",
    "univariate.index = X_train.columns\n",
    "univariate.sort_values(ascending=False).plot.bar(figsize=(20, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Bins0', 'Bins4', 'rmean_bins5', 'rstd_bins5', 'rstd_bins6',\n",
       "       'rskew_bins5', 'rskew_bins6', 'rkurto_bins5', 'rkurto_bins6',\n",
       "       'gkurto_bins6', 'bmean_bins4', 'bmean_bins5', 'bstd_bins3',\n",
       "       'bstd_bins4', 'bstd_bins5', 'bskew_bins3', 'bskew_bins4', 'bskew_bins5',\n",
       "       'bkurto_bins3', 'bkurto_bins5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the top 10 features\n",
    "sel_ = SelectKBest(f_classif, k=20).fit(X_train, y_train)\n",
    "\n",
    "# display selected feature names\n",
    "X_train.columns[sel_.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I keep a copy of the dataset with all the variables\n",
    "# to compare the performance of machine learning models\n",
    "# at the end of the notebook\n",
    "\n",
    "X_train_original = X_train.copy()\n",
    "X_test_original = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlated features:  36\n"
     ]
    }
   ],
   "source": [
    "# find and remove correlated features\n",
    "def correlation(dataset, threshold):\n",
    "    \n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    \n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            # we are interested in absolute coeff value\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    \n",
    "    return col_corr\n",
    "\n",
    "\n",
    "corr_features = correlation(X_train, 0.8)\n",
    "print('correlated features: ', len(set(corr_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1735, 68), (744, 68))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove correlated features\n",
    "X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep a copy of the dataset at  this stage\n",
    "X_train_corr = X_train.copy()\n",
    "X_test_corr = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1735, 20), (744, 20))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_ = SelectKBest(f_classif, k=20).fit(X_train, y_train)\n",
    "\n",
    "# capture selected feature names\n",
    "features_to_keep = X_train.columns[sel_.get_support()]\n",
    "\n",
    "# select features\n",
    "X_train_anova = sel_.transform(X_train)\n",
    "X_test_anova = sel_.transform(X_test)\n",
    "\n",
    "# numpy array to dataframe\n",
    "X_train_anova = pd.DataFrame(X_train_anova)\n",
    "X_train_anova.columns = features_to_keep\n",
    "\n",
    "X_test_anova = pd.DataFrame(X_test_anova)\n",
    "X_test_anova.columns = features_to_keep\n",
    "\n",
    "X_train_anova.shape, X_test_anova.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build random forests and\n",
    "# compare its performance in train and test sets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = rf, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.9492984445928084\n",
      "Test set\n",
      "Random Forests roc-auc: 0.9196219035202087\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83       354\n",
      "           1       0.84      0.86      0.85       390\n",
      "\n",
      "    accuracy                           0.84       744\n",
      "   macro avg       0.84      0.84      0.84       744\n",
      "weighted avg       0.84      0.84      0.84       744\n",
      "\n",
      "Confusion Matrix:\n",
      "[[292  62]\n",
      " [ 54 336]]\n",
      "Metrics:\n",
      "Accuracy: 0.844\n",
      "F1 Score: 0.853\n",
      "Precision: 0.844\n",
      "Recall: 0.862\n",
      "After Cross Validation:\n",
      "Accuracy: 84.03 %\n",
      "Standard Deviation: 2.01 %\n"
     ]
    }
   ],
   "source": [
    "run_randomForests(X_train_original,\n",
    "                  X_test_original,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.9354389380008956\n",
      "Test set\n",
      "Random Forests roc-auc: 0.9115167318557148\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81       354\n",
      "           1       0.83      0.84      0.83       390\n",
      "\n",
      "    accuracy                           0.83       744\n",
      "   macro avg       0.83      0.82      0.82       744\n",
      "weighted avg       0.83      0.83      0.83       744\n",
      "\n",
      "Confusion Matrix:\n",
      "[[286  68]\n",
      " [ 62 328]]\n",
      "Metrics:\n",
      "Accuracy: 0.825\n",
      "F1 Score: 0.835\n",
      "Precision: 0.828\n",
      "Recall: 0.841\n",
      "After Cross Validation:\n",
      "Accuracy: 83.23 %\n",
      "Standard Deviation: 1.89 %\n"
     ]
    }
   ],
   "source": [
    "# filter methods - univariate roc-auc\n",
    "run_randomForests(X_train_anova,\n",
    "                  X_test_anova,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def run_logistic(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    logit = LogisticRegression(penalty='l1', random_state=44, max_iter=1000, solver='liblinear')\n",
    "    logit.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = logit.predict_proba(scaler.transform(X_train))\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = logit.predict_proba(scaler.transform(X_test))\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = logit.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = logit, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.8680357252980907\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.8687454729827612\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90       354\n",
      "           1       0.90      0.92      0.91       390\n",
      "\n",
      "    accuracy                           0.90       744\n",
      "   macro avg       0.91      0.90      0.90       744\n",
      "weighted avg       0.90      0.90      0.90       744\n",
      "\n",
      "Confusion Matrix:\n",
      "[[313  41]\n",
      " [ 30 360]]\n",
      "Metrics:\n",
      "Accuracy: 0.905\n",
      "F1 Score: 0.910\n",
      "Precision: 0.898\n",
      "Recall: 0.923\n",
      "After Cross Validation:\n",
      "Accuracy: 92.45 %\n",
      "Standard Deviation: 1.73 %\n"
     ]
    }
   ],
   "source": [
    "run_logistic(X_train_original,\n",
    "                  X_test_original,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.878821150963784\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.8606982471389251\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80       354\n",
      "           1       0.82      0.84      0.83       390\n",
      "\n",
      "    accuracy                           0.82       744\n",
      "   macro avg       0.82      0.82      0.82       744\n",
      "weighted avg       0.82      0.82      0.82       744\n",
      "\n",
      "Confusion Matrix:\n",
      "[[280  74]\n",
      " [ 62 328]]\n",
      "Metrics:\n",
      "Accuracy: 0.817\n",
      "F1 Score: 0.828\n",
      "Precision: 0.816\n",
      "Recall: 0.841\n",
      "After Cross Validation:\n",
      "Accuracy: 81.96 %\n",
      "Standard Deviation: 2.01 %\n"
     ]
    }
   ],
   "source": [
    "run_logistic(X_train_anova,\n",
    "                  X_test_anova,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run_kernel_SVM(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = SVC(kernel = 'rbf', random_state = 0, probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.7716104001265561\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.7870563523105896\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.54      0.62       354\n",
      "           1       0.66      0.82      0.73       390\n",
      "\n",
      "    accuracy                           0.69       744\n",
      "   macro avg       0.70      0.68      0.68       744\n",
      "weighted avg       0.69      0.69      0.68       744\n",
      "\n",
      "Confusion Matrix:\n",
      "[[190 164]\n",
      " [ 70 320]]\n",
      "Metrics:\n",
      "Accuracy: 0.685\n",
      "F1 Score: 0.732\n",
      "Precision: 0.661\n",
      "Recall: 0.821\n",
      "After Cross Validation:\n",
      "Accuracy: 69.22 %\n",
      "Standard Deviation: 4.13 %\n"
     ]
    }
   ],
   "source": [
    "run_kernel_SVM(X_train_original,\n",
    "                  X_test_original,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.8046946430821783\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.8189482833550631\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.58      0.64       354\n",
      "           1       0.68      0.79      0.73       390\n",
      "\n",
      "    accuracy                           0.69       744\n",
      "   macro avg       0.70      0.69      0.69       744\n",
      "weighted avg       0.70      0.69      0.69       744\n",
      "\n",
      "Confusion Matrix:\n",
      "[[206 148]\n",
      " [ 80 310]]\n",
      "Metrics:\n",
      "Accuracy: 0.694\n",
      "F1 Score: 0.731\n",
      "Precision: 0.677\n",
      "Recall: 0.795\n",
      "After Cross Validation:\n",
      "Accuracy: 67.55 %\n",
      "Standard Deviation: 3.19 %\n"
     ]
    }
   ],
   "source": [
    "run_kernel_SVM(X_train_anova,\n",
    "                  X_test_anova,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def run_knn(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('KNN roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('KNN roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "KNN roc-auc: 0.5\n",
      "Test set\n",
      "KNN roc-auc: 0.5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       354\n",
      "           1       0.78      0.74      0.76       390\n",
      "\n",
      "    accuracy                           0.75       744\n",
      "   macro avg       0.75      0.75      0.75       744\n",
      "weighted avg       0.75      0.75      0.75       744\n",
      "\n",
      "Confusion Matrix:\n",
      "[[271  83]\n",
      " [102 288]]\n",
      "Metrics:\n",
      "Accuracy: 0.751\n",
      "F1 Score: 0.757\n",
      "Precision: 0.776\n",
      "Recall: 0.738\n",
      "After Cross Validation:\n",
      "Accuracy: 75.45 %\n",
      "Standard Deviation: 2.01 %\n"
     ]
    }
   ],
   "source": [
    "run_knn(X_train_original,\n",
    "                  X_test_original,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "KNN roc-auc: 0.5\n",
      "Test set\n",
      "KNN roc-auc: 0.5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.64      0.66       354\n",
      "           1       0.69      0.73      0.71       390\n",
      "\n",
      "    accuracy                           0.69       744\n",
      "   macro avg       0.69      0.69      0.69       744\n",
      "weighted avg       0.69      0.69      0.69       744\n",
      "\n",
      "Confusion Matrix:\n",
      "[[228 126]\n",
      " [106 284]]\n",
      "Metrics:\n",
      "Accuracy: 0.688\n",
      "F1 Score: 0.710\n",
      "Precision: 0.693\n",
      "Recall: 0.728\n",
      "After Cross Validation:\n",
      "Accuracy: 64.72 %\n",
      "Standard Deviation: 3.00 %\n"
     ]
    }
   ],
   "source": [
    "run_knn(X_train_anova,\n",
    "                  X_test_anova,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def run_decision_tree(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(X_train)\n",
    "    print('Decision Tree roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(X_test)\n",
    "    print('Decision Tree roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Decision Tree roc-auc: 1.0\n",
      "Test set\n",
      "Decision Tree roc-auc: 0.813168187744459\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80       354\n",
      "           1       0.81      0.84      0.83       390\n",
      "\n",
      "    accuracy                           0.81       744\n",
      "   macro avg       0.81      0.81      0.81       744\n",
      "weighted avg       0.81      0.81      0.81       744\n",
      "\n",
      "Confusion Matrix:\n",
      "[[278  76]\n",
      " [ 62 328]]\n",
      "Metrics:\n",
      "Accuracy: 0.815\n",
      "F1 Score: 0.826\n",
      "Precision: 0.812\n",
      "Recall: 0.841\n",
      "After Cross Validation:\n",
      "Accuracy: 81.21 %\n",
      "Standard Deviation: 1.55 %\n"
     ]
    }
   ],
   "source": [
    "run_decision_tree(X_train_original,\n",
    "                  X_test_original,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Decision Tree roc-auc: 1.0\n",
      "Test set\n",
      "Decision Tree roc-auc: 0.8251412429378531\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       354\n",
      "           1       0.85      0.80      0.83       390\n",
      "\n",
      "    accuracy                           0.82       744\n",
      "   macro avg       0.82      0.83      0.82       744\n",
      "weighted avg       0.83      0.82      0.82       744\n",
      "\n",
      "Confusion Matrix:\n",
      "[[301  53]\n",
      " [ 78 312]]\n",
      "Metrics:\n",
      "Accuracy: 0.824\n",
      "F1 Score: 0.826\n",
      "Precision: 0.855\n",
      "Recall: 0.800\n",
      "After Cross Validation:\n",
      "Accuracy: 80.05 %\n",
      "Standard Deviation: 3.20 %\n"
     ]
    }
   ],
   "source": [
    "run_decision_tree(X_train_anova,\n",
    "                  X_test_anova,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def run_naive_bayes(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.5\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.62      0.71       354\n",
      "           1       0.72      0.89      0.80       390\n",
      "\n",
      "    accuracy                           0.76       744\n",
      "   macro avg       0.78      0.76      0.76       744\n",
      "weighted avg       0.78      0.76      0.76       744\n",
      "\n",
      "Confusion Matrix:\n",
      "[[221 133]\n",
      " [ 44 346]]\n",
      "Metrics:\n",
      "Accuracy: 0.762\n",
      "F1 Score: 0.796\n",
      "Precision: 0.722\n",
      "Recall: 0.887\n",
      "After Cross Validation:\n",
      "Accuracy: 74.58 %\n",
      "Standard Deviation: 2.76 %\n"
     ]
    }
   ],
   "source": [
    "run_naive_bayes(X_train_original,\n",
    "                  X_test_original,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.32174620666725656\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.34343039258293495\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.53      0.65       354\n",
      "           1       0.68      0.92      0.78       390\n",
      "\n",
      "    accuracy                           0.73       744\n",
      "   macro avg       0.77      0.72      0.72       744\n",
      "weighted avg       0.76      0.73      0.72       744\n",
      "\n",
      "Confusion Matrix:\n",
      "[[186 168]\n",
      " [ 31 359]]\n",
      "Metrics:\n",
      "Accuracy: 0.733\n",
      "F1 Score: 0.783\n",
      "Precision: 0.681\n",
      "Recall: 0.921\n",
      "After Cross Validation:\n",
      "Accuracy: 72.56 %\n",
      "Standard Deviation: 3.43 %\n"
     ]
    }
   ],
   "source": [
    "run_naive_bayes(X_train_anova,\n",
    "                  X_test_anova,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run_linear_SVM(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = SVC(kernel = 'linear', random_state = 0, probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_linear_SVM(X_train_original,\n",
    "                  X_test_original,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_linear_SVM(X_train_anova,\n",
    "                  X_test_anova,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
