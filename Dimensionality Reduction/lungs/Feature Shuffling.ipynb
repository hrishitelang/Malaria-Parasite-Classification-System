{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>rmean_bins1</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4722</td>\n",
       "      <td>15567</td>\n",
       "      <td>4</td>\n",
       "      <td>7683</td>\n",
       "      <td>12061</td>\n",
       "      <td>1</td>\n",
       "      <td>8864</td>\n",
       "      <td>16634</td>\n",
       "      <td>77.433079</td>\n",
       "      <td>0.202929</td>\n",
       "      <td>...</td>\n",
       "      <td>29.26670025</td>\n",
       "      <td>39.092067</td>\n",
       "      <td>21.915792</td>\n",
       "      <td>15.564234</td>\n",
       "      <td>10.232452</td>\n",
       "      <td>12.530200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.674295</td>\n",
       "      <td>31.538221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6556</td>\n",
       "      <td>13701</td>\n",
       "      <td>25</td>\n",
       "      <td>9956</td>\n",
       "      <td>9437</td>\n",
       "      <td>0</td>\n",
       "      <td>12114</td>\n",
       "      <td>13747</td>\n",
       "      <td>79.728951</td>\n",
       "      <td>5.447851</td>\n",
       "      <td>...</td>\n",
       "      <td>33.53821958</td>\n",
       "      <td>28.281468</td>\n",
       "      <td>23.127681</td>\n",
       "      <td>11.979449</td>\n",
       "      <td>17.519198</td>\n",
       "      <td>24.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.506228</td>\n",
       "      <td>36.562100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10512</td>\n",
       "      <td>12249</td>\n",
       "      <td>1</td>\n",
       "      <td>11502</td>\n",
       "      <td>7743</td>\n",
       "      <td>2</td>\n",
       "      <td>9619</td>\n",
       "      <td>13908</td>\n",
       "      <td>68.987348</td>\n",
       "      <td>36.388358</td>\n",
       "      <td>...</td>\n",
       "      <td>25.22521593</td>\n",
       "      <td>26.681675</td>\n",
       "      <td>24.442798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.323460</td>\n",
       "      <td>38.083555</td>\n",
       "      <td>4.204482</td>\n",
       "      <td>55.658016</td>\n",
       "      <td>27.952446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7987</td>\n",
       "      <td>11854</td>\n",
       "      <td>2</td>\n",
       "      <td>10419</td>\n",
       "      <td>11895</td>\n",
       "      <td>9</td>\n",
       "      <td>11931</td>\n",
       "      <td>11439</td>\n",
       "      <td>94.638788</td>\n",
       "      <td>15.529948</td>\n",
       "      <td>...</td>\n",
       "      <td>34.51618537</td>\n",
       "      <td>24.056261</td>\n",
       "      <td>28.558353</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>13.800903</td>\n",
       "      <td>27.757483</td>\n",
       "      <td>33.449086</td>\n",
       "      <td>44.809595</td>\n",
       "      <td>37.884099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7761</td>\n",
       "      <td>14159</td>\n",
       "      <td>4</td>\n",
       "      <td>10898</td>\n",
       "      <td>10560</td>\n",
       "      <td>9</td>\n",
       "      <td>9153</td>\n",
       "      <td>12992</td>\n",
       "      <td>68.762015</td>\n",
       "      <td>4.809379</td>\n",
       "      <td>...</td>\n",
       "      <td>32.13721328</td>\n",
       "      <td>27.884767</td>\n",
       "      <td>23.329477</td>\n",
       "      <td>13.445587</td>\n",
       "      <td>16.742312</td>\n",
       "      <td>28.738945</td>\n",
       "      <td>26.135224</td>\n",
       "      <td>49.330295</td>\n",
       "      <td>35.162254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bins0  Bins1  Bins2  Bins3  Bins4  Bins5  Bins6  Bins7  rmean_bins0  \\\n",
       "0   4722  15567      4   7683  12061      1   8864  16634    77.433079   \n",
       "1   6556  13701     25   9956   9437      0  12114  13747    79.728951   \n",
       "2  10512  12249      1  11502   7743      2   9619  13908    68.987348   \n",
       "3   7987  11854      2  10419  11895      9  11931  11439    94.638788   \n",
       "4   7761  14159      4  10898  10560      9   9153  12992    68.762015   \n",
       "\n",
       "   rmean_bins1  ...  bskew_bins7  bkurto_bins0  bkurto_bins1  bkurto_bins2  \\\n",
       "0     0.202929  ...  29.26670025     39.092067     21.915792     15.564234   \n",
       "1     5.447851  ...  33.53821958     28.281468     23.127681     11.979449   \n",
       "2    36.388358  ...  25.22521593     26.681675     24.442798      0.000000   \n",
       "3    15.529948  ...  34.51618537     24.056261     28.558353      0.840896   \n",
       "4     4.809379  ...  32.13721328     27.884767     23.329477     13.445587   \n",
       "\n",
       "   bkurto_bins3  bkurto_bins4 bkurto_bins5 bkurto_bins6 bkurto_bins7 class  \n",
       "0     10.232452     12.530200     0.000000    40.674295    31.538221     0  \n",
       "1     17.519198     24.313131     0.000000    38.506228    36.562100     0  \n",
       "2     12.323460     38.083555     4.204482    55.658016    27.952446     0  \n",
       "3     13.800903     27.757483    33.449086    44.809595    37.884099     0  \n",
       "4     16.742312     28.738945    26.135224    49.330295    35.162254     0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['filename'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['rstd_bins0','rstd_bins1','rstd_bins2','rstd_bins3','rstd_bins4','rstd_bins5','rstd_bins6','rstd_bins7','gstd_bins0','gstd_bins1','gstd_bins2','gstd_bins3','gstd_bins4','gstd_bins5','gstd_bins6','gstd_bins7','bstd_bins0','bstd_bins1','bstd_bins2','bstd_bins3','bstd_bins4','bstd_bins5','bstd_bins6','bstd_bins7','gskew_bins0','gskew_bins1','gskew_bins2','gskew_bins3','gskew_bins4','gskew_bins5','gskew_bins6','gskew_bins7','bskew_bins0','bskew_bins1','bskew_bins2','bskew_bins3','bskew_bins4','bskew_bins5','bskew_bins6','bskew_bins7','class']\n",
    "for i in name:\n",
    "    data[i] = pd.to_numeric(data[i],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>rmean_bins1</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4722.0</td>\n",
       "      <td>15567.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7683.0</td>\n",
       "      <td>12061.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8864.0</td>\n",
       "      <td>16634.0</td>\n",
       "      <td>77.433079</td>\n",
       "      <td>0.202929</td>\n",
       "      <td>...</td>\n",
       "      <td>29.266700</td>\n",
       "      <td>39.092067</td>\n",
       "      <td>21.915792</td>\n",
       "      <td>15.564234</td>\n",
       "      <td>10.232452</td>\n",
       "      <td>12.530200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.674295</td>\n",
       "      <td>31.538221</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6556.0</td>\n",
       "      <td>13701.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9956.0</td>\n",
       "      <td>9437.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12114.0</td>\n",
       "      <td>13747.0</td>\n",
       "      <td>79.728951</td>\n",
       "      <td>5.447851</td>\n",
       "      <td>...</td>\n",
       "      <td>33.538220</td>\n",
       "      <td>28.281468</td>\n",
       "      <td>23.127681</td>\n",
       "      <td>11.979449</td>\n",
       "      <td>17.519198</td>\n",
       "      <td>24.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.506228</td>\n",
       "      <td>36.562100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10512.0</td>\n",
       "      <td>12249.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11502.0</td>\n",
       "      <td>7743.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9619.0</td>\n",
       "      <td>13908.0</td>\n",
       "      <td>68.987348</td>\n",
       "      <td>36.388358</td>\n",
       "      <td>...</td>\n",
       "      <td>25.225216</td>\n",
       "      <td>26.681675</td>\n",
       "      <td>24.442798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.323460</td>\n",
       "      <td>38.083555</td>\n",
       "      <td>4.204482</td>\n",
       "      <td>55.658016</td>\n",
       "      <td>27.952446</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7987.0</td>\n",
       "      <td>11854.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10419.0</td>\n",
       "      <td>11895.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11931.0</td>\n",
       "      <td>11439.0</td>\n",
       "      <td>94.638788</td>\n",
       "      <td>15.529948</td>\n",
       "      <td>...</td>\n",
       "      <td>34.516185</td>\n",
       "      <td>24.056261</td>\n",
       "      <td>28.558353</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>13.800903</td>\n",
       "      <td>27.757483</td>\n",
       "      <td>33.449086</td>\n",
       "      <td>44.809595</td>\n",
       "      <td>37.884099</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7761.0</td>\n",
       "      <td>14159.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10898.0</td>\n",
       "      <td>10560.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9153.0</td>\n",
       "      <td>12992.0</td>\n",
       "      <td>68.762015</td>\n",
       "      <td>4.809379</td>\n",
       "      <td>...</td>\n",
       "      <td>32.137213</td>\n",
       "      <td>27.884767</td>\n",
       "      <td>23.329477</td>\n",
       "      <td>13.445587</td>\n",
       "      <td>16.742312</td>\n",
       "      <td>28.738945</td>\n",
       "      <td>26.135224</td>\n",
       "      <td>49.330295</td>\n",
       "      <td>35.162254</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>4950.0</td>\n",
       "      <td>16941.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9161.0</td>\n",
       "      <td>12953.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8179.0</td>\n",
       "      <td>13352.0</td>\n",
       "      <td>59.237576</td>\n",
       "      <td>0.162269</td>\n",
       "      <td>...</td>\n",
       "      <td>25.786782</td>\n",
       "      <td>40.580961</td>\n",
       "      <td>22.391613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.716628</td>\n",
       "      <td>15.733760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.642531</td>\n",
       "      <td>33.442984</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>6149.0</td>\n",
       "      <td>11217.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10795.0</td>\n",
       "      <td>14813.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7335.0</td>\n",
       "      <td>15226.0</td>\n",
       "      <td>89.067328</td>\n",
       "      <td>2.286262</td>\n",
       "      <td>...</td>\n",
       "      <td>30.321740</td>\n",
       "      <td>38.459722</td>\n",
       "      <td>19.856163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.773049</td>\n",
       "      <td>11.227728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.091211</td>\n",
       "      <td>34.380787</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>8157.0</td>\n",
       "      <td>8955.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8384.0</td>\n",
       "      <td>14395.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8516.0</td>\n",
       "      <td>17126.0</td>\n",
       "      <td>110.959421</td>\n",
       "      <td>12.390955</td>\n",
       "      <td>...</td>\n",
       "      <td>30.361398</td>\n",
       "      <td>40.138990</td>\n",
       "      <td>24.611149</td>\n",
       "      <td>8.738112</td>\n",
       "      <td>13.053664</td>\n",
       "      <td>9.750293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.766410</td>\n",
       "      <td>38.228325</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>6614.0</td>\n",
       "      <td>11508.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10639.0</td>\n",
       "      <td>14738.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7195.0</td>\n",
       "      <td>14839.0</td>\n",
       "      <td>90.745086</td>\n",
       "      <td>4.628172</td>\n",
       "      <td>...</td>\n",
       "      <td>35.209322</td>\n",
       "      <td>29.755901</td>\n",
       "      <td>22.888434</td>\n",
       "      <td>14.582557</td>\n",
       "      <td>13.300365</td>\n",
       "      <td>13.399057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.964578</td>\n",
       "      <td>34.453684</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>6026.0</td>\n",
       "      <td>14923.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11764.0</td>\n",
       "      <td>9530.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6751.0</td>\n",
       "      <td>16540.0</td>\n",
       "      <td>50.459177</td>\n",
       "      <td>3.036186</td>\n",
       "      <td>...</td>\n",
       "      <td>30.498729</td>\n",
       "      <td>34.411057</td>\n",
       "      <td>11.863055</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>9.137053</td>\n",
       "      <td>17.018301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.159898</td>\n",
       "      <td>29.685276</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2476 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bins0    Bins1  Bins2    Bins3    Bins4  Bins5    Bins6    Bins7  \\\n",
       "0      4722.0  15567.0    4.0   7683.0  12061.0    1.0   8864.0  16634.0   \n",
       "1      6556.0  13701.0   25.0   9956.0   9437.0    0.0  12114.0  13747.0   \n",
       "2     10512.0  12249.0    1.0  11502.0   7743.0    2.0   9619.0  13908.0   \n",
       "3      7987.0  11854.0    2.0  10419.0  11895.0    9.0  11931.0  11439.0   \n",
       "4      7761.0  14159.0    4.0  10898.0  10560.0    9.0   9153.0  12992.0   \n",
       "...       ...      ...    ...      ...      ...    ...      ...      ...   \n",
       "2479   4950.0  16941.0    0.0   9161.0  12953.0    0.0   8179.0  13352.0   \n",
       "2480   6149.0  11217.0    1.0  10795.0  14813.0    0.0   7335.0  15226.0   \n",
       "2481   8157.0   8955.0    3.0   8384.0  14395.0    0.0   8516.0  17126.0   \n",
       "2482   6614.0  11508.0    3.0  10639.0  14738.0    0.0   7195.0  14839.0   \n",
       "2483   6026.0  14923.0    2.0  11764.0   9530.0    0.0   6751.0  16540.0   \n",
       "\n",
       "      rmean_bins0  rmean_bins1  ...  bskew_bins7  bkurto_bins0  bkurto_bins1  \\\n",
       "0       77.433079     0.202929  ...    29.266700     39.092067     21.915792   \n",
       "1       79.728951     5.447851  ...    33.538220     28.281468     23.127681   \n",
       "2       68.987348    36.388358  ...    25.225216     26.681675     24.442798   \n",
       "3       94.638788    15.529948  ...    34.516185     24.056261     28.558353   \n",
       "4       68.762015     4.809379  ...    32.137213     27.884767     23.329477   \n",
       "...           ...          ...  ...          ...           ...           ...   \n",
       "2479    59.237576     0.162269  ...    25.786782     40.580961     22.391613   \n",
       "2480    89.067328     2.286262  ...    30.321740     38.459722     19.856163   \n",
       "2481   110.959421    12.390955  ...    30.361398     40.138990     24.611149   \n",
       "2482    90.745086     4.628172  ...    35.209322     29.755901     22.888434   \n",
       "2483    50.459177     3.036186  ...    30.498729     34.411057     11.863055   \n",
       "\n",
       "      bkurto_bins2  bkurto_bins3  bkurto_bins4  bkurto_bins5  bkurto_bins6  \\\n",
       "0        15.564234     10.232452     12.530200      0.000000     40.674295   \n",
       "1        11.979449     17.519198     24.313131      0.000000     38.506228   \n",
       "2         0.000000     12.323460     38.083555      4.204482     55.658016   \n",
       "3         0.840896     13.800903     27.757483     33.449086     44.809595   \n",
       "4        13.445587     16.742312     28.738945     26.135224     49.330295   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2479      0.000000      6.716628     15.733760      0.000000     45.642531   \n",
       "2480      0.000000      7.773049     11.227728      0.000000     40.091211   \n",
       "2481      8.738112     13.053664      9.750293      0.000000     32.766410   \n",
       "2482     14.582557     13.300365     13.399057      0.000000     41.964578   \n",
       "2483      0.840896      9.137053     17.018301      0.000000     42.159898   \n",
       "\n",
       "      bkurto_bins7  class  \n",
       "0        31.538221    0.0  \n",
       "1        36.562100    0.0  \n",
       "2        27.952446    0.0  \n",
       "3        37.884099    0.0  \n",
       "4        35.162254    0.0  \n",
       "...            ...    ...  \n",
       "2479     33.442984    1.0  \n",
       "2480     34.380787    1.0  \n",
       "2481     38.228325    1.0  \n",
       "2482     34.453684    1.0  \n",
       "2483     29.685276    1.0  \n",
       "\n",
       "[2476 rows x 105 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)\n",
    "\n",
    "clean_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1733, 104), (743, 104))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['class'], axis=1),\n",
    "    data['class'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this method, it is necessary to reset the indeces of the returned \n",
    "# datasets\n",
    "\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc score:  0.9642945353504166\n",
      "test auc score:  0.954351145038168\n"
     ]
    }
   ],
   "source": [
    "# The first step to determine feature importance by feature shuffling\n",
    "# is to build the machine learning model for which we want to \n",
    "# select features\n",
    "\n",
    "# In this case, I will build Random Forests, but remember that \n",
    "# you can use this procedure with any other machine learning algorithm\n",
    "\n",
    "# I build few and shallow trees to avoid overfitting\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=50, max_depth=2, random_state=2909, n_jobs=4)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# print roc-auc in train and testing sets\n",
    "print('train auc score: ',\n",
    "      roc_auc_score(y_train, (rf.predict_proba(X_train.fillna(0)))[:, 1]))\n",
    "print('test auc score: ',\n",
    "      roc_auc_score(y_test, (rf.predict_proba(X_test.fillna(0)))[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this cell, I will shuffle one by one, each feature of the dataset\n",
    "\n",
    "# then I use the dataset with the shuffled variable to make predictions\n",
    "# with the random forests I trained in the previous cell\n",
    "\n",
    "# overall train roc-auc: using all the features\n",
    "train_roc = roc_auc_score(y_train, (rf.predict_proba(X_train))[:, 1])\n",
    "\n",
    "# list to capture the performance shift\n",
    "performance_shift = []\n",
    "\n",
    "# selection  logic\n",
    "for feature in X_train.columns:\n",
    "\n",
    "    X_train_c = X_train.copy()\n",
    "\n",
    "    # shuffle individual feature\n",
    "    X_train_c[feature] = X_train_c[feature].sample(\n",
    "        frac=1, random_state=10).reset_index(drop=True)\n",
    "\n",
    "    # make prediction with shuffled feature and calculate roc-auc\n",
    "    shuff_roc = roc_auc_score(y_train, rf.predict_proba(X_train_c)[:, 1])\n",
    "    \n",
    "    drift = train_roc - shuff_roc\n",
    "\n",
    "    # save the drop in roc-auc\n",
    "    performance_shift.append(drift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0018973918412820145,\n",
       " 0.0,\n",
       " 0.00036780004563929936,\n",
       " 0.0,\n",
       " 0.0013020658550009223,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00011074271447164552,\n",
       " 0.0,\n",
       " 0.00017718834315461063,\n",
       " 0.0,\n",
       " 0.0010510490355315483,\n",
       " 0.0,\n",
       " 1.140985543024442e-05,\n",
       " 0.00015839564009278995,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0002785347060954013,\n",
       " 0.002258480207256386,\n",
       " 8.054015597891429e-06,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 2.953139052552789e-05,\n",
       " 2.6175550693174898e-05,\n",
       " 0.0,\n",
       " -7.986898801304321e-05,\n",
       " 0.006417036927661379,\n",
       " 0.00012416607380150158,\n",
       " 0.0007550639623070676,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.00020739090164734186,\n",
       " 0.0007537216263739932,\n",
       " 6.040511698446327e-05,\n",
       " 0.007915083828878844,\n",
       " -0.0002006792219821918,\n",
       " 0.0,\n",
       " 1.0738687463707208e-05,\n",
       " 0.003814247553592609,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00036645770970622493,\n",
       " 0.00509148019383332,\n",
       " 0.007004980066311339,\n",
       " 5.6378109185573066e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0002349087882731471,\n",
       " 0.0003422956629124396,\n",
       " 0.00010335986684018028,\n",
       " 9.12788434431766e-05,\n",
       " 0.0002127602453788624,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 6.778796461581749e-05,\n",
       " 0.0003812234049690444,\n",
       " -4.765292562136647e-05,\n",
       " 0.0,\n",
       " 0.0001872558626521137,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 3.2887230358102926e-05,\n",
       " 0.0025350014094525086,\n",
       " 0.0,\n",
       " -0.00010000402700782729,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0006631139508973538,\n",
       " 0.001931621407573303,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.004686094742069935,\n",
       " 7.248614038135592e-05,\n",
       " 0.0006100916815440227,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.000495321959273487,\n",
       " 0.0,\n",
       " -0.00012550840973490907,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 9.262117937614e-05,\n",
       " 0.0,\n",
       " 2.6175550693063876e-05,\n",
       " 0.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# le't have a look at our list of performances\n",
    "performance_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bins0    0.001897\n",
       "Bins1    0.000000\n",
       "Bins2    0.000368\n",
       "Bins3    0.000000\n",
       "Bins4    0.001302\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now I will transform the list into a pandas Series\n",
    "# for easy manipulation\n",
    "\n",
    "feature_importance = pd.Series(performance_shift)\n",
    "\n",
    "# add variable names in the index\n",
    "feature_importance.index = X_train.columns\n",
    "\n",
    "feature_importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmean_bins0     0.007915\n",
       "gstd_bins1      0.007005\n",
       "rskew_bins6     0.006417\n",
       "gstd_bins0      0.005091\n",
       "bstd_bins3      0.004686\n",
       "                  ...   \n",
       "rskew_bins5    -0.000080\n",
       "bmean_bins1    -0.000100\n",
       "bskew_bins5    -0.000126\n",
       "gmean_bins1    -0.000201\n",
       "rkurto_bins5   -0.000207\n",
       "Length: 104, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now I will sort the dataframe according to the drop in performance\n",
    "# caused by feature shuffling\n",
    "\n",
    "feature_importance.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmean_bins0     0.007915\n",
       "gstd_bins1      0.007005\n",
       "rskew_bins6     0.006417\n",
       "gstd_bins0      0.005091\n",
       "bstd_bins3      0.004686\n",
       "gmean_bins4     0.003814\n",
       "gkurto_bins7    0.002535\n",
       "rstd_bins6      0.002258\n",
       "bmean_bins5     0.001932\n",
       "Bins0           0.001897\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualise the top 10 features that caused the major drop\n",
    "# in the roc-auc (aka model performance)\n",
    "\n",
    "feature_importance.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original number of features (rows in this case)\n",
    "feature_importance.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of features that cause a drop in performance\n",
    "# when shuffled\n",
    "\n",
    "feature_importance[feature_importance>0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Bins0', 'Bins2', 'Bins4', 'rmean_bins1', 'rmean_bins3', 'rmean_bins5',\n",
       "       'rmean_bins7', 'rstd_bins0', 'rstd_bins5', 'rstd_bins6', 'rstd_bins7',\n",
       "       'rskew_bins2', 'rskew_bins3', 'rskew_bins6', 'rskew_bins7',\n",
       "       'rkurto_bins0', 'rkurto_bins6', 'rkurto_bins7', 'gmean_bins0',\n",
       "       'gmean_bins3', 'gmean_bins4', 'gmean_bins7', 'gstd_bins0', 'gstd_bins1',\n",
       "       'gstd_bins2', 'gstd_bins5', 'gstd_bins6', 'gstd_bins7', 'gskew_bins0',\n",
       "       'gskew_bins1', 'gskew_bins7', 'gkurto_bins0', 'gkurto_bins3',\n",
       "       'gkurto_bins6', 'gkurto_bins7', 'bmean_bins4', 'bmean_bins5',\n",
       "       'bstd_bins3', 'bstd_bins4', 'bstd_bins5', 'bskew_bins3', 'bkurto_bins4',\n",
       "       'bkurto_bins6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the important features\n",
    "\n",
    "feature_importance[feature_importance>0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build random forests and\n",
    "# compare its performance in train and test sets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = rf, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.9847107937232372\n",
      "Test set\n",
      "Random Forests roc-auc: 0.969807342784442\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.89      0.91       350\n",
      "         1.0       0.91      0.94      0.92       393\n",
      "\n",
      "    accuracy                           0.92       743\n",
      "   macro avg       0.92      0.92      0.92       743\n",
      "weighted avg       0.92      0.92      0.92       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[313  37]\n",
      " [ 23 370]]\n",
      "Metrics:\n",
      "Accuracy: 0.919\n",
      "F1 Score: 0.925\n",
      "Precision: 0.909\n",
      "Recall: 0.941\n",
      "After Cross Validation:\n",
      "Accuracy: 91.98 %\n",
      "Standard Deviation: 1.97 %\n"
     ]
    }
   ],
   "source": [
    "selected_features = feature_importance[feature_importance > 0].index\n",
    "run_randomForests(X_train[selected_features], X_test[selected_features], y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def run_logistic(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    logit = LogisticRegression(penalty='l1', random_state=44, max_iter=1000, solver='liblinear')\n",
    "    logit.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = logit.predict_proba(scaler.transform(X_train))\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = logit.predict_proba(scaler.transform(X_test))\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = logit.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = logit, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.9783789951273206\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.9712831697564522\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95       350\n",
      "         1.0       0.94      0.96      0.95       393\n",
      "\n",
      "    accuracy                           0.95       743\n",
      "   macro avg       0.95      0.95      0.95       743\n",
      "weighted avg       0.95      0.95      0.95       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[327  23]\n",
      " [ 14 379]]\n",
      "Metrics:\n",
      "Accuracy: 0.950\n",
      "F1 Score: 0.953\n",
      "Precision: 0.943\n",
      "Recall: 0.964\n",
      "After Cross Validation:\n",
      "Accuracy: 94.12 %\n",
      "Standard Deviation: 1.78 %\n"
     ]
    }
   ],
   "source": [
    "run_logistic(X_train[selected_features], X_test[selected_features], y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run_kernel_SVM(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = SVC(kernel = 'rbf', random_state = 0, probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.9054686765910037\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.8992875318066158\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.66      0.72       350\n",
      "         1.0       0.74      0.85      0.79       393\n",
      "\n",
      "    accuracy                           0.76       743\n",
      "   macro avg       0.76      0.75      0.75       743\n",
      "weighted avg       0.76      0.76      0.75       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[230 120]\n",
      " [ 60 333]]\n",
      "Metrics:\n",
      "Accuracy: 0.758\n",
      "F1 Score: 0.787\n",
      "Precision: 0.735\n",
      "Recall: 0.847\n",
      "After Cross Validation:\n",
      "Accuracy: 75.07 %\n",
      "Standard Deviation: 2.66 %\n"
     ]
    }
   ],
   "source": [
    "run_kernel_SVM(X_train[selected_features], X_test[selected_features], y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def run_knn(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('KNN roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('KNN roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "KNN roc-auc: 0.5\n",
      "Test set\n",
      "KNN roc-auc: 0.5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.74      0.78       350\n",
      "         1.0       0.79      0.85      0.82       393\n",
      "\n",
      "    accuracy                           0.80       743\n",
      "   macro avg       0.80      0.80      0.80       743\n",
      "weighted avg       0.80      0.80      0.80       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[260  90]\n",
      " [ 59 334]]\n",
      "Metrics:\n",
      "Accuracy: 0.799\n",
      "F1 Score: 0.818\n",
      "Precision: 0.788\n",
      "Recall: 0.850\n",
      "After Cross Validation:\n",
      "Accuracy: 79.22 %\n",
      "Standard Deviation: 3.11 %\n"
     ]
    }
   ],
   "source": [
    "run_knn(X_train[selected_features], X_test[selected_features], y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def run_decision_tree(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(X_train)\n",
    "    print('Decision Tree roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(X_test)\n",
    "    print('Decision Tree roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Decision Tree roc-auc: 1.0\n",
      "Test set\n",
      "Decision Tree roc-auc: 0.8846673936750272\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.87      0.88       350\n",
      "         1.0       0.89      0.90      0.89       393\n",
      "\n",
      "    accuracy                           0.89       743\n",
      "   macro avg       0.89      0.88      0.89       743\n",
      "weighted avg       0.89      0.89      0.89       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[304  46]\n",
      " [ 39 354]]\n",
      "Metrics:\n",
      "Accuracy: 0.886\n",
      "F1 Score: 0.893\n",
      "Precision: 0.885\n",
      "Recall: 0.901\n",
      "After Cross Validation:\n",
      "Accuracy: 89.27 %\n",
      "Standard Deviation: 2.09 %\n"
     ]
    }
   ],
   "source": [
    "run_decision_tree(X_train[selected_features], X_test[selected_features], y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def run_naive_bayes(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.5\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.88      0.88       350\n",
      "         1.0       0.89      0.91      0.90       393\n",
      "\n",
      "    accuracy                           0.89       743\n",
      "   macro avg       0.89      0.89      0.89       743\n",
      "weighted avg       0.89      0.89      0.89       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[307  43]\n",
      " [ 37 356]]\n",
      "Metrics:\n",
      "Accuracy: 0.892\n",
      "F1 Score: 0.899\n",
      "Precision: 0.892\n",
      "Recall: 0.906\n",
      "After Cross Validation:\n",
      "Accuracy: 88.35 %\n",
      "Standard Deviation: 2.56 %\n"
     ]
    }
   ],
   "source": [
    "run_naive_bayes(X_train[selected_features], X_test[selected_features], y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run_linear_SVM(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = SVC(kernel = 'linear', random_state = 0, probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.5550632911392406\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.5471428571428572\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.90      0.92       350\n",
      "         1.0       0.91      0.96      0.94       393\n",
      "\n",
      "    accuracy                           0.93       743\n",
      "   macro avg       0.93      0.93      0.93       743\n",
      "weighted avg       0.93      0.93      0.93       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[314  36]\n",
      " [ 15 378]]\n",
      "Metrics:\n",
      "Accuracy: 0.931\n",
      "F1 Score: 0.937\n",
      "Precision: 0.913\n",
      "Recall: 0.962\n",
      "After Cross Validation:\n"
     ]
    }
   ],
   "source": [
    "run_linear_SVM(X_train[selected_features], X_test[selected_features], y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
