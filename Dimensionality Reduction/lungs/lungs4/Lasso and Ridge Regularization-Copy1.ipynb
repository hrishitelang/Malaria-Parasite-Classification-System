{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3837, 106)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('image_bins_stats_lungs4.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transformed_image_covid_1.png</td>\n",
       "      <td>4722</td>\n",
       "      <td>15567</td>\n",
       "      <td>4</td>\n",
       "      <td>7683</td>\n",
       "      <td>12061</td>\n",
       "      <td>1</td>\n",
       "      <td>8864</td>\n",
       "      <td>16634</td>\n",
       "      <td>77.433079</td>\n",
       "      <td>...</td>\n",
       "      <td>29.26670025</td>\n",
       "      <td>39.092067</td>\n",
       "      <td>21.915792</td>\n",
       "      <td>15.564234</td>\n",
       "      <td>10.232452</td>\n",
       "      <td>12.530200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.674295</td>\n",
       "      <td>31.538221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transformed_image_covid_2.png</td>\n",
       "      <td>6556</td>\n",
       "      <td>13701</td>\n",
       "      <td>25</td>\n",
       "      <td>9956</td>\n",
       "      <td>9437</td>\n",
       "      <td>0</td>\n",
       "      <td>12114</td>\n",
       "      <td>13747</td>\n",
       "      <td>79.728951</td>\n",
       "      <td>...</td>\n",
       "      <td>33.53821958</td>\n",
       "      <td>28.281468</td>\n",
       "      <td>23.127681</td>\n",
       "      <td>11.979449</td>\n",
       "      <td>17.519198</td>\n",
       "      <td>24.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.506228</td>\n",
       "      <td>36.562100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transformed_image_covid_3.png</td>\n",
       "      <td>10512</td>\n",
       "      <td>12249</td>\n",
       "      <td>1</td>\n",
       "      <td>11502</td>\n",
       "      <td>7743</td>\n",
       "      <td>2</td>\n",
       "      <td>9619</td>\n",
       "      <td>13908</td>\n",
       "      <td>68.987348</td>\n",
       "      <td>...</td>\n",
       "      <td>25.22521593</td>\n",
       "      <td>26.681675</td>\n",
       "      <td>24.442798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.323460</td>\n",
       "      <td>38.083555</td>\n",
       "      <td>4.204482</td>\n",
       "      <td>55.658016</td>\n",
       "      <td>27.952446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transformed_image_covid_4.png</td>\n",
       "      <td>7987</td>\n",
       "      <td>11854</td>\n",
       "      <td>2</td>\n",
       "      <td>10419</td>\n",
       "      <td>11895</td>\n",
       "      <td>9</td>\n",
       "      <td>11931</td>\n",
       "      <td>11439</td>\n",
       "      <td>94.638788</td>\n",
       "      <td>...</td>\n",
       "      <td>34.51618537</td>\n",
       "      <td>24.056261</td>\n",
       "      <td>28.558353</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>13.800903</td>\n",
       "      <td>27.757483</td>\n",
       "      <td>33.449086</td>\n",
       "      <td>44.809595</td>\n",
       "      <td>37.884099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transformed_image_covid_5.png</td>\n",
       "      <td>7761</td>\n",
       "      <td>14159</td>\n",
       "      <td>4</td>\n",
       "      <td>10898</td>\n",
       "      <td>10560</td>\n",
       "      <td>9</td>\n",
       "      <td>9153</td>\n",
       "      <td>12992</td>\n",
       "      <td>68.762015</td>\n",
       "      <td>...</td>\n",
       "      <td>32.13721328</td>\n",
       "      <td>27.884767</td>\n",
       "      <td>23.329477</td>\n",
       "      <td>13.445587</td>\n",
       "      <td>16.742312</td>\n",
       "      <td>28.738945</td>\n",
       "      <td>26.135224</td>\n",
       "      <td>49.330295</td>\n",
       "      <td>35.162254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        filename  Bins0  Bins1  Bins2  Bins3  Bins4  Bins5  \\\n",
       "0  transformed_image_covid_1.png   4722  15567      4   7683  12061      1   \n",
       "1  transformed_image_covid_2.png   6556  13701     25   9956   9437      0   \n",
       "2  transformed_image_covid_3.png  10512  12249      1  11502   7743      2   \n",
       "3  transformed_image_covid_4.png   7987  11854      2  10419  11895      9   \n",
       "4  transformed_image_covid_5.png   7761  14159      4  10898  10560      9   \n",
       "\n",
       "   Bins6  Bins7  rmean_bins0  ...  bskew_bins7  bkurto_bins0  bkurto_bins1  \\\n",
       "0   8864  16634    77.433079  ...  29.26670025     39.092067     21.915792   \n",
       "1  12114  13747    79.728951  ...  33.53821958     28.281468     23.127681   \n",
       "2   9619  13908    68.987348  ...  25.22521593     26.681675     24.442798   \n",
       "3  11931  11439    94.638788  ...  34.51618537     24.056261     28.558353   \n",
       "4   9153  12992    68.762015  ...  32.13721328     27.884767     23.329477   \n",
       "\n",
       "   bkurto_bins2  bkurto_bins3  bkurto_bins4  bkurto_bins5 bkurto_bins6  \\\n",
       "0     15.564234     10.232452     12.530200      0.000000    40.674295   \n",
       "1     11.979449     17.519198     24.313131      0.000000    38.506228   \n",
       "2      0.000000     12.323460     38.083555      4.204482    55.658016   \n",
       "3      0.840896     13.800903     27.757483     33.449086    44.809595   \n",
       "4     13.445587     16.742312     28.738945     26.135224    49.330295   \n",
       "\n",
       "  bkurto_bins7 class  \n",
       "0    31.538221     0  \n",
       "1    36.562100     0  \n",
       "2    27.952446     0  \n",
       "3    37.884099     0  \n",
       "4    35.162254     0  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>rmean_bins1</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4722</td>\n",
       "      <td>15567</td>\n",
       "      <td>4</td>\n",
       "      <td>7683</td>\n",
       "      <td>12061</td>\n",
       "      <td>1</td>\n",
       "      <td>8864</td>\n",
       "      <td>16634</td>\n",
       "      <td>77.433079</td>\n",
       "      <td>0.202929</td>\n",
       "      <td>...</td>\n",
       "      <td>29.26670025</td>\n",
       "      <td>39.092067</td>\n",
       "      <td>21.915792</td>\n",
       "      <td>15.564234</td>\n",
       "      <td>10.232452</td>\n",
       "      <td>12.530200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.674295</td>\n",
       "      <td>31.538221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6556</td>\n",
       "      <td>13701</td>\n",
       "      <td>25</td>\n",
       "      <td>9956</td>\n",
       "      <td>9437</td>\n",
       "      <td>0</td>\n",
       "      <td>12114</td>\n",
       "      <td>13747</td>\n",
       "      <td>79.728951</td>\n",
       "      <td>5.447851</td>\n",
       "      <td>...</td>\n",
       "      <td>33.53821958</td>\n",
       "      <td>28.281468</td>\n",
       "      <td>23.127681</td>\n",
       "      <td>11.979449</td>\n",
       "      <td>17.519198</td>\n",
       "      <td>24.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.506228</td>\n",
       "      <td>36.562100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10512</td>\n",
       "      <td>12249</td>\n",
       "      <td>1</td>\n",
       "      <td>11502</td>\n",
       "      <td>7743</td>\n",
       "      <td>2</td>\n",
       "      <td>9619</td>\n",
       "      <td>13908</td>\n",
       "      <td>68.987348</td>\n",
       "      <td>36.388358</td>\n",
       "      <td>...</td>\n",
       "      <td>25.22521593</td>\n",
       "      <td>26.681675</td>\n",
       "      <td>24.442798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.323460</td>\n",
       "      <td>38.083555</td>\n",
       "      <td>4.204482</td>\n",
       "      <td>55.658016</td>\n",
       "      <td>27.952446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7987</td>\n",
       "      <td>11854</td>\n",
       "      <td>2</td>\n",
       "      <td>10419</td>\n",
       "      <td>11895</td>\n",
       "      <td>9</td>\n",
       "      <td>11931</td>\n",
       "      <td>11439</td>\n",
       "      <td>94.638788</td>\n",
       "      <td>15.529948</td>\n",
       "      <td>...</td>\n",
       "      <td>34.51618537</td>\n",
       "      <td>24.056261</td>\n",
       "      <td>28.558353</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>13.800903</td>\n",
       "      <td>27.757483</td>\n",
       "      <td>33.449086</td>\n",
       "      <td>44.809595</td>\n",
       "      <td>37.884099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7761</td>\n",
       "      <td>14159</td>\n",
       "      <td>4</td>\n",
       "      <td>10898</td>\n",
       "      <td>10560</td>\n",
       "      <td>9</td>\n",
       "      <td>9153</td>\n",
       "      <td>12992</td>\n",
       "      <td>68.762015</td>\n",
       "      <td>4.809379</td>\n",
       "      <td>...</td>\n",
       "      <td>32.13721328</td>\n",
       "      <td>27.884767</td>\n",
       "      <td>23.329477</td>\n",
       "      <td>13.445587</td>\n",
       "      <td>16.742312</td>\n",
       "      <td>28.738945</td>\n",
       "      <td>26.135224</td>\n",
       "      <td>49.330295</td>\n",
       "      <td>35.162254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bins0  Bins1  Bins2  Bins3  Bins4  Bins5  Bins6  Bins7  rmean_bins0  \\\n",
       "0   4722  15567      4   7683  12061      1   8864  16634    77.433079   \n",
       "1   6556  13701     25   9956   9437      0  12114  13747    79.728951   \n",
       "2  10512  12249      1  11502   7743      2   9619  13908    68.987348   \n",
       "3   7987  11854      2  10419  11895      9  11931  11439    94.638788   \n",
       "4   7761  14159      4  10898  10560      9   9153  12992    68.762015   \n",
       "\n",
       "   rmean_bins1  ...  bskew_bins7  bkurto_bins0  bkurto_bins1  bkurto_bins2  \\\n",
       "0     0.202929  ...  29.26670025     39.092067     21.915792     15.564234   \n",
       "1     5.447851  ...  33.53821958     28.281468     23.127681     11.979449   \n",
       "2    36.388358  ...  25.22521593     26.681675     24.442798      0.000000   \n",
       "3    15.529948  ...  34.51618537     24.056261     28.558353      0.840896   \n",
       "4     4.809379  ...  32.13721328     27.884767     23.329477     13.445587   \n",
       "\n",
       "   bkurto_bins3  bkurto_bins4 bkurto_bins5 bkurto_bins6 bkurto_bins7 class  \n",
       "0     10.232452     12.530200     0.000000    40.674295    31.538221     0  \n",
       "1     17.519198     24.313131     0.000000    38.506228    36.562100     0  \n",
       "2     12.323460     38.083555     4.204482    55.658016    27.952446     0  \n",
       "3     13.800903     27.757483    33.449086    44.809595    37.884099     0  \n",
       "4     16.742312     28.738945    26.135224    49.330295    35.162254     0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['filename'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3837 entries, 0 to 3836\n",
      "Columns: 105 entries, Bins0 to class\n",
      "dtypes: float64(48), int64(8), object(49)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['rstd_bins0','rstd_bins1','rstd_bins2','rstd_bins3','rstd_bins4','rstd_bins5','rstd_bins6','rstd_bins7','rskew_bins0','rskew_bins1','rskew_bins2','rskew_bins3','rskew_bins4','rskew_bins5','rskew_bins6','rskew_bins7','gstd_bins0','gstd_bins1','gstd_bins2','gstd_bins3','gstd_bins4','gstd_bins5','gstd_bins6','gstd_bins7','bstd_bins0','bstd_bins1','bstd_bins2','bstd_bins3','bstd_bins4','bstd_bins5','bstd_bins6','bstd_bins7','gskew_bins0','gskew_bins1','gskew_bins2','gskew_bins3','gskew_bins4','gskew_bins5','gskew_bins6','gskew_bins7','bskew_bins0','bskew_bins1','bskew_bins2','bskew_bins3','bskew_bins4','bskew_bins5','bskew_bins6','bskew_bins7','class']\n",
    "for i in name:\n",
    "    data[i] = pd.to_numeric(data[i],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3837 entries, 0 to 3836\n",
      "Columns: 105 entries, Bins0 to class\n",
      "dtypes: float64(97), int64(8)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>rmean_bins1</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4722.0</td>\n",
       "      <td>15567.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7683.0</td>\n",
       "      <td>12061.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8864.0</td>\n",
       "      <td>16634.0</td>\n",
       "      <td>77.433079</td>\n",
       "      <td>0.202929</td>\n",
       "      <td>...</td>\n",
       "      <td>29.266700</td>\n",
       "      <td>39.092067</td>\n",
       "      <td>21.915792</td>\n",
       "      <td>15.564234</td>\n",
       "      <td>10.232452</td>\n",
       "      <td>12.530200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.674295</td>\n",
       "      <td>31.538221</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6556.0</td>\n",
       "      <td>13701.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9956.0</td>\n",
       "      <td>9437.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12114.0</td>\n",
       "      <td>13747.0</td>\n",
       "      <td>79.728951</td>\n",
       "      <td>5.447851</td>\n",
       "      <td>...</td>\n",
       "      <td>33.538220</td>\n",
       "      <td>28.281468</td>\n",
       "      <td>23.127681</td>\n",
       "      <td>11.979449</td>\n",
       "      <td>17.519198</td>\n",
       "      <td>24.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.506228</td>\n",
       "      <td>36.562100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10512.0</td>\n",
       "      <td>12249.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11502.0</td>\n",
       "      <td>7743.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9619.0</td>\n",
       "      <td>13908.0</td>\n",
       "      <td>68.987348</td>\n",
       "      <td>36.388358</td>\n",
       "      <td>...</td>\n",
       "      <td>25.225216</td>\n",
       "      <td>26.681675</td>\n",
       "      <td>24.442798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.323460</td>\n",
       "      <td>38.083555</td>\n",
       "      <td>4.204482</td>\n",
       "      <td>55.658016</td>\n",
       "      <td>27.952446</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7987.0</td>\n",
       "      <td>11854.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10419.0</td>\n",
       "      <td>11895.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11931.0</td>\n",
       "      <td>11439.0</td>\n",
       "      <td>94.638788</td>\n",
       "      <td>15.529948</td>\n",
       "      <td>...</td>\n",
       "      <td>34.516185</td>\n",
       "      <td>24.056261</td>\n",
       "      <td>28.558353</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>13.800903</td>\n",
       "      <td>27.757483</td>\n",
       "      <td>33.449086</td>\n",
       "      <td>44.809595</td>\n",
       "      <td>37.884099</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7761.0</td>\n",
       "      <td>14159.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10898.0</td>\n",
       "      <td>10560.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9153.0</td>\n",
       "      <td>12992.0</td>\n",
       "      <td>68.762015</td>\n",
       "      <td>4.809379</td>\n",
       "      <td>...</td>\n",
       "      <td>32.137213</td>\n",
       "      <td>27.884767</td>\n",
       "      <td>23.329477</td>\n",
       "      <td>13.445587</td>\n",
       "      <td>16.742312</td>\n",
       "      <td>28.738945</td>\n",
       "      <td>26.135224</td>\n",
       "      <td>49.330295</td>\n",
       "      <td>35.162254</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3832</th>\n",
       "      <td>9870.0</td>\n",
       "      <td>10436.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9558.0</td>\n",
       "      <td>9764.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16080.0</td>\n",
       "      <td>9815.0</td>\n",
       "      <td>104.708207</td>\n",
       "      <td>27.440974</td>\n",
       "      <td>...</td>\n",
       "      <td>28.826381</td>\n",
       "      <td>16.609479</td>\n",
       "      <td>32.541509</td>\n",
       "      <td>10.841782</td>\n",
       "      <td>18.263777</td>\n",
       "      <td>29.591836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.584547</td>\n",
       "      <td>43.219779</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3833</th>\n",
       "      <td>5946.0</td>\n",
       "      <td>14026.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11041.0</td>\n",
       "      <td>12415.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7886.0</td>\n",
       "      <td>14221.0</td>\n",
       "      <td>74.044736</td>\n",
       "      <td>1.607016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.246127</td>\n",
       "      <td>30.936390</td>\n",
       "      <td>21.337923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.706518</td>\n",
       "      <td>17.877323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.339391</td>\n",
       "      <td>32.611797</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3834</th>\n",
       "      <td>7330.0</td>\n",
       "      <td>8408.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10811.0</td>\n",
       "      <td>18521.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6699.0</td>\n",
       "      <td>13759.0</td>\n",
       "      <td>112.515416</td>\n",
       "      <td>7.136774</td>\n",
       "      <td>...</td>\n",
       "      <td>28.790502</td>\n",
       "      <td>42.515393</td>\n",
       "      <td>18.625921</td>\n",
       "      <td>11.891740</td>\n",
       "      <td>14.170267</td>\n",
       "      <td>3.991819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.311970</td>\n",
       "      <td>41.914116</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3835</th>\n",
       "      <td>7630.0</td>\n",
       "      <td>16431.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9530.0</td>\n",
       "      <td>3413.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17843.0</td>\n",
       "      <td>10685.0</td>\n",
       "      <td>73.122412</td>\n",
       "      <td>24.310145</td>\n",
       "      <td>...</td>\n",
       "      <td>37.426827</td>\n",
       "      <td>20.622111</td>\n",
       "      <td>29.148814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.197666</td>\n",
       "      <td>31.678731</td>\n",
       "      <td>4.769168</td>\n",
       "      <td>50.967873</td>\n",
       "      <td>38.781249</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>5415.0</td>\n",
       "      <td>17347.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8790.0</td>\n",
       "      <td>12865.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8924.0</td>\n",
       "      <td>12193.0</td>\n",
       "      <td>60.702862</td>\n",
       "      <td>1.042082</td>\n",
       "      <td>...</td>\n",
       "      <td>34.588816</td>\n",
       "      <td>33.378388</td>\n",
       "      <td>26.261638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.291031</td>\n",
       "      <td>20.163037</td>\n",
       "      <td>5.045378</td>\n",
       "      <td>45.099627</td>\n",
       "      <td>35.944590</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3823 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bins0    Bins1  Bins2    Bins3    Bins4  Bins5    Bins6    Bins7  \\\n",
       "0      4722.0  15567.0    4.0   7683.0  12061.0    1.0   8864.0  16634.0   \n",
       "1      6556.0  13701.0   25.0   9956.0   9437.0    0.0  12114.0  13747.0   \n",
       "2     10512.0  12249.0    1.0  11502.0   7743.0    2.0   9619.0  13908.0   \n",
       "3      7987.0  11854.0    2.0  10419.0  11895.0    9.0  11931.0  11439.0   \n",
       "4      7761.0  14159.0    4.0  10898.0  10560.0    9.0   9153.0  12992.0   \n",
       "...       ...      ...    ...      ...      ...    ...      ...      ...   \n",
       "3832   9870.0  10436.0   13.0   9558.0   9764.0    0.0  16080.0   9815.0   \n",
       "3833   5946.0  14026.0    1.0  11041.0  12415.0    0.0   7886.0  14221.0   \n",
       "3834   7330.0   8408.0    6.0  10811.0  18521.0    2.0   6699.0  13759.0   \n",
       "3835   7630.0  16431.0    1.0   9530.0   3413.0    3.0  17843.0  10685.0   \n",
       "3836   5415.0  17347.0    0.0   8790.0  12865.0    2.0   8924.0  12193.0   \n",
       "\n",
       "      rmean_bins0  rmean_bins1  ...  bskew_bins7  bkurto_bins0  bkurto_bins1  \\\n",
       "0       77.433079     0.202929  ...    29.266700     39.092067     21.915792   \n",
       "1       79.728951     5.447851  ...    33.538220     28.281468     23.127681   \n",
       "2       68.987348    36.388358  ...    25.225216     26.681675     24.442798   \n",
       "3       94.638788    15.529948  ...    34.516185     24.056261     28.558353   \n",
       "4       68.762015     4.809379  ...    32.137213     27.884767     23.329477   \n",
       "...           ...          ...  ...          ...           ...           ...   \n",
       "3832   104.708207    27.440974  ...    28.826381     16.609479     32.541509   \n",
       "3833    74.044736     1.607016  ...    39.246127     30.936390     21.337923   \n",
       "3834   112.515416     7.136774  ...    28.790502     42.515393     18.625921   \n",
       "3835    73.122412    24.310145  ...    37.426827     20.622111     29.148814   \n",
       "3836    60.702862     1.042082  ...    34.588816     33.378388     26.261638   \n",
       "\n",
       "      bkurto_bins2  bkurto_bins3  bkurto_bins4  bkurto_bins5  bkurto_bins6  \\\n",
       "0        15.564234     10.232452     12.530200      0.000000     40.674295   \n",
       "1        11.979449     17.519198     24.313131      0.000000     38.506228   \n",
       "2         0.000000     12.323460     38.083555      4.204482     55.658016   \n",
       "3         0.840896     13.800903     27.757483     33.449086     44.809595   \n",
       "4        13.445587     16.742312     28.738945     26.135224     49.330295   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "3832     10.841782     18.263777     29.591836      0.000000     43.584547   \n",
       "3833      0.000000      9.706518     17.877323      0.000000     45.339391   \n",
       "3834     11.891740     14.170267      3.991819      0.000000     36.311970   \n",
       "3835      0.000000     20.197666     31.678731      4.769168     50.967873   \n",
       "3836      0.000000     17.291031     20.163037      5.045378     45.099627   \n",
       "\n",
       "      bkurto_bins7  class  \n",
       "0        31.538221    0.0  \n",
       "1        36.562100    0.0  \n",
       "2        27.952446    0.0  \n",
       "3        37.884099    0.0  \n",
       "4        35.162254    0.0  \n",
       "...            ...    ...  \n",
       "3832     43.219779    2.0  \n",
       "3833     32.611797    2.0  \n",
       "3834     41.914116    2.0  \n",
       "3835     38.781249    2.0  \n",
       "3836     35.944590    2.0  \n",
       "\n",
       "[3823 rows x 105 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)\n",
    "\n",
    "clean_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2676, 104), (1147, 104))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['class'], axis=1),\n",
    "    data['class'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear models benefit from feature scaling\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=0.07, penalty='l1',\n",
       "                                             random_state=10,\n",
       "                                             solver='liblinear'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here I will do the model fitting and feature selection\n",
    "# altogether in one line of code\n",
    "\n",
    "# first I specify the Logistic Regression model, and I\n",
    "# make sure I select the Lasso (l1) penalty.\n",
    "\n",
    "# Then I use the selectFromModel class from sklearn, which\n",
    "# will select the features which coefficients are non-zero\n",
    "\n",
    "sel_ = SelectFromModel(\n",
    "    LogisticRegression(C=0.07, penalty='l1', solver='liblinear', random_state=10))\n",
    "\n",
    "sel_.fit(scaler.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True, False, False,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "        True,  True,  True,  True, False,  True, False, False,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True, False, False,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "       False,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "       False,  True, False, False, False, False,  True,  True,  True,\n",
       "        True,  True,  True, False,  True])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this command let's me visualise the index of the\n",
    "# features that were selected\n",
    "\n",
    "sel_.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 104\n",
      "selected features: 80\n",
      "features with coefficients shrank to zero: 163\n"
     ]
    }
   ],
   "source": [
    "# Now I make a list with the selected features\n",
    "selected_feat = X_train.columns[(sel_.get_support())]\n",
    "\n",
    "print('total features: {}'.format((X_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "    np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of features which coefficient was shrank to zero:\n",
    "np.sum(sel_.estimator_.coef_ == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 104 but corresponding boolean dimension is 312",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-62b739b82e64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# we can identify the removed features like this:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mremoved_feats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mremoved_feats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3940\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3941\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3942\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3943\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 104 but corresponding boolean dimension is 312"
     ]
    }
   ],
   "source": [
    "# we can identify the removed features like this:\n",
    "\n",
    "removed_feats = X_train.columns[(sel_.estimator_.coef_ == 0).ravel().tolist()]\n",
    "removed_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2676, 80), (1147, 80))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can then remove the features from the training and testing set\n",
    "# like this:\n",
    "\n",
    "X_train_selected = sel_.transform(X_train)\n",
    "X_test_selected = sel_.transform(X_test)\n",
    "\n",
    "X_train_selected.shape, X_test_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Bins0', 'Bins1', 'Bins2', 'Bins3', 'Bins6', 'Bins7', 'rmean_bins0',\n",
       "       'rmean_bins1', 'rmean_bins2', 'rmean_bins4', 'rmean_bins5',\n",
       "       'rmean_bins6', 'rmean_bins7', 'rstd_bins0', 'rstd_bins1', 'rstd_bins2',\n",
       "       'rstd_bins3', 'rstd_bins4', 'rstd_bins5', 'rstd_bins6', 'rstd_bins7',\n",
       "       'rskew_bins0', 'rskew_bins3', 'rskew_bins4', 'rskew_bins5',\n",
       "       'rskew_bins6', 'rkurto_bins0', 'rkurto_bins3', 'rkurto_bins4',\n",
       "       'rkurto_bins6', 'rkurto_bins7', 'gmean_bins0', 'gmean_bins1',\n",
       "       'gmean_bins2', 'gmean_bins3', 'gmean_bins4', 'gmean_bins5',\n",
       "       'gmean_bins6', 'gstd_bins0', 'gstd_bins1', 'gstd_bins2', 'gstd_bins3',\n",
       "       'gstd_bins4', 'gstd_bins5', 'gstd_bins6', 'gstd_bins7', 'gskew_bins0',\n",
       "       'gskew_bins2', 'gskew_bins3', 'gskew_bins6', 'gskew_bins7',\n",
       "       'gkurto_bins0', 'gkurto_bins1', 'gkurto_bins2', 'gkurto_bins3',\n",
       "       'gkurto_bins5', 'gkurto_bins6', 'bmean_bins1', 'bmean_bins2',\n",
       "       'bmean_bins3', 'bmean_bins5', 'bmean_bins6', 'bmean_bins7',\n",
       "       'bstd_bins0', 'bstd_bins1', 'bstd_bins2', 'bstd_bins3', 'bstd_bins4',\n",
       "       'bstd_bins5', 'bstd_bins7', 'bskew_bins0', 'bskew_bins1', 'bskew_bins3',\n",
       "       'bkurto_bins0', 'bkurto_bins1', 'bkurto_bins2', 'bkurto_bins3',\n",
       "       'bkurto_bins4', 'bkurto_bins5', 'bkurto_bins7'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build random forests and\n",
    "# compare its performance in train and test sets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "#     print('Train set')\n",
    "#     pred = rf.predict_proba(X_train)\n",
    "#     print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "#     print('Test set')\n",
    "#     pred = rf.predict_proba(X_test)\n",
    "#     print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred, average='micro')))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred, average='micro')))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred, average='micro')))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = rf, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.79      0.81       364\n",
      "         1.0       0.72      0.81      0.76       378\n",
      "         2.0       0.70      0.66      0.68       405\n",
      "\n",
      "    accuracy                           0.75      1147\n",
      "   macro avg       0.76      0.75      0.75      1147\n",
      "weighted avg       0.75      0.75      0.75      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[286  27  51]\n",
      " [  9 308  61]\n",
      " [ 44  94 267]]\n",
      "Metrics:\n",
      "Accuracy: 0.751\n",
      "F1 Score: 0.751\n",
      "Precision: 0.751\n",
      "Recall: 0.751\n",
      "After Cross Validation:\n",
      "Accuracy: 73.58 %\n",
      "Standard Deviation: 1.42 %\n"
     ]
    }
   ],
   "source": [
    "run_randomForests(X_train_selected, X_test_selected, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def run_logistic(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    logit = LogisticRegression(penalty='l1', random_state=44, max_iter=1000, solver='liblinear')\n",
    "    logit.fit(X_train, y_train)\n",
    "    \n",
    "#     print('Train set')\n",
    "#     pred = logit.predict_proba(scaler.transform(X_train))\n",
    "#     print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "#     print('Test set')\n",
    "#     pred = logit.predict_proba(scaler.transform(X_test))\n",
    "#     print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = logit.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred, average='micro')))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred, average='micro')))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred, average='micro')))\n",
    "    \n",
    "#     print('After Cross Validation:')\n",
    "#     accuracies = cross_val_score(estimator = logit, X = X_train, y = y_train, cv = 10)\n",
    "#     print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "#     print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.89      0.88       364\n",
      "         1.0       0.80      0.87      0.83       378\n",
      "         2.0       0.82      0.74      0.78       405\n",
      "\n",
      "    accuracy                           0.83      1147\n",
      "   macro avg       0.83      0.83      0.83      1147\n",
      "weighted avg       0.83      0.83      0.83      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[323  15  26]\n",
      " [  9 329  40]\n",
      " [ 38  69 298]]\n",
      "Metrics:\n",
      "Accuracy: 0.828\n",
      "F1 Score: 0.828\n",
      "Precision: 0.828\n",
      "Recall: 0.828\n"
     ]
    }
   ],
   "source": [
    "run_logistic(X_train_selected, X_test_selected, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run_kernel_SVM(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = SVC(kernel = 'rbf', random_state = 0, probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "#     print('Train set')\n",
    "#     pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "#     print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "#     print('Test set')\n",
    "#     pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "#     print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred, average='micro')))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred, average='micro')))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred, average='micro')))\n",
    "    \n",
    "#     print('After Cross Validation:')\n",
    "#     accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "#     print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "#     print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.50      0.58       364\n",
      "         1.0       0.52      0.83      0.64       378\n",
      "         2.0       0.51      0.34      0.41       405\n",
      "\n",
      "    accuracy                           0.55      1147\n",
      "   macro avg       0.57      0.56      0.54      1147\n",
      "weighted avg       0.57      0.55      0.54      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[182  91  91]\n",
      " [ 22 314  42]\n",
      " [ 65 201 139]]\n",
      "Metrics:\n",
      "Accuracy: 0.554\n",
      "F1 Score: 0.554\n",
      "Precision: 0.554\n",
      "Recall: 0.554\n"
     ]
    }
   ],
   "source": [
    "run_kernel_SVM(X_train_selected, X_test_selected, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def run_knn(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "#     print('Train set')\n",
    "#     pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "#     print('KNN roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "#     print('Test set')\n",
    "#     pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "#     print('KNN roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred, average='micro')))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred, average='micro')))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred, average='micro')))\n",
    "    \n",
    "#     print('After Cross Validation:')\n",
    "#     accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "#     print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "#     print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.72      0.69       364\n",
      "         1.0       0.64      0.75      0.69       378\n",
      "         2.0       0.63      0.47      0.54       405\n",
      "\n",
      "    accuracy                           0.64      1147\n",
      "   macro avg       0.64      0.65      0.64      1147\n",
      "weighted avg       0.64      0.64      0.64      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[263  42  59]\n",
      " [ 41 284  53]\n",
      " [ 93 121 191]]\n",
      "Metrics:\n",
      "Accuracy: 0.643\n",
      "F1 Score: 0.643\n",
      "Precision: 0.643\n",
      "Recall: 0.643\n"
     ]
    }
   ],
   "source": [
    "run_knn(X_train_selected, X_test_selected, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def run_decision_tree(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "#     print('Train set')\n",
    "#     pred = classifier.predict_proba(X_train)\n",
    "#     print('Decision Tree roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "#     print('Test set')\n",
    "#     pred = classifier.predict_proba(X_test)\n",
    "#     print('Decision Tree roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred, average='micro')))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred, average='micro')))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred, average='micro')))\n",
    "    \n",
    "#     print('After Cross Validation:')\n",
    "#     accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "#     print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "#     print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.76      0.76       364\n",
      "         1.0       0.70      0.70      0.70       378\n",
      "         2.0       0.65      0.64      0.65       405\n",
      "\n",
      "    accuracy                           0.70      1147\n",
      "   macro avg       0.70      0.70      0.70      1147\n",
      "weighted avg       0.70      0.70      0.70      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[278  28  58]\n",
      " [ 30 265  83]\n",
      " [ 56  88 261]]\n",
      "Metrics:\n",
      "Accuracy: 0.701\n",
      "F1 Score: 0.701\n",
      "Precision: 0.701\n",
      "Recall: 0.701\n"
     ]
    }
   ],
   "source": [
    "run_decision_tree(X_train_selected, X_test_selected, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run_linear_SVM(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = SVC(kernel = 'linear', random_state = 0, probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "#     print('Train set')\n",
    "#     pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "#     print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "#     print('Test set')\n",
    "#     pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "#     print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred, average='micro')))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred, average='micro')))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred, average='micro')))\n",
    "    \n",
    "#     print('After Cross Validation:')\n",
    "#     accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "#     print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "#     print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_linear_SVM(X_train_selected, X_test_selected, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def run_naive_bayes(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "#     print('Train set')\n",
    "#     pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "#     print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "#     print('Test set')\n",
    "#     pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "#     print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred, average='micro')))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred, average='micro')))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred, average='micro')))\n",
    "    \n",
    "#     print('After Cross Validation:')\n",
    "#     accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "#     print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "#     print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.63      0.69       364\n",
      "         1.0       0.69      0.83      0.75       378\n",
      "         2.0       0.60      0.58      0.59       405\n",
      "\n",
      "    accuracy                           0.68      1147\n",
      "   macro avg       0.69      0.68      0.68      1147\n",
      "weighted avg       0.68      0.68      0.68      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[229  26 109]\n",
      " [ 17 315  46]\n",
      " [ 53 117 235]]\n",
      "Metrics:\n",
      "Accuracy: 0.679\n",
      "F1 Score: 0.679\n",
      "Precision: 0.679\n",
      "Recall: 0.679\n"
     ]
    }
   ],
   "source": [
    "run_naive_bayes(X_train_selected, X_test_selected, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For comparison, I will fit a logistic regression with a\n",
    "# Ridge regularisation, and evaluate the coefficients\n",
    "\n",
    "l1_logit = LogisticRegression(C=0.5, penalty='l2', max_iter=300, random_state=10)\n",
    "l1_logit.fit(scaler.transform(X_train), y_train)\n",
    "\n",
    "# I count the number of coefficients with zero values\n",
    "# and it is zero, as expected\n",
    "np.sum(l1_logit.coef_ == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=0.5, random_state=10,\n",
       "                                             solver='liblinear'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here I will do the model fitting and feature selection\n",
    "# altogether in one line of code\n",
    "\n",
    "# first I specify the Logistic Regression model, and I\n",
    "# make sure I select the Lasso (l1) penalty.\n",
    "\n",
    "# Then I use the selectFromModel class from sklearn, which\n",
    "# will select the features which coefficients are non-zero\n",
    "\n",
    "sel_ = SelectFromModel(\n",
    "    LogisticRegression(C=0.5, penalty='l2', solver='liblinear', random_state=10))\n",
    "\n",
    "sel_.fit(scaler.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True, False,  True, False,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True, False, False,\n",
       "       False, False,  True, False,  True,  True, False, False, False,\n",
       "        True, False, False,  True,  True,  True, False, False,  True,\n",
       "        True, False,  True,  True,  True,  True, False,  True,  True,\n",
       "        True, False, False,  True, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "        True,  True, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True,  True, False,  True,  True])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this command let's me visualise the index of the\n",
    "# features that were selected\n",
    "\n",
    "sel_.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 104\n",
      "selected features: 40\n",
      "features with coefficients shrank to zero: 0\n"
     ]
    }
   ],
   "source": [
    "# Now I make a list with the selected features\n",
    "selected_feat = X_train.columns[(sel_.get_support())]\n",
    "\n",
    "print('total features: {}'.format((X_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "    np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 104 but corresponding boolean dimension is 312",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-62b739b82e64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# we can identify the removed features like this:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mremoved_feats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mremoved_feats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3940\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3941\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3942\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3943\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 104 but corresponding boolean dimension is 312"
     ]
    }
   ],
   "source": [
    "# we can identify the removed features like this:\n",
    "\n",
    "removed_feats = X_train.columns[(sel_.estimator_.coef_ == 0).ravel().tolist()]\n",
    "removed_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2676, 40), (1147, 40))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can then remove the features from the training and testing set\n",
    "# like this:\n",
    "\n",
    "X_train_ridge = sel_.transform(X_train)\n",
    "X_test_ridge = sel_.transform(X_test)\n",
    "\n",
    "X_train_ridge.shape, X_test_ridge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Bins0', 'Bins1', 'Bins2', 'Bins3', 'Bins5', 'Bins7', 'rmean_bins0',\n",
       "       'rmean_bins1', 'rmean_bins3', 'rmean_bins4', 'rmean_bins5',\n",
       "       'rmean_bins6', 'rmean_bins7', 'rstd_bins4', 'rstd_bins6', 'rstd_bins7',\n",
       "       'rskew_bins3', 'rskew_bins6', 'rskew_bins7', 'rkurto_bins0',\n",
       "       'rkurto_bins3', 'rkurto_bins4', 'rkurto_bins6', 'rkurto_bins7',\n",
       "       'gmean_bins0', 'gmean_bins1', 'gmean_bins3', 'gmean_bins4',\n",
       "       'gmean_bins5', 'gstd_bins0', 'gstd_bins3', 'gkurto_bins6',\n",
       "       'bmean_bins0', 'bmean_bins1', 'bmean_bins3', 'bkurto_bins0',\n",
       "       'bkurto_bins3', 'bkurto_bins4', 'bkurto_bins6', 'bkurto_bins7'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.77      0.80       364\n",
      "         1.0       0.72      0.80      0.76       378\n",
      "         2.0       0.70      0.66      0.68       405\n",
      "\n",
      "    accuracy                           0.74      1147\n",
      "   macro avg       0.75      0.74      0.74      1147\n",
      "weighted avg       0.74      0.74      0.74      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[282  28  54]\n",
      " [ 13 302  63]\n",
      " [ 47  91 267]]\n",
      "Metrics:\n",
      "Accuracy: 0.742\n",
      "F1 Score: 0.742\n",
      "Precision: 0.742\n",
      "Recall: 0.742\n",
      "After Cross Validation:\n",
      "Accuracy: 73.13 %\n",
      "Standard Deviation: 2.21 %\n"
     ]
    }
   ],
   "source": [
    "run_randomForests(X_train_ridge, X_test_ridge, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.86      0.88       364\n",
      "         1.0       0.78      0.88      0.83       378\n",
      "         2.0       0.82      0.75      0.79       405\n",
      "\n",
      "    accuracy                           0.83      1147\n",
      "   macro avg       0.83      0.83      0.83      1147\n",
      "weighted avg       0.83      0.83      0.83      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[314  22  28]\n",
      " [  8 332  38]\n",
      " [ 28  72 305]]\n",
      "Metrics:\n",
      "Accuracy: 0.829\n",
      "F1 Score: 0.829\n",
      "Precision: 0.829\n",
      "Recall: 0.829\n"
     ]
    }
   ],
   "source": [
    "run_logistic(X_train_ridge, X_test_ridge, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.45      0.54       364\n",
      "         1.0       0.48      0.89      0.62       378\n",
      "         2.0       0.53      0.26      0.35       405\n",
      "\n",
      "    accuracy                           0.53      1147\n",
      "   macro avg       0.56      0.53      0.50      1147\n",
      "weighted avg       0.56      0.53      0.50      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[165 126  73]\n",
      " [ 22 336  20]\n",
      " [ 60 239 106]]\n",
      "Metrics:\n",
      "Accuracy: 0.529\n",
      "F1 Score: 0.529\n",
      "Precision: 0.529\n",
      "Recall: 0.529\n"
     ]
    }
   ],
   "source": [
    "run_kernel_SVM(X_train_ridge, X_test_ridge, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.72      0.68       364\n",
      "         1.0       0.63      0.73      0.67       378\n",
      "         2.0       0.63      0.47      0.54       405\n",
      "\n",
      "    accuracy                           0.63      1147\n",
      "   macro avg       0.63      0.64      0.63      1147\n",
      "weighted avg       0.63      0.63      0.63      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[262  44  58]\n",
      " [ 47 275  56]\n",
      " [ 94 120 191]]\n",
      "Metrics:\n",
      "Accuracy: 0.635\n",
      "F1 Score: 0.635\n",
      "Precision: 0.635\n",
      "Recall: 0.635\n"
     ]
    }
   ],
   "source": [
    "run_knn(X_train_ridge, X_test_ridge, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.78      0.80       364\n",
      "         1.0       0.71      0.75      0.73       378\n",
      "         2.0       0.66      0.66      0.66       405\n",
      "\n",
      "    accuracy                           0.73      1147\n",
      "   macro avg       0.73      0.73      0.73      1147\n",
      "weighted avg       0.73      0.73      0.73      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[284  25  55]\n",
      " [ 14 283  81]\n",
      " [ 48  90 267]]\n",
      "Metrics:\n",
      "Accuracy: 0.727\n",
      "F1 Score: 0.727\n",
      "Precision: 0.727\n",
      "Recall: 0.727\n"
     ]
    }
   ],
   "source": [
    "run_decision_tree(X_train_ridge, X_test_ridge, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.60      0.68       364\n",
      "         1.0       0.63      0.83      0.71       378\n",
      "         2.0       0.57      0.51      0.54       405\n",
      "\n",
      "    accuracy                           0.64      1147\n",
      "   macro avg       0.66      0.65      0.64      1147\n",
      "weighted avg       0.65      0.64      0.64      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[220  39 105]\n",
      " [ 13 313  52]\n",
      " [ 52 147 206]]\n",
      "Metrics:\n",
      "Accuracy: 0.644\n",
      "F1 Score: 0.644\n",
      "Precision: 0.644\n",
      "Recall: 0.644\n"
     ]
    }
   ],
   "source": [
    "run_naive_bayes(X_train_ridge, X_test_ridge, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-a716445bd79d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun_linear_SVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_ridge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_ridge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-8daa3ed88160>\u001b[0m in \u001b[0;36mrun_linear_SVM\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# function to train and test the performance of logistic regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#     print('Train set')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_vectors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_support\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual_coef_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_probA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m             self._probB, self.fit_status_ = libsvm.fit(\n\u001b[0m\u001b[0;32m    269\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                 \u001b[0msvm_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_linear_SVM(X_train_ridge, X_test_ridge, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
