{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold, f_classif, SelectKBest\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3837, 106)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('image_bins_stats_lungs4.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transformed_image_covid_1.png</td>\n",
       "      <td>4722</td>\n",
       "      <td>15567</td>\n",
       "      <td>4</td>\n",
       "      <td>7683</td>\n",
       "      <td>12061</td>\n",
       "      <td>1</td>\n",
       "      <td>8864</td>\n",
       "      <td>16634</td>\n",
       "      <td>77.433079</td>\n",
       "      <td>...</td>\n",
       "      <td>29.26670025</td>\n",
       "      <td>39.092067</td>\n",
       "      <td>21.915792</td>\n",
       "      <td>15.564234</td>\n",
       "      <td>10.232452</td>\n",
       "      <td>12.530200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.674295</td>\n",
       "      <td>31.538221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transformed_image_covid_2.png</td>\n",
       "      <td>6556</td>\n",
       "      <td>13701</td>\n",
       "      <td>25</td>\n",
       "      <td>9956</td>\n",
       "      <td>9437</td>\n",
       "      <td>0</td>\n",
       "      <td>12114</td>\n",
       "      <td>13747</td>\n",
       "      <td>79.728951</td>\n",
       "      <td>...</td>\n",
       "      <td>33.53821958</td>\n",
       "      <td>28.281468</td>\n",
       "      <td>23.127681</td>\n",
       "      <td>11.979449</td>\n",
       "      <td>17.519198</td>\n",
       "      <td>24.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.506228</td>\n",
       "      <td>36.562100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transformed_image_covid_3.png</td>\n",
       "      <td>10512</td>\n",
       "      <td>12249</td>\n",
       "      <td>1</td>\n",
       "      <td>11502</td>\n",
       "      <td>7743</td>\n",
       "      <td>2</td>\n",
       "      <td>9619</td>\n",
       "      <td>13908</td>\n",
       "      <td>68.987348</td>\n",
       "      <td>...</td>\n",
       "      <td>25.22521593</td>\n",
       "      <td>26.681675</td>\n",
       "      <td>24.442798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.323460</td>\n",
       "      <td>38.083555</td>\n",
       "      <td>4.204482</td>\n",
       "      <td>55.658016</td>\n",
       "      <td>27.952446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transformed_image_covid_4.png</td>\n",
       "      <td>7987</td>\n",
       "      <td>11854</td>\n",
       "      <td>2</td>\n",
       "      <td>10419</td>\n",
       "      <td>11895</td>\n",
       "      <td>9</td>\n",
       "      <td>11931</td>\n",
       "      <td>11439</td>\n",
       "      <td>94.638788</td>\n",
       "      <td>...</td>\n",
       "      <td>34.51618537</td>\n",
       "      <td>24.056261</td>\n",
       "      <td>28.558353</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>13.800903</td>\n",
       "      <td>27.757483</td>\n",
       "      <td>33.449086</td>\n",
       "      <td>44.809595</td>\n",
       "      <td>37.884099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transformed_image_covid_5.png</td>\n",
       "      <td>7761</td>\n",
       "      <td>14159</td>\n",
       "      <td>4</td>\n",
       "      <td>10898</td>\n",
       "      <td>10560</td>\n",
       "      <td>9</td>\n",
       "      <td>9153</td>\n",
       "      <td>12992</td>\n",
       "      <td>68.762015</td>\n",
       "      <td>...</td>\n",
       "      <td>32.13721328</td>\n",
       "      <td>27.884767</td>\n",
       "      <td>23.329477</td>\n",
       "      <td>13.445587</td>\n",
       "      <td>16.742312</td>\n",
       "      <td>28.738945</td>\n",
       "      <td>26.135224</td>\n",
       "      <td>49.330295</td>\n",
       "      <td>35.162254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        filename  Bins0  Bins1  Bins2  Bins3  Bins4  Bins5  \\\n",
       "0  transformed_image_covid_1.png   4722  15567      4   7683  12061      1   \n",
       "1  transformed_image_covid_2.png   6556  13701     25   9956   9437      0   \n",
       "2  transformed_image_covid_3.png  10512  12249      1  11502   7743      2   \n",
       "3  transformed_image_covid_4.png   7987  11854      2  10419  11895      9   \n",
       "4  transformed_image_covid_5.png   7761  14159      4  10898  10560      9   \n",
       "\n",
       "   Bins6  Bins7  rmean_bins0  ...  bskew_bins7  bkurto_bins0  bkurto_bins1  \\\n",
       "0   8864  16634    77.433079  ...  29.26670025     39.092067     21.915792   \n",
       "1  12114  13747    79.728951  ...  33.53821958     28.281468     23.127681   \n",
       "2   9619  13908    68.987348  ...  25.22521593     26.681675     24.442798   \n",
       "3  11931  11439    94.638788  ...  34.51618537     24.056261     28.558353   \n",
       "4   9153  12992    68.762015  ...  32.13721328     27.884767     23.329477   \n",
       "\n",
       "   bkurto_bins2  bkurto_bins3  bkurto_bins4  bkurto_bins5 bkurto_bins6  \\\n",
       "0     15.564234     10.232452     12.530200      0.000000    40.674295   \n",
       "1     11.979449     17.519198     24.313131      0.000000    38.506228   \n",
       "2      0.000000     12.323460     38.083555      4.204482    55.658016   \n",
       "3      0.840896     13.800903     27.757483     33.449086    44.809595   \n",
       "4     13.445587     16.742312     28.738945     26.135224    49.330295   \n",
       "\n",
       "  bkurto_bins7 class  \n",
       "0    31.538221     0  \n",
       "1    36.562100     0  \n",
       "2    27.952446     0  \n",
       "3    37.884099     0  \n",
       "4    35.162254     0  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>rmean_bins1</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4722</td>\n",
       "      <td>15567</td>\n",
       "      <td>4</td>\n",
       "      <td>7683</td>\n",
       "      <td>12061</td>\n",
       "      <td>1</td>\n",
       "      <td>8864</td>\n",
       "      <td>16634</td>\n",
       "      <td>77.433079</td>\n",
       "      <td>0.202929</td>\n",
       "      <td>...</td>\n",
       "      <td>29.26670025</td>\n",
       "      <td>39.092067</td>\n",
       "      <td>21.915792</td>\n",
       "      <td>15.564234</td>\n",
       "      <td>10.232452</td>\n",
       "      <td>12.530200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.674295</td>\n",
       "      <td>31.538221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6556</td>\n",
       "      <td>13701</td>\n",
       "      <td>25</td>\n",
       "      <td>9956</td>\n",
       "      <td>9437</td>\n",
       "      <td>0</td>\n",
       "      <td>12114</td>\n",
       "      <td>13747</td>\n",
       "      <td>79.728951</td>\n",
       "      <td>5.447851</td>\n",
       "      <td>...</td>\n",
       "      <td>33.53821958</td>\n",
       "      <td>28.281468</td>\n",
       "      <td>23.127681</td>\n",
       "      <td>11.979449</td>\n",
       "      <td>17.519198</td>\n",
       "      <td>24.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.506228</td>\n",
       "      <td>36.562100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10512</td>\n",
       "      <td>12249</td>\n",
       "      <td>1</td>\n",
       "      <td>11502</td>\n",
       "      <td>7743</td>\n",
       "      <td>2</td>\n",
       "      <td>9619</td>\n",
       "      <td>13908</td>\n",
       "      <td>68.987348</td>\n",
       "      <td>36.388358</td>\n",
       "      <td>...</td>\n",
       "      <td>25.22521593</td>\n",
       "      <td>26.681675</td>\n",
       "      <td>24.442798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.323460</td>\n",
       "      <td>38.083555</td>\n",
       "      <td>4.204482</td>\n",
       "      <td>55.658016</td>\n",
       "      <td>27.952446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7987</td>\n",
       "      <td>11854</td>\n",
       "      <td>2</td>\n",
       "      <td>10419</td>\n",
       "      <td>11895</td>\n",
       "      <td>9</td>\n",
       "      <td>11931</td>\n",
       "      <td>11439</td>\n",
       "      <td>94.638788</td>\n",
       "      <td>15.529948</td>\n",
       "      <td>...</td>\n",
       "      <td>34.51618537</td>\n",
       "      <td>24.056261</td>\n",
       "      <td>28.558353</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>13.800903</td>\n",
       "      <td>27.757483</td>\n",
       "      <td>33.449086</td>\n",
       "      <td>44.809595</td>\n",
       "      <td>37.884099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7761</td>\n",
       "      <td>14159</td>\n",
       "      <td>4</td>\n",
       "      <td>10898</td>\n",
       "      <td>10560</td>\n",
       "      <td>9</td>\n",
       "      <td>9153</td>\n",
       "      <td>12992</td>\n",
       "      <td>68.762015</td>\n",
       "      <td>4.809379</td>\n",
       "      <td>...</td>\n",
       "      <td>32.13721328</td>\n",
       "      <td>27.884767</td>\n",
       "      <td>23.329477</td>\n",
       "      <td>13.445587</td>\n",
       "      <td>16.742312</td>\n",
       "      <td>28.738945</td>\n",
       "      <td>26.135224</td>\n",
       "      <td>49.330295</td>\n",
       "      <td>35.162254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bins0  Bins1  Bins2  Bins3  Bins4  Bins5  Bins6  Bins7  rmean_bins0  \\\n",
       "0   4722  15567      4   7683  12061      1   8864  16634    77.433079   \n",
       "1   6556  13701     25   9956   9437      0  12114  13747    79.728951   \n",
       "2  10512  12249      1  11502   7743      2   9619  13908    68.987348   \n",
       "3   7987  11854      2  10419  11895      9  11931  11439    94.638788   \n",
       "4   7761  14159      4  10898  10560      9   9153  12992    68.762015   \n",
       "\n",
       "   rmean_bins1  ...  bskew_bins7  bkurto_bins0  bkurto_bins1  bkurto_bins2  \\\n",
       "0     0.202929  ...  29.26670025     39.092067     21.915792     15.564234   \n",
       "1     5.447851  ...  33.53821958     28.281468     23.127681     11.979449   \n",
       "2    36.388358  ...  25.22521593     26.681675     24.442798      0.000000   \n",
       "3    15.529948  ...  34.51618537     24.056261     28.558353      0.840896   \n",
       "4     4.809379  ...  32.13721328     27.884767     23.329477     13.445587   \n",
       "\n",
       "   bkurto_bins3  bkurto_bins4 bkurto_bins5 bkurto_bins6 bkurto_bins7 class  \n",
       "0     10.232452     12.530200     0.000000    40.674295    31.538221     0  \n",
       "1     17.519198     24.313131     0.000000    38.506228    36.562100     0  \n",
       "2     12.323460     38.083555     4.204482    55.658016    27.952446     0  \n",
       "3     13.800903     27.757483    33.449086    44.809595    37.884099     0  \n",
       "4     16.742312     28.738945    26.135224    49.330295    35.162254     0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['filename'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['rstd_bins0','rstd_bins1','rstd_bins2','rstd_bins3','rstd_bins4','rstd_bins5','rstd_bins6','rstd_bins7','rskew_bins0','rskew_bins1','rskew_bins2','rskew_bins3','rskew_bins4','rskew_bins5','rskew_bins6','rskew_bins7','gstd_bins0','gstd_bins1','gstd_bins2','gstd_bins3','gstd_bins4','gstd_bins5','gstd_bins6','gstd_bins7','bstd_bins0','bstd_bins1','bstd_bins2','bstd_bins3','bstd_bins4','bstd_bins5','bstd_bins6','bstd_bins7','gskew_bins0','gskew_bins1','gskew_bins2','gskew_bins3','gskew_bins4','gskew_bins5','gskew_bins6','gskew_bins7','bskew_bins0','bskew_bins1','bskew_bins2','bskew_bins3','bskew_bins4','bskew_bins5','bskew_bins6','bskew_bins7','class']\n",
    "for i in name:\n",
    "    data[i] = pd.to_numeric(data[i],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>rmean_bins1</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4722.0</td>\n",
       "      <td>15567.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7683.0</td>\n",
       "      <td>12061.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8864.0</td>\n",
       "      <td>16634.0</td>\n",
       "      <td>77.433079</td>\n",
       "      <td>0.202929</td>\n",
       "      <td>...</td>\n",
       "      <td>29.266700</td>\n",
       "      <td>39.092067</td>\n",
       "      <td>21.915792</td>\n",
       "      <td>15.564234</td>\n",
       "      <td>10.232452</td>\n",
       "      <td>12.530200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.674295</td>\n",
       "      <td>31.538221</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6556.0</td>\n",
       "      <td>13701.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9956.0</td>\n",
       "      <td>9437.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12114.0</td>\n",
       "      <td>13747.0</td>\n",
       "      <td>79.728951</td>\n",
       "      <td>5.447851</td>\n",
       "      <td>...</td>\n",
       "      <td>33.538220</td>\n",
       "      <td>28.281468</td>\n",
       "      <td>23.127681</td>\n",
       "      <td>11.979449</td>\n",
       "      <td>17.519198</td>\n",
       "      <td>24.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.506228</td>\n",
       "      <td>36.562100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10512.0</td>\n",
       "      <td>12249.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11502.0</td>\n",
       "      <td>7743.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9619.0</td>\n",
       "      <td>13908.0</td>\n",
       "      <td>68.987348</td>\n",
       "      <td>36.388358</td>\n",
       "      <td>...</td>\n",
       "      <td>25.225216</td>\n",
       "      <td>26.681675</td>\n",
       "      <td>24.442798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.323460</td>\n",
       "      <td>38.083555</td>\n",
       "      <td>4.204482</td>\n",
       "      <td>55.658016</td>\n",
       "      <td>27.952446</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7987.0</td>\n",
       "      <td>11854.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10419.0</td>\n",
       "      <td>11895.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11931.0</td>\n",
       "      <td>11439.0</td>\n",
       "      <td>94.638788</td>\n",
       "      <td>15.529948</td>\n",
       "      <td>...</td>\n",
       "      <td>34.516185</td>\n",
       "      <td>24.056261</td>\n",
       "      <td>28.558353</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>13.800903</td>\n",
       "      <td>27.757483</td>\n",
       "      <td>33.449086</td>\n",
       "      <td>44.809595</td>\n",
       "      <td>37.884099</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7761.0</td>\n",
       "      <td>14159.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10898.0</td>\n",
       "      <td>10560.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9153.0</td>\n",
       "      <td>12992.0</td>\n",
       "      <td>68.762015</td>\n",
       "      <td>4.809379</td>\n",
       "      <td>...</td>\n",
       "      <td>32.137213</td>\n",
       "      <td>27.884767</td>\n",
       "      <td>23.329477</td>\n",
       "      <td>13.445587</td>\n",
       "      <td>16.742312</td>\n",
       "      <td>28.738945</td>\n",
       "      <td>26.135224</td>\n",
       "      <td>49.330295</td>\n",
       "      <td>35.162254</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3832</th>\n",
       "      <td>9870.0</td>\n",
       "      <td>10436.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9558.0</td>\n",
       "      <td>9764.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16080.0</td>\n",
       "      <td>9815.0</td>\n",
       "      <td>104.708207</td>\n",
       "      <td>27.440974</td>\n",
       "      <td>...</td>\n",
       "      <td>28.826381</td>\n",
       "      <td>16.609479</td>\n",
       "      <td>32.541509</td>\n",
       "      <td>10.841782</td>\n",
       "      <td>18.263777</td>\n",
       "      <td>29.591836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.584547</td>\n",
       "      <td>43.219779</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3833</th>\n",
       "      <td>5946.0</td>\n",
       "      <td>14026.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11041.0</td>\n",
       "      <td>12415.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7886.0</td>\n",
       "      <td>14221.0</td>\n",
       "      <td>74.044736</td>\n",
       "      <td>1.607016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.246127</td>\n",
       "      <td>30.936390</td>\n",
       "      <td>21.337923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.706518</td>\n",
       "      <td>17.877323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.339391</td>\n",
       "      <td>32.611797</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3834</th>\n",
       "      <td>7330.0</td>\n",
       "      <td>8408.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10811.0</td>\n",
       "      <td>18521.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6699.0</td>\n",
       "      <td>13759.0</td>\n",
       "      <td>112.515416</td>\n",
       "      <td>7.136774</td>\n",
       "      <td>...</td>\n",
       "      <td>28.790502</td>\n",
       "      <td>42.515393</td>\n",
       "      <td>18.625921</td>\n",
       "      <td>11.891740</td>\n",
       "      <td>14.170267</td>\n",
       "      <td>3.991819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.311970</td>\n",
       "      <td>41.914116</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3835</th>\n",
       "      <td>7630.0</td>\n",
       "      <td>16431.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9530.0</td>\n",
       "      <td>3413.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17843.0</td>\n",
       "      <td>10685.0</td>\n",
       "      <td>73.122412</td>\n",
       "      <td>24.310145</td>\n",
       "      <td>...</td>\n",
       "      <td>37.426827</td>\n",
       "      <td>20.622111</td>\n",
       "      <td>29.148814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.197666</td>\n",
       "      <td>31.678731</td>\n",
       "      <td>4.769168</td>\n",
       "      <td>50.967873</td>\n",
       "      <td>38.781249</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>5415.0</td>\n",
       "      <td>17347.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8790.0</td>\n",
       "      <td>12865.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8924.0</td>\n",
       "      <td>12193.0</td>\n",
       "      <td>60.702862</td>\n",
       "      <td>1.042082</td>\n",
       "      <td>...</td>\n",
       "      <td>34.588816</td>\n",
       "      <td>33.378388</td>\n",
       "      <td>26.261638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.291031</td>\n",
       "      <td>20.163037</td>\n",
       "      <td>5.045378</td>\n",
       "      <td>45.099627</td>\n",
       "      <td>35.944590</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3823 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bins0    Bins1  Bins2    Bins3    Bins4  Bins5    Bins6    Bins7  \\\n",
       "0      4722.0  15567.0    4.0   7683.0  12061.0    1.0   8864.0  16634.0   \n",
       "1      6556.0  13701.0   25.0   9956.0   9437.0    0.0  12114.0  13747.0   \n",
       "2     10512.0  12249.0    1.0  11502.0   7743.0    2.0   9619.0  13908.0   \n",
       "3      7987.0  11854.0    2.0  10419.0  11895.0    9.0  11931.0  11439.0   \n",
       "4      7761.0  14159.0    4.0  10898.0  10560.0    9.0   9153.0  12992.0   \n",
       "...       ...      ...    ...      ...      ...    ...      ...      ...   \n",
       "3832   9870.0  10436.0   13.0   9558.0   9764.0    0.0  16080.0   9815.0   \n",
       "3833   5946.0  14026.0    1.0  11041.0  12415.0    0.0   7886.0  14221.0   \n",
       "3834   7330.0   8408.0    6.0  10811.0  18521.0    2.0   6699.0  13759.0   \n",
       "3835   7630.0  16431.0    1.0   9530.0   3413.0    3.0  17843.0  10685.0   \n",
       "3836   5415.0  17347.0    0.0   8790.0  12865.0    2.0   8924.0  12193.0   \n",
       "\n",
       "      rmean_bins0  rmean_bins1  ...  bskew_bins7  bkurto_bins0  bkurto_bins1  \\\n",
       "0       77.433079     0.202929  ...    29.266700     39.092067     21.915792   \n",
       "1       79.728951     5.447851  ...    33.538220     28.281468     23.127681   \n",
       "2       68.987348    36.388358  ...    25.225216     26.681675     24.442798   \n",
       "3       94.638788    15.529948  ...    34.516185     24.056261     28.558353   \n",
       "4       68.762015     4.809379  ...    32.137213     27.884767     23.329477   \n",
       "...           ...          ...  ...          ...           ...           ...   \n",
       "3832   104.708207    27.440974  ...    28.826381     16.609479     32.541509   \n",
       "3833    74.044736     1.607016  ...    39.246127     30.936390     21.337923   \n",
       "3834   112.515416     7.136774  ...    28.790502     42.515393     18.625921   \n",
       "3835    73.122412    24.310145  ...    37.426827     20.622111     29.148814   \n",
       "3836    60.702862     1.042082  ...    34.588816     33.378388     26.261638   \n",
       "\n",
       "      bkurto_bins2  bkurto_bins3  bkurto_bins4  bkurto_bins5  bkurto_bins6  \\\n",
       "0        15.564234     10.232452     12.530200      0.000000     40.674295   \n",
       "1        11.979449     17.519198     24.313131      0.000000     38.506228   \n",
       "2         0.000000     12.323460     38.083555      4.204482     55.658016   \n",
       "3         0.840896     13.800903     27.757483     33.449086     44.809595   \n",
       "4        13.445587     16.742312     28.738945     26.135224     49.330295   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "3832     10.841782     18.263777     29.591836      0.000000     43.584547   \n",
       "3833      0.000000      9.706518     17.877323      0.000000     45.339391   \n",
       "3834     11.891740     14.170267      3.991819      0.000000     36.311970   \n",
       "3835      0.000000     20.197666     31.678731      4.769168     50.967873   \n",
       "3836      0.000000     17.291031     20.163037      5.045378     45.099627   \n",
       "\n",
       "      bkurto_bins7  class  \n",
       "0        31.538221    0.0  \n",
       "1        36.562100    0.0  \n",
       "2        27.952446    0.0  \n",
       "3        37.884099    0.0  \n",
       "4        35.162254    0.0  \n",
       "...            ...    ...  \n",
       "3832     43.219779    2.0  \n",
       "3833     32.611797    2.0  \n",
       "3834     41.914116    2.0  \n",
       "3835     38.781249    2.0  \n",
       "3836     35.944590    2.0  \n",
       "\n",
       "[3823 rows x 105 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)\n",
    "\n",
    "clean_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2676, 104), (1147, 104))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['class'], axis=1),\n",
    "    data['class'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([186.34326519,  12.07242871,  34.35329927,   2.81636429,\n",
       "        220.16959356,  21.61454467,   2.47558785,  26.27319559,\n",
       "         20.46050509,  90.4284612 ,  70.27133912,  26.65975928,\n",
       "        164.98822716, 202.58865198,  14.95358979,  57.4033063 ,\n",
       "         45.46932438,  19.26901086, 141.01037563,  29.80422911,\n",
       "         32.44141033, 164.55750848, 336.95581743,   6.94339774,\n",
       "         66.2093384 ,  18.74490433, 147.72031672,  28.27716946,\n",
       "         25.47127335, 168.36530777, 375.66604275,  21.27653421,\n",
       "         96.27316889,  24.73665886, 148.54689954,  25.73602148,\n",
       "         24.12834009, 164.34874842, 280.22833241,  31.13187338,\n",
       "        149.49473234,  77.8686534 ,  94.15159881, 128.69931696,\n",
       "        137.00010905,  33.66991556,   8.22626498,  49.02445474,\n",
       "        300.01694552,  98.85512238, 123.88305069,  36.64704703,\n",
       "         17.75641047, 111.70163834,  78.92925922,  80.41908187,\n",
       "        241.77364431,  74.52506234, 126.42345324,  28.25439318,\n",
       "         15.16128393, 111.94904447,  86.5940078 , 134.96498093,\n",
       "        160.63313172,  57.12138779, 119.37278667,  27.07108473,\n",
       "          7.16915811, 111.88279109,  96.18155942, 168.53226404,\n",
       "         25.569446  ,  30.13544487, 105.47650936,  49.25247242,\n",
       "        160.26181546, 214.1158061 ,  77.77981649,  10.833213  ,\n",
       "         72.78242722,  32.71255747,  99.09766682, 217.70689053,\n",
       "         84.14107409, 170.49846462,  22.5093337 ,   5.255933  ,\n",
       "         74.59455214,  30.12399047, 105.16973921, 203.09129385,\n",
       "         85.65585758, 161.07407084,  22.06869153,  11.49450256,\n",
       "         79.53145964,  26.96329591, 108.27885903, 164.5241366 ,\n",
       "         86.28873124, 160.94546117,  25.01525838,  23.11594701]),\n",
       " array([1.73314564e-076, 6.03321504e-006, 1.85811354e-015, 6.00005810e-002,\n",
       "        3.06883741e-089, 4.87551138e-010, 8.43063638e-002, 5.01649885e-012,\n",
       "        1.51861024e-009, 9.97650345e-039, 1.80632495e-030, 3.43382554e-012,\n",
       "        2.72871347e-068, 1.20135012e-082, 3.48177447e-007, 3.89569382e-025,\n",
       "        3.81419976e-020, 4.91277904e-009, 6.02494857e-059, 1.57907307e-013,\n",
       "        1.19992023e-014, 4.00392531e-068, 3.14103834e-131, 9.82486689e-004,\n",
       "        8.61397881e-029, 8.23667937e-009, 1.41235811e-061, 7.03869035e-013,\n",
       "        1.10168459e-011, 1.35499035e-069, 1.67282788e-144, 6.79982842e-010,\n",
       "        4.23029439e-041, 2.26576132e-011, 6.71093089e-062, 8.49649661e-012,\n",
       "        4.11775706e-011, 4.82187234e-068, 3.26665244e-111, 4.31186405e-014,\n",
       "        2.86047358e-062, 1.35074750e-033, 3.06536707e-040, 4.33081421e-054,\n",
       "        2.27779093e-057, 3.61823424e-015, 2.74364862e-004, 1.23068473e-021,\n",
       "        2.83636468e-118, 3.81355343e-042, 3.52908853e-052, 1.98923220e-016,\n",
       "        2.18406866e-008, 2.56752462e-047, 4.95999674e-034, 1.21579715e-034,\n",
       "        3.06810006e-097, 3.19415243e-032, 3.45817901e-053, 7.19744914e-013,\n",
       "        2.83533987e-007, 2.04344759e-047, 3.63769403e-037, 1.44456321e-056,\n",
       "        1.32423756e-066, 5.10493522e-025, 2.20321735e-050, 2.29436190e-012,\n",
       "        7.84865297e-004, 2.17226956e-047, 4.60769728e-041, 1.16827169e-069,\n",
       "        1.00050740e-011, 1.14212044e-013, 8.12651255e-045, 9.87715222e-022,\n",
       "        1.84476943e-066, 5.60592186e-087, 1.46903648e-033, 2.06139268e-005,\n",
       "        1.66587820e-031, 9.20866550e-015, 3.04268532e-042, 2.54664142e-088,\n",
       "        3.64890605e-036, 2.04055742e-070, 2.02175628e-010, 5.27052528e-003,\n",
       "        2.99068897e-032, 1.15498625e-013, 1.07994251e-044, 7.76497109e-083,\n",
       "        8.78200831e-037, 8.93388041e-067, 3.11858897e-010, 1.06990543e-005,\n",
       "        2.80921865e-034, 2.55003688e-012, 6.06704624e-046, 4.12468204e-068,\n",
       "        4.84565039e-037, 1.00204962e-066, 1.72357749e-011, 1.11352843e-010]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the univariate statistical measure between\n",
    "# each of the variables and the target\n",
    "\n",
    "# similarly to chi2, the output is one array with f-scores\n",
    "# and one array with the pvalues\n",
    "\n",
    "univariate = f_classif(X_train, y_train)\n",
    "\n",
    "univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b817b89cd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) let's capture the pvalues in a pandas series\n",
    "# 2) add the variable names in the index\n",
    "# 3) sort the features based on their anova pvalues\n",
    "# 4) and make a var plot\n",
    "\n",
    "univariate = pd.Series(univariate[1])\n",
    "univariate.index = X_train.columns\n",
    "univariate.sort_values(ascending=False).plot.bar(figsize=(20, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Bins0', 'Bins4', 'rmean_bins4', 'rmean_bins5', 'rstd_bins5',\n",
       "       'rstd_bins6', 'rskew_bins5', 'rskew_bins6', 'rkurto_bins5',\n",
       "       'rkurto_bins6', 'gstd_bins0', 'gskew_bins0', 'gkurto_bins7',\n",
       "       'bmean_bins5', 'bstd_bins3', 'bstd_bins5', 'bskew_bins3', 'bskew_bins5',\n",
       "       'bkurto_bins3', 'bkurto_bins5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the top 10 features\n",
    "sel_ = SelectKBest(f_classif, k=20).fit(X_train, y_train)\n",
    "\n",
    "# display selected feature names\n",
    "X_train.columns[sel_.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I keep a copy of the dataset with all the variables\n",
    "# to compare the performance of machine learning models\n",
    "# at the end of the notebook\n",
    "\n",
    "X_train_original = X_train.copy()\n",
    "X_test_original = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlated features:  36\n"
     ]
    }
   ],
   "source": [
    "# find and remove correlated features\n",
    "def correlation(dataset, threshold):\n",
    "    \n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    \n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            # we are interested in absolute coeff value\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    \n",
    "    return col_corr\n",
    "\n",
    "\n",
    "corr_features = correlation(X_train, 0.8)\n",
    "print('correlated features: ', len(set(corr_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2676, 68), (1147, 68))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove correlated features\n",
    "X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep a copy of the dataset at  this stage\n",
    "X_train_corr = X_train.copy()\n",
    "X_test_corr = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2676, 20), (1147, 20))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_ = SelectKBest(f_classif, k=20).fit(X_train, y_train)\n",
    "\n",
    "# capture selected feature names\n",
    "features_to_keep = X_train.columns[sel_.get_support()]\n",
    "\n",
    "# select features\n",
    "X_train_anova = sel_.transform(X_train)\n",
    "X_test_anova = sel_.transform(X_test)\n",
    "\n",
    "# numpy array to dataframe\n",
    "X_train_anova = pd.DataFrame(X_train_anova)\n",
    "X_train_anova.columns = features_to_keep\n",
    "\n",
    "X_test_anova = pd.DataFrame(X_test_anova)\n",
    "X_test_anova.columns = features_to_keep\n",
    "\n",
    "X_train_anova.shape, X_test_anova.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build random forests and\n",
    "# compare its performance in train and test sets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "#     print('Train set')\n",
    "#     pred = rf.predict_proba(X_train)\n",
    "#     print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1], multi_class='ovo')))\n",
    "    \n",
    "#     print('Test set')\n",
    "#     pred = rf.predict_proba(X_test)\n",
    "#     print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1], multi_class='ovo')))\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred, average='micro')))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred, average='micro')))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred, average='micro')))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = rf, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.79      0.81       364\n",
      "         1.0       0.71      0.81      0.76       378\n",
      "         2.0       0.71      0.66      0.68       405\n",
      "\n",
      "    accuracy                           0.75      1147\n",
      "   macro avg       0.75      0.75      0.75      1147\n",
      "weighted avg       0.75      0.75      0.75      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[286  29  49]\n",
      " [ 10 306  62]\n",
      " [ 42  96 267]]\n",
      "Metrics:\n",
      "Accuracy: 0.749\n",
      "F1 Score: 0.749\n",
      "Precision: 0.749\n",
      "Recall: 0.749\n",
      "After Cross Validation:\n",
      "Accuracy: 73.02 %\n",
      "Standard Deviation: 1.69 %\n"
     ]
    }
   ],
   "source": [
    "run_randomForests(X_train_original,\n",
    "                  X_test_original,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.77      0.80       364\n",
      "         1.0       0.73      0.77      0.75       378\n",
      "         2.0       0.66      0.67      0.66       405\n",
      "\n",
      "    accuracy                           0.73      1147\n",
      "   macro avg       0.74      0.73      0.73      1147\n",
      "weighted avg       0.73      0.73      0.73      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[279  24  61]\n",
      " [  7 290  81]\n",
      " [ 51  84 270]]\n",
      "Metrics:\n",
      "Accuracy: 0.731\n",
      "F1 Score: 0.731\n",
      "Precision: 0.731\n",
      "Recall: 0.731\n",
      "After Cross Validation:\n",
      "Accuracy: 71.52 %\n",
      "Standard Deviation: 2.01 %\n"
     ]
    }
   ],
   "source": [
    "# filter methods - univariate roc-auc\n",
    "run_randomForests(X_train_anova,\n",
    "                  X_test_anova,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def run_logistic(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    logit = LogisticRegression(penalty='l1', random_state=44, max_iter=1000, solver='liblinear')\n",
    "    logit.fit(X_train, y_train)\n",
    "    \n",
    "#     print('Train set')\n",
    "#     pred = logit.predict_proba(scaler.transform(X_train))\n",
    "#     print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "#     print('Test set')\n",
    "#     pred = logit.predict_proba(scaler.transform(X_test))\n",
    "#     print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = logit.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred, average='micro')))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred, average='micro')))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred, average='micro')))\n",
    "    \n",
    "#     print('After Cross Validation:')\n",
    "#     accuracies = cross_val_score(estimator = logit, X = X_train, y = y_train, cv = 10)\n",
    "#     print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "#     print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.90      0.90       364\n",
      "         1.0       0.80      0.88      0.83       378\n",
      "         2.0       0.82      0.74      0.78       405\n",
      "\n",
      "    accuracy                           0.84      1147\n",
      "   macro avg       0.84      0.84      0.84      1147\n",
      "weighted avg       0.84      0.84      0.84      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[329  11  24]\n",
      " [  7 331  40]\n",
      " [ 31  73 301]]\n",
      "Metrics:\n",
      "Accuracy: 0.838\n",
      "F1 Score: 0.838\n",
      "Precision: 0.838\n",
      "Recall: 0.838\n"
     ]
    }
   ],
   "source": [
    "run_logistic(X_train_original,\n",
    "                  X_test_original,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.79      0.80       364\n",
      "         1.0       0.67      0.84      0.74       378\n",
      "         2.0       0.69      0.54      0.61       405\n",
      "\n",
      "    accuracy                           0.72      1147\n",
      "   macro avg       0.72      0.72      0.72      1147\n",
      "weighted avg       0.72      0.72      0.71      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[286  29  49]\n",
      " [ 12 318  48]\n",
      " [ 57 129 219]]\n",
      "Metrics:\n",
      "Accuracy: 0.718\n",
      "F1 Score: 0.718\n",
      "Precision: 0.718\n",
      "Recall: 0.718\n"
     ]
    }
   ],
   "source": [
    "run_logistic(X_train_anova,\n",
    "                  X_test_anova,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run_kernel_SVM(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = SVC(kernel = 'rbf', random_state = 0, probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "#     print('Train set')\n",
    "#     pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "#     print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "#     print('Test set')\n",
    "#     pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "#     print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred, average='micro')))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred, average='micro')))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred, average='micro')))\n",
    "    \n",
    "#     print('After Cross Validation:')\n",
    "#     accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "#     print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "#     print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.54      0.60       364\n",
      "         1.0       0.52      0.82      0.64       378\n",
      "         2.0       0.49      0.31      0.38       405\n",
      "\n",
      "    accuracy                           0.55      1147\n",
      "   macro avg       0.56      0.56      0.54      1147\n",
      "weighted avg       0.55      0.55      0.53      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[198  72  94]\n",
      " [ 30 309  39]\n",
      " [ 71 208 126]]\n",
      "Metrics:\n",
      "Accuracy: 0.552\n",
      "F1 Score: 0.552\n",
      "Precision: 0.552\n",
      "Recall: 0.552\n"
     ]
    }
   ],
   "source": [
    "run_kernel_SVM(X_train_original,\n",
    "                  X_test_original,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.57      0.59       364\n",
      "         1.0       0.47      0.83      0.60       378\n",
      "         2.0       0.51      0.17      0.26       405\n",
      "\n",
      "    accuracy                           0.51      1147\n",
      "   macro avg       0.53      0.52      0.48      1147\n",
      "weighted avg       0.53      0.51      0.47      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[207 111  46]\n",
      " [ 43 313  22]\n",
      " [ 88 247  70]]\n",
      "Metrics:\n",
      "Accuracy: 0.514\n",
      "F1 Score: 0.514\n",
      "Precision: 0.514\n",
      "Recall: 0.514\n"
     ]
    }
   ],
   "source": [
    "run_kernel_SVM(X_train_anova,\n",
    "                  X_test_anova,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def run_knn(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "#     print('Train set')\n",
    "#     pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "#     print('KNN roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "#     print('Test set')\n",
    "#     pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "#     print('KNN roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred, average='micro')))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred, average='micro')))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred, average='micro')))\n",
    "    \n",
    "#     print('After Cross Validation:')\n",
    "#     accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "#     print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "#     print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.71      0.70       364\n",
      "         1.0       0.62      0.79      0.69       378\n",
      "         2.0       0.63      0.45      0.53       405\n",
      "\n",
      "    accuracy                           0.64      1147\n",
      "   macro avg       0.65      0.65      0.64      1147\n",
      "weighted avg       0.64      0.64      0.64      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[260  47  57]\n",
      " [ 32 297  49]\n",
      " [ 89 134 182]]\n",
      "Metrics:\n",
      "Accuracy: 0.644\n",
      "F1 Score: 0.644\n",
      "Precision: 0.644\n",
      "Recall: 0.644\n"
     ]
    }
   ],
   "source": [
    "run_knn(X_train_original,\n",
    "                  X_test_original,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.64      0.60       364\n",
      "         1.0       0.53      0.63      0.58       378\n",
      "         2.0       0.53      0.37      0.43       405\n",
      "\n",
      "    accuracy                           0.54      1147\n",
      "   macro avg       0.54      0.55      0.54      1147\n",
      "weighted avg       0.54      0.54      0.53      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[233  67  64]\n",
      " [ 68 239  71]\n",
      " [112 143 150]]\n",
      "Metrics:\n",
      "Accuracy: 0.542\n",
      "F1 Score: 0.542\n",
      "Precision: 0.542\n",
      "Recall: 0.542\n"
     ]
    }
   ],
   "source": [
    "run_knn(X_train_anova,\n",
    "                  X_test_anova,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def run_decision_tree(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "#     print('Train set')\n",
    "#     pred = classifier.predict_proba(X_train)\n",
    "#     print('Decision Tree roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "#     print('Test set')\n",
    "#     pred = classifier.predict_proba(X_test)\n",
    "#     print('Decision Tree roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred, average='micro')))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred, average='micro')))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred, average='micro')))\n",
    "    \n",
    "#     print('After Cross Validation:')\n",
    "#     accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "#     print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "#     print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.74      0.76       364\n",
      "         1.0       0.71      0.70      0.71       378\n",
      "         2.0       0.66      0.69      0.67       405\n",
      "\n",
      "    accuracy                           0.71      1147\n",
      "   macro avg       0.71      0.71      0.71      1147\n",
      "weighted avg       0.71      0.71      0.71      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[269  34  61]\n",
      " [ 26 266  86]\n",
      " [ 50  75 280]]\n",
      "Metrics:\n",
      "Accuracy: 0.711\n",
      "F1 Score: 0.711\n",
      "Precision: 0.711\n",
      "Recall: 0.711\n"
     ]
    }
   ],
   "source": [
    "run_decision_tree(X_train_original,\n",
    "                  X_test_original,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.77      0.78       364\n",
      "         1.0       0.71      0.71      0.71       378\n",
      "         2.0       0.64      0.65      0.65       405\n",
      "\n",
      "    accuracy                           0.71      1147\n",
      "   macro avg       0.71      0.71      0.71      1147\n",
      "weighted avg       0.71      0.71      0.71      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[281  24  59]\n",
      " [ 24 267  87]\n",
      " [ 55  87 263]]\n",
      "Metrics:\n",
      "Accuracy: 0.707\n",
      "F1 Score: 0.707\n",
      "Precision: 0.707\n",
      "Recall: 0.707\n"
     ]
    }
   ],
   "source": [
    "run_decision_tree(X_train_anova,\n",
    "                  X_test_anova,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def run_naive_bayes(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "#     print('Train set')\n",
    "#     pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "#     print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "#     print('Test set')\n",
    "#     pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "#     print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred, average='micro')))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred, average='micro')))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred, average='micro')))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.61      0.68       364\n",
      "         1.0       0.68      0.83      0.75       378\n",
      "         2.0       0.59      0.58      0.59       405\n",
      "\n",
      "    accuracy                           0.67      1147\n",
      "   macro avg       0.68      0.67      0.67      1147\n",
      "weighted avg       0.67      0.67      0.67      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[222  28 114]\n",
      " [ 17 312  49]\n",
      " [ 53 117 235]]\n",
      "Metrics:\n",
      "Accuracy: 0.670\n",
      "F1 Score: 0.670\n",
      "Precision: 0.670\n",
      "Recall: 0.670\n",
      "After Cross Validation:\n",
      "Accuracy: 66.03 %\n",
      "Standard Deviation: 2.24 %\n"
     ]
    }
   ],
   "source": [
    "run_naive_bayes(X_train_original,\n",
    "                  X_test_original,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.58      0.66       364\n",
      "         1.0       0.60      0.85      0.70       378\n",
      "         2.0       0.53      0.44      0.48       405\n",
      "\n",
      "    accuracy                           0.62      1147\n",
      "   macro avg       0.63      0.62      0.61      1147\n",
      "weighted avg       0.63      0.62      0.61      1147\n",
      "\n",
      "Confusion Matrix:\n",
      "[[212  35 117]\n",
      " [ 17 320  41]\n",
      " [ 48 180 177]]\n",
      "Metrics:\n",
      "Accuracy: 0.618\n",
      "F1 Score: 0.618\n",
      "Precision: 0.618\n",
      "Recall: 0.618\n",
      "After Cross Validation:\n",
      "Accuracy: 62.74 %\n",
      "Standard Deviation: 2.40 %\n"
     ]
    }
   ],
   "source": [
    "run_naive_bayes(X_train_anova,\n",
    "                  X_test_anova,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run_linear_SVM(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = SVC(kernel = 'linear', random_state = 0, probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "#     print('Train set')\n",
    "#     pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "#     print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "#     print('Test set')\n",
    "#     pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "#     print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred, average='micro')))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred, average='micro')))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred, average='micro')))\n",
    "    \n",
    "#     print('After Cross Validation:')\n",
    "#     accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "#     print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "#     print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_linear_SVM(X_train_original,\n",
    "                  X_test_original,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_linear_SVM(X_train_anova,\n",
    "                  X_test_anova,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
