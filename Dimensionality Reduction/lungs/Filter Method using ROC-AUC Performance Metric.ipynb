{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2484, 106)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('image_bins_stats_lungs1.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transformed_image_covid_1.png</td>\n",
       "      <td>4722</td>\n",
       "      <td>15567</td>\n",
       "      <td>4</td>\n",
       "      <td>7683</td>\n",
       "      <td>12061</td>\n",
       "      <td>1</td>\n",
       "      <td>8864</td>\n",
       "      <td>16634</td>\n",
       "      <td>77.433079</td>\n",
       "      <td>...</td>\n",
       "      <td>29.26670025</td>\n",
       "      <td>39.092067</td>\n",
       "      <td>21.915792</td>\n",
       "      <td>15.564234</td>\n",
       "      <td>10.232452</td>\n",
       "      <td>12.530200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.674295</td>\n",
       "      <td>31.538221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transformed_image_covid_2.png</td>\n",
       "      <td>6556</td>\n",
       "      <td>13701</td>\n",
       "      <td>25</td>\n",
       "      <td>9956</td>\n",
       "      <td>9437</td>\n",
       "      <td>0</td>\n",
       "      <td>12114</td>\n",
       "      <td>13747</td>\n",
       "      <td>79.728951</td>\n",
       "      <td>...</td>\n",
       "      <td>33.53821958</td>\n",
       "      <td>28.281468</td>\n",
       "      <td>23.127681</td>\n",
       "      <td>11.979449</td>\n",
       "      <td>17.519198</td>\n",
       "      <td>24.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.506228</td>\n",
       "      <td>36.562100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transformed_image_covid_3.png</td>\n",
       "      <td>10512</td>\n",
       "      <td>12249</td>\n",
       "      <td>1</td>\n",
       "      <td>11502</td>\n",
       "      <td>7743</td>\n",
       "      <td>2</td>\n",
       "      <td>9619</td>\n",
       "      <td>13908</td>\n",
       "      <td>68.987348</td>\n",
       "      <td>...</td>\n",
       "      <td>25.22521593</td>\n",
       "      <td>26.681675</td>\n",
       "      <td>24.442798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.323460</td>\n",
       "      <td>38.083555</td>\n",
       "      <td>4.204482</td>\n",
       "      <td>55.658016</td>\n",
       "      <td>27.952446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transformed_image_covid_4.png</td>\n",
       "      <td>7987</td>\n",
       "      <td>11854</td>\n",
       "      <td>2</td>\n",
       "      <td>10419</td>\n",
       "      <td>11895</td>\n",
       "      <td>9</td>\n",
       "      <td>11931</td>\n",
       "      <td>11439</td>\n",
       "      <td>94.638788</td>\n",
       "      <td>...</td>\n",
       "      <td>34.51618537</td>\n",
       "      <td>24.056261</td>\n",
       "      <td>28.558353</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>13.800903</td>\n",
       "      <td>27.757483</td>\n",
       "      <td>33.449086</td>\n",
       "      <td>44.809595</td>\n",
       "      <td>37.884099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transformed_image_covid_5.png</td>\n",
       "      <td>7761</td>\n",
       "      <td>14159</td>\n",
       "      <td>4</td>\n",
       "      <td>10898</td>\n",
       "      <td>10560</td>\n",
       "      <td>9</td>\n",
       "      <td>9153</td>\n",
       "      <td>12992</td>\n",
       "      <td>68.762015</td>\n",
       "      <td>...</td>\n",
       "      <td>32.13721328</td>\n",
       "      <td>27.884767</td>\n",
       "      <td>23.329477</td>\n",
       "      <td>13.445587</td>\n",
       "      <td>16.742312</td>\n",
       "      <td>28.738945</td>\n",
       "      <td>26.135224</td>\n",
       "      <td>49.330295</td>\n",
       "      <td>35.162254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        filename  Bins0  Bins1  Bins2  Bins3  Bins4  Bins5  \\\n",
       "0  transformed_image_covid_1.png   4722  15567      4   7683  12061      1   \n",
       "1  transformed_image_covid_2.png   6556  13701     25   9956   9437      0   \n",
       "2  transformed_image_covid_3.png  10512  12249      1  11502   7743      2   \n",
       "3  transformed_image_covid_4.png   7987  11854      2  10419  11895      9   \n",
       "4  transformed_image_covid_5.png   7761  14159      4  10898  10560      9   \n",
       "\n",
       "   Bins6  Bins7  rmean_bins0  ...  bskew_bins7  bkurto_bins0  bkurto_bins1  \\\n",
       "0   8864  16634    77.433079  ...  29.26670025     39.092067     21.915792   \n",
       "1  12114  13747    79.728951  ...  33.53821958     28.281468     23.127681   \n",
       "2   9619  13908    68.987348  ...  25.22521593     26.681675     24.442798   \n",
       "3  11931  11439    94.638788  ...  34.51618537     24.056261     28.558353   \n",
       "4   9153  12992    68.762015  ...  32.13721328     27.884767     23.329477   \n",
       "\n",
       "   bkurto_bins2  bkurto_bins3  bkurto_bins4  bkurto_bins5 bkurto_bins6  \\\n",
       "0     15.564234     10.232452     12.530200      0.000000    40.674295   \n",
       "1     11.979449     17.519198     24.313131      0.000000    38.506228   \n",
       "2      0.000000     12.323460     38.083555      4.204482    55.658016   \n",
       "3      0.840896     13.800903     27.757483     33.449086    44.809595   \n",
       "4     13.445587     16.742312     28.738945     26.135224    49.330295   \n",
       "\n",
       "  bkurto_bins7 class  \n",
       "0    31.538221     0  \n",
       "1    36.562100     0  \n",
       "2    27.952446     0  \n",
       "3    37.884099     0  \n",
       "4    35.162254     0  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>rmean_bins1</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4722</td>\n",
       "      <td>15567</td>\n",
       "      <td>4</td>\n",
       "      <td>7683</td>\n",
       "      <td>12061</td>\n",
       "      <td>1</td>\n",
       "      <td>8864</td>\n",
       "      <td>16634</td>\n",
       "      <td>77.433079</td>\n",
       "      <td>0.202929</td>\n",
       "      <td>...</td>\n",
       "      <td>29.26670025</td>\n",
       "      <td>39.092067</td>\n",
       "      <td>21.915792</td>\n",
       "      <td>15.564234</td>\n",
       "      <td>10.232452</td>\n",
       "      <td>12.530200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.674295</td>\n",
       "      <td>31.538221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6556</td>\n",
       "      <td>13701</td>\n",
       "      <td>25</td>\n",
       "      <td>9956</td>\n",
       "      <td>9437</td>\n",
       "      <td>0</td>\n",
       "      <td>12114</td>\n",
       "      <td>13747</td>\n",
       "      <td>79.728951</td>\n",
       "      <td>5.447851</td>\n",
       "      <td>...</td>\n",
       "      <td>33.53821958</td>\n",
       "      <td>28.281468</td>\n",
       "      <td>23.127681</td>\n",
       "      <td>11.979449</td>\n",
       "      <td>17.519198</td>\n",
       "      <td>24.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.506228</td>\n",
       "      <td>36.562100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10512</td>\n",
       "      <td>12249</td>\n",
       "      <td>1</td>\n",
       "      <td>11502</td>\n",
       "      <td>7743</td>\n",
       "      <td>2</td>\n",
       "      <td>9619</td>\n",
       "      <td>13908</td>\n",
       "      <td>68.987348</td>\n",
       "      <td>36.388358</td>\n",
       "      <td>...</td>\n",
       "      <td>25.22521593</td>\n",
       "      <td>26.681675</td>\n",
       "      <td>24.442798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.323460</td>\n",
       "      <td>38.083555</td>\n",
       "      <td>4.204482</td>\n",
       "      <td>55.658016</td>\n",
       "      <td>27.952446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7987</td>\n",
       "      <td>11854</td>\n",
       "      <td>2</td>\n",
       "      <td>10419</td>\n",
       "      <td>11895</td>\n",
       "      <td>9</td>\n",
       "      <td>11931</td>\n",
       "      <td>11439</td>\n",
       "      <td>94.638788</td>\n",
       "      <td>15.529948</td>\n",
       "      <td>...</td>\n",
       "      <td>34.51618537</td>\n",
       "      <td>24.056261</td>\n",
       "      <td>28.558353</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>13.800903</td>\n",
       "      <td>27.757483</td>\n",
       "      <td>33.449086</td>\n",
       "      <td>44.809595</td>\n",
       "      <td>37.884099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7761</td>\n",
       "      <td>14159</td>\n",
       "      <td>4</td>\n",
       "      <td>10898</td>\n",
       "      <td>10560</td>\n",
       "      <td>9</td>\n",
       "      <td>9153</td>\n",
       "      <td>12992</td>\n",
       "      <td>68.762015</td>\n",
       "      <td>4.809379</td>\n",
       "      <td>...</td>\n",
       "      <td>32.13721328</td>\n",
       "      <td>27.884767</td>\n",
       "      <td>23.329477</td>\n",
       "      <td>13.445587</td>\n",
       "      <td>16.742312</td>\n",
       "      <td>28.738945</td>\n",
       "      <td>26.135224</td>\n",
       "      <td>49.330295</td>\n",
       "      <td>35.162254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bins0  Bins1  Bins2  Bins3  Bins4  Bins5  Bins6  Bins7  rmean_bins0  \\\n",
       "0   4722  15567      4   7683  12061      1   8864  16634    77.433079   \n",
       "1   6556  13701     25   9956   9437      0  12114  13747    79.728951   \n",
       "2  10512  12249      1  11502   7743      2   9619  13908    68.987348   \n",
       "3   7987  11854      2  10419  11895      9  11931  11439    94.638788   \n",
       "4   7761  14159      4  10898  10560      9   9153  12992    68.762015   \n",
       "\n",
       "   rmean_bins1  ...  bskew_bins7  bkurto_bins0  bkurto_bins1  bkurto_bins2  \\\n",
       "0     0.202929  ...  29.26670025     39.092067     21.915792     15.564234   \n",
       "1     5.447851  ...  33.53821958     28.281468     23.127681     11.979449   \n",
       "2    36.388358  ...  25.22521593     26.681675     24.442798      0.000000   \n",
       "3    15.529948  ...  34.51618537     24.056261     28.558353      0.840896   \n",
       "4     4.809379  ...  32.13721328     27.884767     23.329477     13.445587   \n",
       "\n",
       "   bkurto_bins3  bkurto_bins4 bkurto_bins5 bkurto_bins6 bkurto_bins7 class  \n",
       "0     10.232452     12.530200     0.000000    40.674295    31.538221     0  \n",
       "1     17.519198     24.313131     0.000000    38.506228    36.562100     0  \n",
       "2     12.323460     38.083555     4.204482    55.658016    27.952446     0  \n",
       "3     13.800903     27.757483    33.449086    44.809595    37.884099     0  \n",
       "4     16.742312     28.738945    26.135224    49.330295    35.162254     0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['filename'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['rstd_bins0','rstd_bins1','rstd_bins2','rstd_bins3','rstd_bins4','rstd_bins5','rstd_bins6','rstd_bins7','gstd_bins0','gstd_bins1','gstd_bins2','gstd_bins3','gstd_bins4','gstd_bins5','gstd_bins6','gstd_bins7','bstd_bins0','bstd_bins1','bstd_bins2','bstd_bins3','bstd_bins4','bstd_bins5','bstd_bins6','bstd_bins7','gskew_bins0','gskew_bins1','gskew_bins2','gskew_bins3','gskew_bins4','gskew_bins5','gskew_bins6','gskew_bins7','bskew_bins0','bskew_bins1','bskew_bins2','bskew_bins3','bskew_bins4','bskew_bins5','bskew_bins6','bskew_bins7','class']\n",
    "for i in name:\n",
    "    data[i] = pd.to_numeric(data[i],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bins0</th>\n",
       "      <th>Bins1</th>\n",
       "      <th>Bins2</th>\n",
       "      <th>Bins3</th>\n",
       "      <th>Bins4</th>\n",
       "      <th>Bins5</th>\n",
       "      <th>Bins6</th>\n",
       "      <th>Bins7</th>\n",
       "      <th>rmean_bins0</th>\n",
       "      <th>rmean_bins1</th>\n",
       "      <th>...</th>\n",
       "      <th>bskew_bins7</th>\n",
       "      <th>bkurto_bins0</th>\n",
       "      <th>bkurto_bins1</th>\n",
       "      <th>bkurto_bins2</th>\n",
       "      <th>bkurto_bins3</th>\n",
       "      <th>bkurto_bins4</th>\n",
       "      <th>bkurto_bins5</th>\n",
       "      <th>bkurto_bins6</th>\n",
       "      <th>bkurto_bins7</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4722.0</td>\n",
       "      <td>15567.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7683.0</td>\n",
       "      <td>12061.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8864.0</td>\n",
       "      <td>16634.0</td>\n",
       "      <td>77.433079</td>\n",
       "      <td>0.202929</td>\n",
       "      <td>...</td>\n",
       "      <td>29.266700</td>\n",
       "      <td>39.092067</td>\n",
       "      <td>21.915792</td>\n",
       "      <td>15.564234</td>\n",
       "      <td>10.232452</td>\n",
       "      <td>12.530200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.674295</td>\n",
       "      <td>31.538221</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6556.0</td>\n",
       "      <td>13701.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9956.0</td>\n",
       "      <td>9437.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12114.0</td>\n",
       "      <td>13747.0</td>\n",
       "      <td>79.728951</td>\n",
       "      <td>5.447851</td>\n",
       "      <td>...</td>\n",
       "      <td>33.538220</td>\n",
       "      <td>28.281468</td>\n",
       "      <td>23.127681</td>\n",
       "      <td>11.979449</td>\n",
       "      <td>17.519198</td>\n",
       "      <td>24.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.506228</td>\n",
       "      <td>36.562100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10512.0</td>\n",
       "      <td>12249.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11502.0</td>\n",
       "      <td>7743.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9619.0</td>\n",
       "      <td>13908.0</td>\n",
       "      <td>68.987348</td>\n",
       "      <td>36.388358</td>\n",
       "      <td>...</td>\n",
       "      <td>25.225216</td>\n",
       "      <td>26.681675</td>\n",
       "      <td>24.442798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.323460</td>\n",
       "      <td>38.083555</td>\n",
       "      <td>4.204482</td>\n",
       "      <td>55.658016</td>\n",
       "      <td>27.952446</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7987.0</td>\n",
       "      <td>11854.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10419.0</td>\n",
       "      <td>11895.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11931.0</td>\n",
       "      <td>11439.0</td>\n",
       "      <td>94.638788</td>\n",
       "      <td>15.529948</td>\n",
       "      <td>...</td>\n",
       "      <td>34.516185</td>\n",
       "      <td>24.056261</td>\n",
       "      <td>28.558353</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>13.800903</td>\n",
       "      <td>27.757483</td>\n",
       "      <td>33.449086</td>\n",
       "      <td>44.809595</td>\n",
       "      <td>37.884099</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7761.0</td>\n",
       "      <td>14159.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10898.0</td>\n",
       "      <td>10560.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9153.0</td>\n",
       "      <td>12992.0</td>\n",
       "      <td>68.762015</td>\n",
       "      <td>4.809379</td>\n",
       "      <td>...</td>\n",
       "      <td>32.137213</td>\n",
       "      <td>27.884767</td>\n",
       "      <td>23.329477</td>\n",
       "      <td>13.445587</td>\n",
       "      <td>16.742312</td>\n",
       "      <td>28.738945</td>\n",
       "      <td>26.135224</td>\n",
       "      <td>49.330295</td>\n",
       "      <td>35.162254</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>4950.0</td>\n",
       "      <td>16941.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9161.0</td>\n",
       "      <td>12953.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8179.0</td>\n",
       "      <td>13352.0</td>\n",
       "      <td>59.237576</td>\n",
       "      <td>0.162269</td>\n",
       "      <td>...</td>\n",
       "      <td>25.786782</td>\n",
       "      <td>40.580961</td>\n",
       "      <td>22.391613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.716628</td>\n",
       "      <td>15.733760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.642531</td>\n",
       "      <td>33.442984</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>6149.0</td>\n",
       "      <td>11217.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10795.0</td>\n",
       "      <td>14813.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7335.0</td>\n",
       "      <td>15226.0</td>\n",
       "      <td>89.067328</td>\n",
       "      <td>2.286262</td>\n",
       "      <td>...</td>\n",
       "      <td>30.321740</td>\n",
       "      <td>38.459722</td>\n",
       "      <td>19.856163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.773049</td>\n",
       "      <td>11.227728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.091211</td>\n",
       "      <td>34.380787</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>8157.0</td>\n",
       "      <td>8955.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8384.0</td>\n",
       "      <td>14395.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8516.0</td>\n",
       "      <td>17126.0</td>\n",
       "      <td>110.959421</td>\n",
       "      <td>12.390955</td>\n",
       "      <td>...</td>\n",
       "      <td>30.361398</td>\n",
       "      <td>40.138990</td>\n",
       "      <td>24.611149</td>\n",
       "      <td>8.738112</td>\n",
       "      <td>13.053664</td>\n",
       "      <td>9.750293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.766410</td>\n",
       "      <td>38.228325</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>6614.0</td>\n",
       "      <td>11508.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10639.0</td>\n",
       "      <td>14738.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7195.0</td>\n",
       "      <td>14839.0</td>\n",
       "      <td>90.745086</td>\n",
       "      <td>4.628172</td>\n",
       "      <td>...</td>\n",
       "      <td>35.209322</td>\n",
       "      <td>29.755901</td>\n",
       "      <td>22.888434</td>\n",
       "      <td>14.582557</td>\n",
       "      <td>13.300365</td>\n",
       "      <td>13.399057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.964578</td>\n",
       "      <td>34.453684</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>6026.0</td>\n",
       "      <td>14923.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11764.0</td>\n",
       "      <td>9530.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6751.0</td>\n",
       "      <td>16540.0</td>\n",
       "      <td>50.459177</td>\n",
       "      <td>3.036186</td>\n",
       "      <td>...</td>\n",
       "      <td>30.498729</td>\n",
       "      <td>34.411057</td>\n",
       "      <td>11.863055</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>9.137053</td>\n",
       "      <td>17.018301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.159898</td>\n",
       "      <td>29.685276</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2476 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bins0    Bins1  Bins2    Bins3    Bins4  Bins5    Bins6    Bins7  \\\n",
       "0      4722.0  15567.0    4.0   7683.0  12061.0    1.0   8864.0  16634.0   \n",
       "1      6556.0  13701.0   25.0   9956.0   9437.0    0.0  12114.0  13747.0   \n",
       "2     10512.0  12249.0    1.0  11502.0   7743.0    2.0   9619.0  13908.0   \n",
       "3      7987.0  11854.0    2.0  10419.0  11895.0    9.0  11931.0  11439.0   \n",
       "4      7761.0  14159.0    4.0  10898.0  10560.0    9.0   9153.0  12992.0   \n",
       "...       ...      ...    ...      ...      ...    ...      ...      ...   \n",
       "2479   4950.0  16941.0    0.0   9161.0  12953.0    0.0   8179.0  13352.0   \n",
       "2480   6149.0  11217.0    1.0  10795.0  14813.0    0.0   7335.0  15226.0   \n",
       "2481   8157.0   8955.0    3.0   8384.0  14395.0    0.0   8516.0  17126.0   \n",
       "2482   6614.0  11508.0    3.0  10639.0  14738.0    0.0   7195.0  14839.0   \n",
       "2483   6026.0  14923.0    2.0  11764.0   9530.0    0.0   6751.0  16540.0   \n",
       "\n",
       "      rmean_bins0  rmean_bins1  ...  bskew_bins7  bkurto_bins0  bkurto_bins1  \\\n",
       "0       77.433079     0.202929  ...    29.266700     39.092067     21.915792   \n",
       "1       79.728951     5.447851  ...    33.538220     28.281468     23.127681   \n",
       "2       68.987348    36.388358  ...    25.225216     26.681675     24.442798   \n",
       "3       94.638788    15.529948  ...    34.516185     24.056261     28.558353   \n",
       "4       68.762015     4.809379  ...    32.137213     27.884767     23.329477   \n",
       "...           ...          ...  ...          ...           ...           ...   \n",
       "2479    59.237576     0.162269  ...    25.786782     40.580961     22.391613   \n",
       "2480    89.067328     2.286262  ...    30.321740     38.459722     19.856163   \n",
       "2481   110.959421    12.390955  ...    30.361398     40.138990     24.611149   \n",
       "2482    90.745086     4.628172  ...    35.209322     29.755901     22.888434   \n",
       "2483    50.459177     3.036186  ...    30.498729     34.411057     11.863055   \n",
       "\n",
       "      bkurto_bins2  bkurto_bins3  bkurto_bins4  bkurto_bins5  bkurto_bins6  \\\n",
       "0        15.564234     10.232452     12.530200      0.000000     40.674295   \n",
       "1        11.979449     17.519198     24.313131      0.000000     38.506228   \n",
       "2         0.000000     12.323460     38.083555      4.204482     55.658016   \n",
       "3         0.840896     13.800903     27.757483     33.449086     44.809595   \n",
       "4        13.445587     16.742312     28.738945     26.135224     49.330295   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2479      0.000000      6.716628     15.733760      0.000000     45.642531   \n",
       "2480      0.000000      7.773049     11.227728      0.000000     40.091211   \n",
       "2481      8.738112     13.053664      9.750293      0.000000     32.766410   \n",
       "2482     14.582557     13.300365     13.399057      0.000000     41.964578   \n",
       "2483      0.840896      9.137053     17.018301      0.000000     42.159898   \n",
       "\n",
       "      bkurto_bins7  class  \n",
       "0        31.538221    0.0  \n",
       "1        36.562100    0.0  \n",
       "2        27.952446    0.0  \n",
       "3        37.884099    0.0  \n",
       "4        35.162254    0.0  \n",
       "...            ...    ...  \n",
       "2479     33.442984    1.0  \n",
       "2480     34.380787    1.0  \n",
       "2481     38.228325    1.0  \n",
       "2482     34.453684    1.0  \n",
       "2483     29.685276    1.0  \n",
       "\n",
       "[2476 rows x 105 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)\n",
    "\n",
    "clean_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1733, 104), (743, 104))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['class'], axis=1),\n",
    "    data['class'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6047764449291168,\n",
       " 0.5214249363867685,\n",
       " 0.6716466739367503,\n",
       " 0.6272991639403853,\n",
       " 0.6153871319520176,\n",
       " 0.6668884042166484,\n",
       " 0.6191239549254817,\n",
       " 0.6416648491457653,\n",
       " 0.590745183569611,\n",
       " 0.5948527808069792]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine roc-auc for each feature\n",
    "\n",
    "# here we store the roc-auc values\n",
    "roc_values = []\n",
    "\n",
    "# iterate over each feature in the dataset\n",
    "for feature in X_train.columns:\n",
    "\n",
    "    # train a decision tree classifier\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train[feature].fillna(0).to_frame(), y_train)\n",
    "\n",
    "    # obtain the predictions\n",
    "    y_scored = clf.predict_proba(X_test[feature].to_frame())\n",
    "\n",
    "    # calculate and store the roc-auc\n",
    "    roc_values.append(roc_auc_score(y_test, y_scored[:, 1]))\n",
    "    \n",
    "# display the result\n",
    "roc_values[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'roc-auc')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now let's:\n",
    "\n",
    "# 1) capture the roc-auc values in a pandas series\n",
    "# 2) add the variable names in the index\n",
    "# 3) sort the features based on the roc-auc\n",
    "# 4) and make a var plot\n",
    "\n",
    "roc_values = pd.Series(roc_values)\n",
    "roc_values.index = X_train.columns\n",
    "roc_values.sort_values(ascending=False).plot.bar(figsize=(20, 5))\n",
    "plt.ylabel('roc-auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a roc auc value of 0.5 indicates random decision\n",
    "# let's check how many features show a roc-auc value\n",
    "# higher than random\n",
    "\n",
    "len(roc_values[roc_values > 0.62])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Bins0', 'Bins2', 'Bins3', 'Bins4', 'Bins5', 'Bins6', 'Bins7',\n",
       "       'rmean_bins2', 'rmean_bins4', 'rmean_bins5', 'rmean_bins7',\n",
       "       'rstd_bins2', 'rstd_bins3', 'rstd_bins5', 'rstd_bins6', 'rskew_bins0',\n",
       "       'rskew_bins2', 'rskew_bins3', 'rskew_bins5', 'rskew_bins6',\n",
       "       'rskew_bins7', 'rkurto_bins0', 'rkurto_bins2', 'rkurto_bins3',\n",
       "       'rkurto_bins4', 'rkurto_bins5', 'rkurto_bins6', 'rkurto_bins7',\n",
       "       'gmean_bins0', 'gmean_bins1', 'gmean_bins2', 'gmean_bins3',\n",
       "       'gmean_bins4', 'gmean_bins6', 'gmean_bins7', 'gstd_bins0', 'gstd_bins1',\n",
       "       'gstd_bins2', 'gstd_bins7', 'gskew_bins0', 'gskew_bins1', 'gskew_bins2',\n",
       "       'gskew_bins6', 'gskew_bins7', 'gkurto_bins0', 'gkurto_bins1',\n",
       "       'gkurto_bins6', 'gkurto_bins7', 'bmean_bins2', 'bmean_bins3',\n",
       "       'bmean_bins5', 'bmean_bins6', 'bstd_bins1', 'bstd_bins2', 'bstd_bins3',\n",
       "       'bstd_bins5', 'bstd_bins6', 'bskew_bins1', 'bskew_bins3', 'bskew_bins5',\n",
       "       'bskew_bins7', 'bkurto_bins1', 'bkurto_bins6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = roc_values[roc_values > 0.6].index\n",
    "\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1733, 63), (743, 63))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select features in the dataframes\n",
    "\n",
    "X_train = X_train[selected_features]\n",
    "X_test = X_test[selected_features]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build random forests and\n",
    "# compare its performance in train and test sets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = rf, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.9844584345678349\n",
      "Test set\n",
      "Random Forests roc-auc: 0.9700617957106507\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.88      0.91       350\n",
      "         1.0       0.90      0.94      0.92       393\n",
      "\n",
      "    accuracy                           0.91       743\n",
      "   macro avg       0.92      0.91      0.91       743\n",
      "weighted avg       0.91      0.91      0.91       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[309  41]\n",
      " [ 23 370]]\n",
      "Metrics:\n",
      "Accuracy: 0.914\n",
      "F1 Score: 0.920\n",
      "Precision: 0.900\n",
      "Recall: 0.941\n",
      "After Cross Validation:\n",
      "Accuracy: 91.11 %\n",
      "Standard Deviation: 2.01 %\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "run_randomForests(X_train,\n",
    "                  X_test,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def run_logistic(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    logit = LogisticRegression(penalty='l1', random_state=44, max_iter=1000, solver='liblinear')\n",
    "    logit.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = logit.predict_proba(scaler.transform(X_train))\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = logit.predict_proba(scaler.transform(X_test))\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = logit.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = logit, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.9822529766299314\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.9745910577971647\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97       350\n",
      "         1.0       0.96      0.98      0.97       393\n",
      "\n",
      "    accuracy                           0.97       743\n",
      "   macro avg       0.97      0.97      0.97       743\n",
      "weighted avg       0.97      0.97      0.97       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[335  15]\n",
      " [  8 385]]\n",
      "Metrics:\n",
      "Accuracy: 0.969\n",
      "F1 Score: 0.971\n",
      "Precision: 0.963\n",
      "Recall: 0.980\n",
      "After Cross Validation:\n",
      "Accuracy: 95.44 %\n",
      "Standard Deviation: 1.75 %\n"
     ]
    }
   ],
   "source": [
    "run_logistic(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run_kernel_SVM(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = SVC(kernel = 'rbf', random_state = 0, probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.830397197202572\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.8206034169392948\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.72      0.78       350\n",
      "         1.0       0.78      0.89      0.83       393\n",
      "\n",
      "    accuracy                           0.81       743\n",
      "   macro avg       0.82      0.80      0.81       743\n",
      "weighted avg       0.81      0.81      0.81       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[251  99]\n",
      " [ 43 350]]\n",
      "Metrics:\n",
      "Accuracy: 0.809\n",
      "F1 Score: 0.831\n",
      "Precision: 0.780\n",
      "Recall: 0.891\n",
      "After Cross Validation:\n",
      "Accuracy: 79.81 %\n",
      "Standard Deviation: 3.20 %\n"
     ]
    }
   ],
   "source": [
    "run_kernel_SVM(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def run_knn(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('KNN roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('KNN roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "KNN roc-auc: 0.5\n",
      "Test set\n",
      "KNN roc-auc: 0.5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.83      0.87       350\n",
      "         1.0       0.86      0.92      0.89       393\n",
      "\n",
      "    accuracy                           0.88       743\n",
      "   macro avg       0.88      0.88      0.88       743\n",
      "weighted avg       0.88      0.88      0.88       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[292  58]\n",
      " [ 30 363]]\n",
      "Metrics:\n",
      "Accuracy: 0.882\n",
      "F1 Score: 0.892\n",
      "Precision: 0.862\n",
      "Recall: 0.924\n",
      "After Cross Validation:\n",
      "Accuracy: 86.09 %\n",
      "Standard Deviation: 2.73 %\n"
     ]
    }
   ],
   "source": [
    "run_knn(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def run_decision_tree(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(X_train)\n",
    "    print('Decision Tree roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(X_test)\n",
    "    print('Decision Tree roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Decision Tree roc-auc: 1.0\n",
      "Test set\n",
      "Decision Tree roc-auc: 0.9018320610687023\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.88      0.90       350\n",
      "         1.0       0.90      0.92      0.91       393\n",
      "\n",
      "    accuracy                           0.90       743\n",
      "   macro avg       0.90      0.90      0.90       743\n",
      "weighted avg       0.90      0.90      0.90       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[308  42]\n",
      " [ 30 363]]\n",
      "Metrics:\n",
      "Accuracy: 0.903\n",
      "F1 Score: 0.910\n",
      "Precision: 0.896\n",
      "Recall: 0.924\n",
      "After Cross Validation:\n",
      "Accuracy: 90.37 %\n",
      "Standard Deviation: 2.62 %\n"
     ]
    }
   ],
   "source": [
    "run_decision_tree(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def run_naive_bayes(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.5\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.85      0.87       350\n",
      "         1.0       0.88      0.91      0.89       393\n",
      "\n",
      "    accuracy                           0.88       743\n",
      "   macro avg       0.89      0.88      0.88       743\n",
      "weighted avg       0.88      0.88      0.88       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[299  51]\n",
      " [ 35 358]]\n",
      "Metrics:\n",
      "Accuracy: 0.884\n",
      "F1 Score: 0.893\n",
      "Precision: 0.875\n",
      "Recall: 0.911\n",
      "After Cross Validation:\n",
      "Accuracy: 87.31 %\n",
      "Standard Deviation: 2.43 %\n"
     ]
    }
   ],
   "source": [
    "run_naive_bayes(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run_linear_SVM(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    classifier = SVC(kernel = 'linear', random_state = 0, probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_train))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = classifier.predict_proba(scaler.transform(X_test))\n",
    "    print('Kernel SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print('Metrics:')\n",
    "    print('Accuracy: {0:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {0:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: {0:.3f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "    print('Recall: {0:.3f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "    \n",
    "    print('After Cross Validation:')\n",
    "    accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Kernel SVM roc-auc: 0.5\n",
      "Test set\n",
      "Kernel SVM roc-auc: 0.5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.94       350\n",
      "         1.0       0.93      0.97      0.95       393\n",
      "\n",
      "    accuracy                           0.95       743\n",
      "   macro avg       0.95      0.95      0.95       743\n",
      "weighted avg       0.95      0.95      0.95       743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[323  27]\n",
      " [ 11 382]]\n",
      "Metrics:\n",
      "Accuracy: 0.949\n",
      "F1 Score: 0.953\n",
      "Precision: 0.934\n",
      "Recall: 0.972\n",
      "After Cross Validation:\n"
     ]
    }
   ],
   "source": [
    "run_linear_SVM(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
